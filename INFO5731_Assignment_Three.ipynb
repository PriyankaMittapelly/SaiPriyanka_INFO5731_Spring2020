{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaMittapelly/SaiPriyanka_INFO5731_Spring2020/blob/main/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA and LSA. The following information should be reported:\n",
        "\n",
        "(1) Features (top n-gram phrases) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8-zDxjW6T9T",
        "outputId": "445ac56d-37a6-46b3-8a51-5f22700fb0ad"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "df = pd.read_csv('/content/datacleaning11.csv')\n",
        "\n",
        "df.head(101)\n",
        "\n",
        "# Convert to list\n",
        "data = df['DATAafter_cleaning'].tolist()\n",
        "\n",
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "#print(data)\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "#print(data_words)\n",
        "\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "#print(trigram_mod[bigram_mod[data_words]])\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "\n",
        "\n",
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "clean_text = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "#print(clean_text)\n",
        "\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(clean_text)\n",
        "\n",
        "# Create Corpus\n",
        "texts = clean_text\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "#print(corpus[:1])\n",
        "\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus]\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "print(lda_model.print_topics())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.045*\"current\" + 0.035*\"focu\" + 0.035*\"chapter\" + 0.024*\"nation\" + 0.024*\"year\" + 0.024*\"work\" + 0.024*\"develop\" + 0.024*\"last\" + 0.024*\"computerassist\" + 0.024*\"thirtyf\"'), (1, '0.046*\"find\" + 0.035*\"word\" + 0.029*\"thesauru\" + 0.018*\"differ\" + 0.018*\"year\" + 0.018*\"gener\" + 0.018*\"keyfact\" + 0.012*\"need\" + 0.012*\"syntact\" + 0.012*\"support\"'), (2, '0.028*\"human\" + 0.028*\"approach\" + 0.014*\"class\" + 0.014*\"automat\" + 0.014*\"way\" + 0.014*\"complex\" + 0.014*\"agent\" + 0.014*\"interpret\" + 0.014*\"result\" + 0.014*\"speak\"'), (3, '0.023*\"effect\" + 0.022*\"test\" + 0.017*\"linguist\" + 0.017*\"state\" + 0.017*\"type\" + 0.012*\"recent\" + 0.012*\"present\" + 0.012*\"also\" + 0.012*\"applic\" + 0.012*\"result\"'), (4, '0.024*\"target\" + 0.024*\"tutor\" + 0.024*\"limit\" + 0.012*\"word\" + 0.012*\"current\" + 0.012*\"automat\" + 0.012*\"object\" + 0.012*\"document\" + 0.012*\"method\" + 0.012*\"gener\"'), (5, '0.033*\"logic\" + 0.026*\"program\" + 0.026*\"word\" + 0.020*\"linguist\" + 0.020*\"process\" + 0.020*\"give\" + 0.020*\"document\" + 0.013*\"model\" + 0.013*\"class\" + 0.013*\"help\"'), (6, '0.040*\"model\" + 0.020*\"recent\" + 0.020*\"particular\" + 0.020*\"develop\" + 0.020*\"present\" + 0.020*\"indian\" + 0.011*\"make\" + 0.011*\"form\" + 0.011*\"work\" + 0.011*\"level\"'), (7, '0.030*\"pattern\" + 0.022*\"work\" + 0.018*\"process\" + 0.018*\"music\" + 0.013*\"statist\" + 0.013*\"extract\" + 0.013*\"confid\" + 0.013*\"limit\" + 0.013*\"develop\" + 0.013*\"understand\"'), (8, '0.025*\"develop\" + 0.017*\"lyric\" + 0.017*\"music\" + 0.017*\"way\" + 0.017*\"concern\" + 0.017*\"statist\" + 0.017*\"includ\" + 0.017*\"review\" + 0.017*\"deep\" + 0.017*\"recent\"'), (9, '0.032*\"visual\" + 0.032*\"automat\" + 0.021*\"develop\" + 0.021*\"model\" + 0.021*\"graph\" + 0.021*\"datum\" + 0.021*\"entri\" + 0.021*\"maximum\" + 0.011*\"understand\" + 0.011*\"perform\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5zHrVa3B-rf",
        "outputId": "072d6832-40c9-4935-a95e-72c9d4fcc6a6"
      },
      "source": [
        "#LSA MODEL\n",
        "\n",
        "from gensim.models import LdaModel\n",
        "import gensim.corpora as corpora\n",
        "\n",
        "def gensim_lsa_model(dictionary,corpus,number_of_topics,words):\n",
        "    lsamodel = LsiModel(corpus, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
        "    pprint(lsamodel.print_topics(num_topics=number_of_topics, num_words=words))\n",
        "    return lsamodel\n",
        "def coherence_values_lsa(dictionary, corpus, doc_clean, stop, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, stop, step):\n",
        "        # generate LSA model\n",
        "        model = LsiModel(corpus, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    print(coherence_values)\n",
        "    return model_list, coherence_values\n",
        "# LSA Model\n",
        "from gensim.models import LsiModel\n",
        "\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "print(lda_model.print_topics())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.045*\"current\" + 0.035*\"focu\" + 0.035*\"chapter\" + 0.024*\"nation\" + 0.024*\"year\" + 0.024*\"work\" + 0.024*\"develop\" + 0.024*\"last\" + 0.024*\"computerassist\" + 0.024*\"thirtyf\"'), (1, '0.046*\"find\" + 0.035*\"word\" + 0.029*\"thesauru\" + 0.018*\"differ\" + 0.018*\"year\" + 0.018*\"gener\" + 0.018*\"keyfact\" + 0.012*\"need\" + 0.012*\"syntact\" + 0.012*\"support\"'), (2, '0.028*\"human\" + 0.028*\"approach\" + 0.014*\"class\" + 0.014*\"automat\" + 0.014*\"way\" + 0.014*\"complex\" + 0.014*\"agent\" + 0.014*\"interpret\" + 0.014*\"result\" + 0.014*\"speak\"'), (3, '0.023*\"effect\" + 0.022*\"test\" + 0.017*\"linguist\" + 0.017*\"state\" + 0.017*\"type\" + 0.012*\"recent\" + 0.012*\"present\" + 0.012*\"also\" + 0.012*\"applic\" + 0.012*\"result\"'), (4, '0.024*\"target\" + 0.024*\"tutor\" + 0.024*\"limit\" + 0.012*\"word\" + 0.012*\"current\" + 0.012*\"automat\" + 0.012*\"object\" + 0.012*\"document\" + 0.012*\"method\" + 0.012*\"gener\"'), (5, '0.033*\"logic\" + 0.026*\"program\" + 0.026*\"word\" + 0.020*\"linguist\" + 0.020*\"process\" + 0.020*\"give\" + 0.020*\"document\" + 0.013*\"model\" + 0.013*\"class\" + 0.013*\"help\"'), (6, '0.040*\"model\" + 0.020*\"recent\" + 0.020*\"particular\" + 0.020*\"develop\" + 0.020*\"present\" + 0.020*\"indian\" + 0.011*\"make\" + 0.011*\"form\" + 0.011*\"work\" + 0.011*\"level\"'), (7, '0.030*\"pattern\" + 0.022*\"work\" + 0.018*\"process\" + 0.018*\"music\" + 0.013*\"statist\" + 0.013*\"extract\" + 0.013*\"confid\" + 0.013*\"limit\" + 0.013*\"develop\" + 0.013*\"understand\"'), (8, '0.025*\"develop\" + 0.017*\"lyric\" + 0.017*\"music\" + 0.017*\"way\" + 0.017*\"concern\" + 0.017*\"statist\" + 0.017*\"includ\" + 0.017*\"review\" + 0.017*\"deep\" + 0.017*\"recent\"'), (9, '0.032*\"visual\" + 0.032*\"automat\" + 0.021*\"develop\" + 0.021*\"model\" + 0.021*\"graph\" + 0.021*\"datum\" + 0.021*\"entri\" + 0.021*\"maximum\" + 0.011*\"understand\" + 0.011*\"perform\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx9ds-AqCEQk"
      },
      "source": [
        "Summarize and describe the topic for each cluster.\n",
        "\n",
        "0, '0.045*\"current\" + 0.035*\"focu\" + 0.035*\"chapter\" + 0.024*\"nation\" + 0.024*\"year\" + 0.024*\"work\" + 0.024*\"develop\" + 0.024*\"last\" + 0.024*\"computerassist\" + 0.024*\"thirtyf\"'),\n",
        " (1, '0.046*\"find\" + 0.035*\"word\" + 0.029*\"thesauru\" + 0.018*\"differ\" + 0.018*\"year\" + 0.018*\"gener\" + 0.018*\"keyfact\" + 0.012*\"need\" + 0.012*\"syntact\" + 0.012*\"support\"'),\n",
        " (2, '0.028*\"human\" + 0.028*\"approach\" + 0.014*\"class\" + 0.014*\"automat\" + 0.014*\"way\" + 0.014*\"complex\" + 0.014*\"agent\" + 0.014*\"interpret\" + 0.014*\"result\" + 0.014*\"speak\"'),\n",
        " (3, '0.023*\"effect\" + 0.022*\"test\" + 0.017*\"linguist\" + 0.017*\"state\" + 0.017*\"type\" + 0.012*\"recent\" + 0.012*\"present\" + 0.012*\"also\" + 0.012*\"applic\" + 0.012*\"result\"'),\n",
        " (4, '0.024*\"target\" + 0.024*\"tutor\" + 0.024*\"limit\" + 0.012*\"word\" + 0.012*\"current\" + 0.012*\"automat\" + 0.012*\"object\" + 0.012*\"document\" + 0.012*\"method\" + 0.012*\"gener\"'), \n",
        "(5, '0.033*\"logic\" + 0.026*\"program\" + 0.026*\"word\" + 0.020*\"linguist\" + 0.020*\"process\" + 0.020*\"give\" + 0.020*\"document\" + 0.013*\"model\" + 0.013*\"class\" + 0.013*\"help\"'), \n",
        "(6, '0.040*\"model\" + 0.020*\"recent\" + 0.020*\"particular\" + 0.020*\"develop\" + 0.020*\"present\" + 0.020*\"indian\" + 0.011*\"make\" + 0.011*\"form\" + 0.011*\"work\" + 0.011*\"level\"'), \n",
        "(7, '0.030*\"pattern\" + 0.022*\"work\" + 0.018*\"process\" + 0.018*\"music\" + 0.013*\"statist\" + 0.013*\"extract\" + 0.013*\"confid\" + 0.013*\"limit\" + 0.013*\"develop\" + 0.013*\"understand\"'),\n",
        " (8, '0.025*\"develop\" + 0.017*\"lyric\" + 0.017*\"music\" + 0.017*\"way\" + 0.017*\"concern\" + 0.017*\"statist\" + 0.017*\"includ\" + 0.017*\"review\" + 0.017*\"deep\" + 0.017*\"recent\"'),\n",
        " (9, '0.032*\"visual\" + 0.032*\"automat\" + 0.021*\"develop\" + 0.021*\"model\" + 0.021*\"graph\" + 0.021*\"datum\" + 0.021*\"entri\" + 0.021*\"maximum\" + 0.011*\"understand\" + 0.011*\"perform\"')\n",
        "Summarizing the topic names based on my knowledge with the help of keywords extracted using LDA and LSA model . \n",
        "As that models extracts the keywords that define the sentence by removing unwanted information to get an idea on the topic \n",
        "topic 0 : programming , it has keywords like computerassist , develop , work\n",
        "topic 1 :  support , its may be categorized into supporting something . we can estimate by looking at words find , need , support but not sure \n",
        "topic 3: test results  , its may be categraized into that topic because it has keywords application , results ,test \n",
        "topic 4: goal , its about reaching some target can be identified by words target , limit , object \n",
        "topic 5 : assignmnet , it consistys of keywords that are related to homework , class, help , work , program\n",
        "topic 6:country , it talks about a country(india ) work , development \n",
        "topic 7 : song composition , it consists of keywords work , pattern , develop , music\n",
        "topic 8: Music  , it consists keywords like lyric , music , deep , review\n",
        "topic 9 : development , because its consists of keywords like develop , understand , graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. \n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "31a04e43-a78c-4254-d59a-1b6d8fe059e8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "uCk6LglJZubh",
        "outputId": "626f1461-a09c-4f77-e370-0332fc66c558"
      },
      "source": [
        "#Cleaning the data , however  data was cleaned in previous assignment 3 \n",
        "\n",
        "df1 = pd.read_csv('/content/datacleaning11.csv')\n",
        "df1['Sentimental'] = df1['Sentimental'].replace(['positive'] ,1 )\n",
        "df1['Sentimental'] = df1['Sentimental'].replace(['neutral'] ,1 )\n",
        "df1['Sentimental'] = df1['Sentimental'].replace(['negative'] ,0)\n",
        "df = pd.DataFrame(df1)\n",
        "\n",
        "data1 = df\n",
        "\n",
        "\n",
        "stopset = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(use_idf=True , lowercase = True  , stop_words=stopset)\n",
        "\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATAafter_cleaning</th>\n",
              "      <th>Sentimental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>found</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>describ method statist model base maximum entr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seal condit random field term condit term cond...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>address issu cooper linguist gener linguist tr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>descript logic use incom base syntact semant t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>present workbench built priberam informática d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>abstract—natur effect bring improv educ set im...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>twenti year disfavor technolog return imit pro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>statist frequent use stylometri cryptographi s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>summar experi use fragment two rather differ p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   DATAafter_cleaning  Sentimental\n",
              "0                                               found            1\n",
              "1   describ method statist model base maximum entr...            1\n",
              "2   seal condit random field term condit term cond...            1\n",
              "3   address issu cooper linguist gener linguist tr...            1\n",
              "4   descript logic use incom base syntact semant t...            0\n",
              "..                                                ...          ...\n",
              "95  present workbench built priberam informática d...            1\n",
              "96  abstract—natur effect bring improv educ set im...            1\n",
              "97  twenti year disfavor technolog return imit pro...            1\n",
              "98  statist frequent use stylometri cryptographi s...            1\n",
              "99  summar experi use fragment two rather differ p...            1\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSFojWiCx6sO",
        "outputId": "b84cace5-10b3-473a-bbb5-a0006b36ec64"
      },
      "source": [
        "y = df.Sentimental\n",
        "x = vectorizer.fit_transform(df.DATAafter_cleaning)\n",
        "print(y.shape)\n",
        "print(x.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x , y  ,random_state=43)\n",
        "clf = naive_bayes.MultinomialNB()\n",
        "clf.fit(X_train , y_train)\n",
        "\n",
        "\n",
        "accuracy = roc_auc_score(y_test , clf.predict_proba(X_test)[:,-1])\n",
        "\n",
        "print(\"Accuracy {}\" .format(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n",
            "(100, 816)\n",
            "Accuracy 0.625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL9d8sz9kWbZ",
        "outputId": "9dd669d0-f7ee-4e25-cfd4-5e5a732e8b30"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "#print(data1)\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "all_features = vectorizer.fit_transform(data1.DATAafter_cleaning)\n",
        "all_features.shape\n",
        "vectorizer.vocabulary_\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_features , data1.Sentimental , test_size = 0.2 , random_state = 88)\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train , y_train)\n",
        "nr_correct = (y_test == classifier.predict(X_test)).sum()\n",
        "classifier.predict(X_test)\n",
        "Accuracy =  classifier.score(X_test , y_test)\n",
        "print(\" Accuracy {}\" .format(Accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy 0.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evtcKvtnx1gU",
        "outputId": "7955c517-9b4d-4614-c14b-90238509243e"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "mnb = MultinomialNB()\n",
        "svm = LinearSVC()\n",
        "xgb = XGBClassifier()\n",
        "scores = cross_val_score(mnb, X_test, y_test, cv=10)\n",
        "print(\"using MNB\",scores.mean())\n",
        "model_svm = svm.fit(X_train,y_train)\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_svm,y_test))\n",
        "print(classification_report(y_test,y_pred_svm))\n",
        "mnb = MultinomialNB()\n",
        "tfid = TfidfVectorizer()\n",
        "svm = LinearSVC()\n",
        "rf = RandomForestClassifier()\n",
        "scores = cross_val_score(rf, X_test, y_test, cv=10)\n",
        "#print(\"using random forest\",scores.mean())\n",
        "model_xgb = xgb.fit(X_train,y_train)\n",
        "y_pred_xgb = model_xgb.predict(X_test)\n",
        "print('Accuracy %s' % accuracy_score(y_pred_xgb,y_test))\n",
        "print(classification_report(y_test,y_pred_xgb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "using MNB 0.9666666666666666\n",
            "Accuracy 0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.96        25\n",
            "   macro avg       0.48      0.50      0.49        25\n",
            "weighted avg       0.92      0.96      0.94        25\n",
            "\n",
            "Accuracy 0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.96        25\n",
            "   macro avg       0.48      0.50      0.49        25\n",
            "weighted avg       0.92      0.96      0.94        25\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehRxbswhmR53"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download here: https://github.com/unt-iialab/info5731_spring2021/blob/main/assignment/assignment4-question3-data.zip. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8daf4d0f-7329-48f7-9b8d-62f4826a6faf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import stats\n",
        "df_train = pd.read_csv(\"/content/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "df_train.info()\n",
        "df_test.info()\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1459 entries, 0 to 1458\n",
            "Data columns (total 80 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1459 non-null   int64  \n",
            " 1   MSSubClass     1459 non-null   int64  \n",
            " 2   MSZoning       1455 non-null   object \n",
            " 3   LotFrontage    1232 non-null   float64\n",
            " 4   LotArea        1459 non-null   int64  \n",
            " 5   Street         1459 non-null   object \n",
            " 6   Alley          107 non-null    object \n",
            " 7   LotShape       1459 non-null   object \n",
            " 8   LandContour    1459 non-null   object \n",
            " 9   Utilities      1457 non-null   object \n",
            " 10  LotConfig      1459 non-null   object \n",
            " 11  LandSlope      1459 non-null   object \n",
            " 12  Neighborhood   1459 non-null   object \n",
            " 13  Condition1     1459 non-null   object \n",
            " 14  Condition2     1459 non-null   object \n",
            " 15  BldgType       1459 non-null   object \n",
            " 16  HouseStyle     1459 non-null   object \n",
            " 17  OverallQual    1459 non-null   int64  \n",
            " 18  OverallCond    1459 non-null   int64  \n",
            " 19  YearBuilt      1459 non-null   int64  \n",
            " 20  YearRemodAdd   1459 non-null   int64  \n",
            " 21  RoofStyle      1459 non-null   object \n",
            " 22  RoofMatl       1459 non-null   object \n",
            " 23  Exterior1st    1458 non-null   object \n",
            " 24  Exterior2nd    1458 non-null   object \n",
            " 25  MasVnrType     1443 non-null   object \n",
            " 26  MasVnrArea     1444 non-null   float64\n",
            " 27  ExterQual      1459 non-null   object \n",
            " 28  ExterCond      1459 non-null   object \n",
            " 29  Foundation     1459 non-null   object \n",
            " 30  BsmtQual       1415 non-null   object \n",
            " 31  BsmtCond       1414 non-null   object \n",
            " 32  BsmtExposure   1415 non-null   object \n",
            " 33  BsmtFinType1   1417 non-null   object \n",
            " 34  BsmtFinSF1     1458 non-null   float64\n",
            " 35  BsmtFinType2   1417 non-null   object \n",
            " 36  BsmtFinSF2     1458 non-null   float64\n",
            " 37  BsmtUnfSF      1458 non-null   float64\n",
            " 38  TotalBsmtSF    1458 non-null   float64\n",
            " 39  Heating        1459 non-null   object \n",
            " 40  HeatingQC      1459 non-null   object \n",
            " 41  CentralAir     1459 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1459 non-null   int64  \n",
            " 44  2ndFlrSF       1459 non-null   int64  \n",
            " 45  LowQualFinSF   1459 non-null   int64  \n",
            " 46  GrLivArea      1459 non-null   int64  \n",
            " 47  BsmtFullBath   1457 non-null   float64\n",
            " 48  BsmtHalfBath   1457 non-null   float64\n",
            " 49  FullBath       1459 non-null   int64  \n",
            " 50  HalfBath       1459 non-null   int64  \n",
            " 51  BedroomAbvGr   1459 non-null   int64  \n",
            " 52  KitchenAbvGr   1459 non-null   int64  \n",
            " 53  KitchenQual    1458 non-null   object \n",
            " 54  TotRmsAbvGrd   1459 non-null   int64  \n",
            " 55  Functional     1457 non-null   object \n",
            " 56  Fireplaces     1459 non-null   int64  \n",
            " 57  FireplaceQu    729 non-null    object \n",
            " 58  GarageType     1383 non-null   object \n",
            " 59  GarageYrBlt    1381 non-null   float64\n",
            " 60  GarageFinish   1381 non-null   object \n",
            " 61  GarageCars     1458 non-null   float64\n",
            " 62  GarageArea     1458 non-null   float64\n",
            " 63  GarageQual     1381 non-null   object \n",
            " 64  GarageCond     1381 non-null   object \n",
            " 65  PavedDrive     1459 non-null   object \n",
            " 66  WoodDeckSF     1459 non-null   int64  \n",
            " 67  OpenPorchSF    1459 non-null   int64  \n",
            " 68  EnclosedPorch  1459 non-null   int64  \n",
            " 69  3SsnPorch      1459 non-null   int64  \n",
            " 70  ScreenPorch    1459 non-null   int64  \n",
            " 71  PoolArea       1459 non-null   int64  \n",
            " 72  PoolQC         3 non-null      object \n",
            " 73  Fence          290 non-null    object \n",
            " 74  MiscFeature    51 non-null     object \n",
            " 75  MiscVal        1459 non-null   int64  \n",
            " 76  MoSold         1459 non-null   int64  \n",
            " 77  YrSold         1459 non-null   int64  \n",
            " 78  SaleType       1458 non-null   object \n",
            " 79  SaleCondition  1459 non-null   object \n",
            "dtypes: float64(11), int64(26), object(43)\n",
            "memory usage: 912.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2ldUKdJz2gaH",
        "outputId": "ff864611-3e71-4b1a-f005-73fdf1264635"
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1457.000000</td>\n",
              "      <td>1457.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.00000</td>\n",
              "      <td>1381.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1458.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2190.000000</td>\n",
              "      <td>57.378341</td>\n",
              "      <td>68.580357</td>\n",
              "      <td>9819.161069</td>\n",
              "      <td>6.078821</td>\n",
              "      <td>5.553804</td>\n",
              "      <td>1971.357779</td>\n",
              "      <td>1983.662783</td>\n",
              "      <td>100.709141</td>\n",
              "      <td>439.203704</td>\n",
              "      <td>52.619342</td>\n",
              "      <td>554.294925</td>\n",
              "      <td>1046.117970</td>\n",
              "      <td>1156.534613</td>\n",
              "      <td>325.967786</td>\n",
              "      <td>3.543523</td>\n",
              "      <td>1486.045922</td>\n",
              "      <td>0.434454</td>\n",
              "      <td>0.065202</td>\n",
              "      <td>1.570939</td>\n",
              "      <td>0.377656</td>\n",
              "      <td>2.854010</td>\n",
              "      <td>1.042495</td>\n",
              "      <td>6.385195</td>\n",
              "      <td>0.58122</td>\n",
              "      <td>1977.721217</td>\n",
              "      <td>1.766118</td>\n",
              "      <td>472.768861</td>\n",
              "      <td>93.174777</td>\n",
              "      <td>48.313914</td>\n",
              "      <td>24.243317</td>\n",
              "      <td>1.794380</td>\n",
              "      <td>17.064428</td>\n",
              "      <td>1.744345</td>\n",
              "      <td>58.167923</td>\n",
              "      <td>6.104181</td>\n",
              "      <td>2007.769705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.321334</td>\n",
              "      <td>42.746880</td>\n",
              "      <td>22.376841</td>\n",
              "      <td>4955.517327</td>\n",
              "      <td>1.436812</td>\n",
              "      <td>1.113740</td>\n",
              "      <td>30.390071</td>\n",
              "      <td>21.130467</td>\n",
              "      <td>177.625900</td>\n",
              "      <td>455.268042</td>\n",
              "      <td>176.753926</td>\n",
              "      <td>437.260486</td>\n",
              "      <td>442.898624</td>\n",
              "      <td>398.165820</td>\n",
              "      <td>420.610226</td>\n",
              "      <td>44.043251</td>\n",
              "      <td>485.566099</td>\n",
              "      <td>0.530648</td>\n",
              "      <td>0.252468</td>\n",
              "      <td>0.555190</td>\n",
              "      <td>0.503017</td>\n",
              "      <td>0.829788</td>\n",
              "      <td>0.208472</td>\n",
              "      <td>1.508895</td>\n",
              "      <td>0.64742</td>\n",
              "      <td>26.431175</td>\n",
              "      <td>0.775945</td>\n",
              "      <td>217.048611</td>\n",
              "      <td>127.744882</td>\n",
              "      <td>68.883364</td>\n",
              "      <td>67.227765</td>\n",
              "      <td>20.207842</td>\n",
              "      <td>56.609763</td>\n",
              "      <td>30.491646</td>\n",
              "      <td>630.806978</td>\n",
              "      <td>2.722432</td>\n",
              "      <td>1.301740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1461.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1879.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>407.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>407.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1895.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1825.500000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>7391.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1953.000000</td>\n",
              "      <td>1963.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>219.250000</td>\n",
              "      <td>784.000000</td>\n",
              "      <td>873.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1117.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1959.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>318.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2190.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>9399.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1992.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>350.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>988.000000</td>\n",
              "      <td>1079.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1432.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1979.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2554.500000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11517.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2001.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>753.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>797.750000</td>\n",
              "      <td>1305.000000</td>\n",
              "      <td>1382.500000</td>\n",
              "      <td>676.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2002.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2919.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>56600.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1290.000000</td>\n",
              "      <td>4010.000000</td>\n",
              "      <td>1526.000000</td>\n",
              "      <td>2140.000000</td>\n",
              "      <td>5095.000000</td>\n",
              "      <td>5095.000000</td>\n",
              "      <td>1862.000000</td>\n",
              "      <td>1064.000000</td>\n",
              "      <td>5095.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>2207.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>1424.000000</td>\n",
              "      <td>742.000000</td>\n",
              "      <td>1012.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>800.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Id   MSSubClass  ...       MoSold       YrSold\n",
              "count  1459.000000  1459.000000  ...  1459.000000  1459.000000\n",
              "mean   2190.000000    57.378341  ...     6.104181  2007.769705\n",
              "std     421.321334    42.746880  ...     2.722432     1.301740\n",
              "min    1461.000000    20.000000  ...     1.000000  2006.000000\n",
              "25%    1825.500000    20.000000  ...     4.000000  2007.000000\n",
              "50%    2190.000000    50.000000  ...     6.000000  2008.000000\n",
              "75%    2554.500000    70.000000  ...     8.000000  2009.000000\n",
              "max    2919.000000   190.000000  ...    12.000000  2010.000000\n",
              "\n",
              "[8 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "EhhHwCBt2lvq",
        "outputId": "63f12c83-a207-4b18-a130-8c682c781ba4"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>46.549315</td>\n",
              "      <td>567.240411</td>\n",
              "      <td>1057.429452</td>\n",
              "      <td>1162.626712</td>\n",
              "      <td>346.992466</td>\n",
              "      <td>5.844521</td>\n",
              "      <td>1515.463699</td>\n",
              "      <td>0.425342</td>\n",
              "      <td>0.057534</td>\n",
              "      <td>1.565068</td>\n",
              "      <td>0.382877</td>\n",
              "      <td>2.866438</td>\n",
              "      <td>1.046575</td>\n",
              "      <td>6.517808</td>\n",
              "      <td>0.613014</td>\n",
              "      <td>1978.506164</td>\n",
              "      <td>1.767123</td>\n",
              "      <td>472.980137</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>161.319273</td>\n",
              "      <td>441.866955</td>\n",
              "      <td>438.705324</td>\n",
              "      <td>386.587738</td>\n",
              "      <td>436.528436</td>\n",
              "      <td>48.623081</td>\n",
              "      <td>525.480383</td>\n",
              "      <td>0.518911</td>\n",
              "      <td>0.238753</td>\n",
              "      <td>0.550916</td>\n",
              "      <td>0.502885</td>\n",
              "      <td>0.815778</td>\n",
              "      <td>0.220338</td>\n",
              "      <td>1.625393</td>\n",
              "      <td>0.644666</td>\n",
              "      <td>24.689725</td>\n",
              "      <td>0.747315</td>\n",
              "      <td>213.804841</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>795.750000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1129.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1961.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>334.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.500000</td>\n",
              "      <td>991.500000</td>\n",
              "      <td>1087.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1464.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1980.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>1298.250000</td>\n",
              "      <td>1391.250000</td>\n",
              "      <td>728.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1776.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2002.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1474.000000</td>\n",
              "      <td>2336.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>4692.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>572.000000</td>\n",
              "      <td>5642.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1418.000000</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Id   MSSubClass  ...       YrSold      SalePrice\n",
              "count  1460.000000  1460.000000  ...  1460.000000    1460.000000\n",
              "mean    730.500000    56.897260  ...  2007.815753  180921.195890\n",
              "std     421.610009    42.300571  ...     1.328095   79442.502883\n",
              "min       1.000000    20.000000  ...  2006.000000   34900.000000\n",
              "25%     365.750000    20.000000  ...  2007.000000  129975.000000\n",
              "50%     730.500000    50.000000  ...  2008.000000  163000.000000\n",
              "75%    1095.250000    70.000000  ...  2009.000000  214000.000000\n",
              "max    1460.000000   190.000000  ...  2010.000000  755000.000000\n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsH4oIab2RRw",
        "outputId": "5f1e6a7b-95ff-410e-e0fc-d2e7bc100559"
      },
      "source": [
        "corr_matrix = df_train.corr()\n",
        "corr_matrix\n",
        "\n",
        "corr_matrix[\"SalePrice\"].sort_values(ascending=False)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalePrice        1.000000\n",
              "OverallQual      0.790982\n",
              "GrLivArea        0.708624\n",
              "GarageCars       0.640409\n",
              "GarageArea       0.623431\n",
              "TotalBsmtSF      0.613581\n",
              "1stFlrSF         0.605852\n",
              "FullBath         0.560664\n",
              "TotRmsAbvGrd     0.533723\n",
              "YearBuilt        0.522897\n",
              "YearRemodAdd     0.507101\n",
              "GarageYrBlt      0.486362\n",
              "MasVnrArea       0.477493\n",
              "Fireplaces       0.466929\n",
              "BsmtFinSF1       0.386420\n",
              "LotFrontage      0.351799\n",
              "WoodDeckSF       0.324413\n",
              "2ndFlrSF         0.319334\n",
              "OpenPorchSF      0.315856\n",
              "HalfBath         0.284108\n",
              "LotArea          0.263843\n",
              "BsmtFullBath     0.227122\n",
              "BsmtUnfSF        0.214479\n",
              "BedroomAbvGr     0.168213\n",
              "ScreenPorch      0.111447\n",
              "PoolArea         0.092404\n",
              "MoSold           0.046432\n",
              "3SsnPorch        0.044584\n",
              "BsmtFinSF2      -0.011378\n",
              "BsmtHalfBath    -0.016844\n",
              "MiscVal         -0.021190\n",
              "Id              -0.021917\n",
              "LowQualFinSF    -0.025606\n",
              "YrSold          -0.028923\n",
              "OverallCond     -0.077856\n",
              "MSSubClass      -0.084284\n",
              "EnclosedPorch   -0.128578\n",
              "KitchenAbvGr    -0.135907\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "6igNs3HdCcAL",
        "outputId": "cdba5898-c8a5-4965-9aaa-a93f2782d5ff"
      },
      "source": [
        "non = pd.DataFrame(df_train.isnull().sum().sort_values(ascending=False)[:20])\n",
        "non.columns = ['Null Count']\n",
        "non"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Null Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PoolQC</th>\n",
              "      <td>1453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MiscFeature</th>\n",
              "      <td>1406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alley</th>\n",
              "      <td>1369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fence</th>\n",
              "      <td>1179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FireplaceQu</th>\n",
              "      <td>690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageCond</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageFinish</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageQual</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtExposure</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtCond</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtQual</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrArea</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrType</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Electrical</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Null Count\n",
              "PoolQC              1453\n",
              "MiscFeature         1406\n",
              "Alley               1369\n",
              "Fence               1179\n",
              "FireplaceQu          690\n",
              "LotFrontage          259\n",
              "GarageCond            81\n",
              "GarageType            81\n",
              "GarageYrBlt           81\n",
              "GarageFinish          81\n",
              "GarageQual            81\n",
              "BsmtExposure          38\n",
              "BsmtFinType2          38\n",
              "BsmtFinType1          37\n",
              "BsmtCond              37\n",
              "BsmtQual              37\n",
              "MasVnrArea             8\n",
              "MasVnrType             8\n",
              "Electrical             1\n",
              "Utilities              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG-u_VoCCvJl",
        "outputId": "e97886dd-5273-4926-f81c-a5f2e80fec26"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df_train = df_train.select_dtypes(include=[np.number]).interpolate().dropna()\n",
        "df_test = df_test.select_dtypes(include=[np.number]).interpolate().dropna()\n",
        "a1 = df_train.drop(['SalePrice','Id'], axis=1)\n",
        "a2 = np.log(df_train.SalePrice)\n",
        "x_train, x_test, y_train, y_test = train_test_split(a1,a2, random_state= 42, test_size=0.2)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(x_train,y_train)\n",
        "y_LR = linear_model.predict(x_test)\n",
        "linear_model.intercept_,linear_model.coef_"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13.988866348992978,\n",
              " array([-7.65018361e-04, -5.95665261e-04,  1.87661534e-06,  8.57816051e-02,\n",
              "         4.42889038e-02,  2.93084751e-03,  1.31197093e-03, -2.09282654e-05,\n",
              "         2.17519038e-05,  6.09968394e-06,  4.57918851e-06,  3.24307762e-05,\n",
              "         4.47322844e-05,  1.88316389e-05,  8.76394091e-05,  1.51203332e-04,\n",
              "         7.24527026e-02,  1.55431436e-02,  3.24099866e-02,  2.21788209e-02,\n",
              "         1.96120990e-03, -4.47403482e-02,  1.43675969e-02,  4.95230875e-02,\n",
              "        -3.29262408e-04,  7.44644907e-02,  3.83372117e-05,  1.20796329e-04,\n",
              "        -4.00325519e-05,  1.50880502e-04,  2.94041692e-04,  3.29046241e-04,\n",
              "        -4.00360397e-04, -2.49339566e-06,  3.09082461e-04, -5.51616325e-03]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkHdSQrQDEBu",
        "outputId": "60bcdfb1-7c96-4bc8-84bd-d0127de1219f"
      },
      "source": [
        "print('Linear Regression:', linear_model.score(x_test,y_test))\n",
        "MSE = np.square(np.subtract(y_test,y_LR)).mean()\n",
        "print(\"Mean Squared Error:\", MSE)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression: 0.8758658336149933\n",
            "Mean Squared Error: 0.023165113523875666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}