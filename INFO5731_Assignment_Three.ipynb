{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaMittapelly/SaiPriyanka_INFO5731_Spring2020/blob/main/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e6132e-b775-472a-d037-303b79cc4ee6"
      },
      "source": [
        "import nltk, re, string, collections\n",
        "from nltk.util import ngrams\n",
        "\n",
        "with open(\"/content/Abstract1.csv\", \"r\", encoding='latin-1') as file:\n",
        "    text = file.read()\n",
        "\n",
        "tokenized = text.split()\n",
        "\n",
        "# and get a list of all the tri-grams\n",
        "esBigrams = ngrams(tokenized, 3)\n",
        "\n",
        "esBigramFreq = collections.Counter(esBigrams)\n",
        "\n",
        "Trigram = dict(esBigramFreq)\n",
        "\n",
        "print(Trigram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('Abstract', 'Abstract', 'not'): 1, ('Abstract', 'not', 'found'): 8, ('not', 'found', '\"'): 4, ('found', '\"', 'describe'): 1, ('\"', 'describe', 'a'): 1, ('describe', 'a', 'method'): 1, ('a', 'method', 'for'): 2, ('method', 'for', 'statistical'): 1, ('for', 'statistical', 'modeling'): 1, ('statistical', 'modeling', 'based'): 1, ('modeling', 'based', 'on'): 1, ('based', 'on', 'maximum'): 1, ('on', 'maximum', 'entropy.'): 1, ('maximum', 'entropy.', 'We'): 1, ('entropy.', 'We', 'present'): 1, ('We', 'present', 'a'): 2, ('present', 'a', 'maximum-likelihood'): 1, ('a', 'maximum-likelihood', 'approach'): 1, ('maximum-likelihood', 'approach', 'for'): 1, ('approach', 'for', 'automatically'): 1, ('for', 'automatically', 'constructing'): 1, ('automatically', 'constructing', 'maximum'): 1, ('constructing', 'maximum', 'entropy'): 1, ('maximum', 'entropy', 'models'): 1, ('entropy', 'models', 'and'): 1, ('models', 'and', 'describe'): 1, ('and', 'describe', 'how'): 1, ('describe', 'how', 'to'): 1, ('how', 'to', 'implement'): 1, ('to', 'implement', 'this'): 1, ('implement', 'this', 'approach'): 1, ('this', 'approach', 'efficiently,'): 1, ('approach', 'efficiently,', 'using'): 1, ('efficiently,', 'using', 'as'): 1, ('using', 'as', 'examples'): 1, ('as', 'examples', 'several'): 1, ('examples', 'several', 'problems'): 1, ('several', 'problems', 'in'): 1, ('problems', 'in', 'natural'): 1, ('in', 'natural', 'language'): 14, ('natural', 'language', 'processing.'): 9, ('language', 'processing.', '\"'): 1, ('processing.', '\"', 'Scaling'): 1, ('\"', 'Scaling', 'conditional'): 1, ('Scaling', 'conditional', 'random'): 1, ('conditional', 'random', 'fields'): 1, ('random', 'fields', 'for'): 1, ('fields', 'for', 'natural'): 1, ('for', 'natural', 'language'): 4, ('natural', 'language', 'processing'): 34, ('language', 'processing', 'Terms'): 1, ('processing', 'Terms', 'and'): 1, ('Terms', 'and', 'Conditions:'): 2, ('and', 'Conditions:', 'Terms'): 1, ('Conditions:', 'Terms', 'and'): 1, ('and', 'Conditions:', 'Copyright'): 1, ('Conditions:', 'Copyright', 'in'): 1, ('Copyright', 'in', 'works'): 1, ('in', 'works', 'deposited'): 1, ('works', 'deposited', 'in'): 1, ('deposited', 'in', 'Minerva'): 1, ('in', 'Minerva', 'Access'): 1, ('Minerva', 'Access', 'is'): 1, ('Access', 'is', 'retained'): 1, ('is', 'retained', 'by'): 1, ('retained', 'by', 'the'): 1, ('by', 'the', '\"'): 1, ('the', '\"', 'The'): 1, ('\"', 'The', 'paper'): 1, ('The', 'paper', 'addresses'): 1, ('paper', 'addresses', 'the'): 1, ('addresses', 'the', 'issue'): 1, ('the', 'issue', 'of'): 1, ('issue', 'of', 'cooperation'): 1, ('of', 'cooperation', 'between'): 1, ('cooperation', 'between', 'linguistics'): 1, ('between', 'linguistics', 'and'): 2, ('linguistics', 'and', 'natural'): 1, ('and', 'natural', 'language'): 1, ('language', 'processing', '(NLP),'): 1, ('processing', '(NLP),', 'in'): 1, ('(NLP),', 'in', 'general,'): 1, ('in', 'general,', 'and'): 1, ('general,', 'and', 'between'): 1, ('and', 'between', 'linguistics'): 1, ('linguistics', 'and', 'machine'): 1, ('and', 'machine', 'translation'): 1, ('machine', 'translation', '(MT),'): 1, ('translation', '(MT),', 'in'): 1, ('(MT),', 'in', 'particular.'): 1, ('in', 'particular.', 'It'): 1, ('particular.', 'It', 'focuses'): 1, ('It', 'focuses', 'on'): 1, ('focuses', 'on', 'just'): 1, ('on', 'just', 'one'): 1, ('just', 'one', 'direction'): 1, ('one', 'direction', 'of'): 1, ('direction', 'of', 'such'): 1, ('of', 'such', 'cooperation,'): 1, ('such', 'cooperation,', 'namely'): 1, ('cooperation,', 'namely', 'applications'): 1, ('namely', 'applications', 'of'): 1, ('applications', 'of', 'linguistics'): 1, ('of', 'linguistics', 'to'): 1, ('linguistics', 'to', 'NLP,'): 1, ('to', 'NLP,', 'virtually'): 1, ('NLP,', 'virtually', '\"'): 1, ('virtually', '\"', '\"'): 1, ('\"', '\"', 'In'): 5, ('\"', 'In', 'most'): 1, ('In', 'most', 'natural'): 1, ('most', 'natural', 'language'): 1, ('language', 'processing', 'applications,'): 1, ('processing', 'applications,', 'Description'): 1, ('applications,', 'Description', 'Logics'): 1, ('Description', 'Logics', 'have'): 2, ('Logics', 'have', 'been'): 2, ('have', 'been', 'used'): 2, ('been', 'used', 'to'): 1, ('used', 'to', 'encode'): 1, ('to', 'encode', 'in'): 1, ('encode', 'in', 'a'): 1, ('in', 'a', 'knowledge'): 1, ('a', 'knowledge', 'base'): 1, ('knowledge', 'base', 'some'): 1, ('base', 'some', 'syntactic,'): 1, ('some', 'syntactic,', 'semantic,'): 1, ('syntactic,', 'semantic,', 'and'): 1, ('semantic,', 'and', 'pragmatic'): 1, ('and', 'pragmatic', 'elements'): 1, ('pragmatic', 'elements', 'needed'): 1, ('elements', 'needed', 'to'): 1, ('needed', 'to', 'drive'): 1, ('to', 'drive', 'the'): 2, ('drive', 'the', 'semantic'): 1, ('the', 'semantic', 'interpretation'): 1, ('semantic', 'interpretation', 'and'): 1, ('interpretation', 'and', 'the'): 1, ('and', 'the', 'natural'): 1, ('the', 'natural', 'language'): 1, ('natural', 'language', 'generation'): 1, ('language', 'generation', 'processes.'): 1, ('generation', 'processes.', 'More'): 1, ('processes.', 'More', 'recently,'): 1, ('More', 'recently,', 'Description'): 1, ('recently,', 'Description', 'Logics'): 1, ('have', 'been', '\"'): 1, ('been', '\"', '\"'): 1, ('\"', '\"', 'We'): 8, ('\"', 'We', 'propose'): 1, ('We', 'propose', 'a'): 2, ('propose', 'a', 'unified'): 1, ('a', 'unified', 'neural'): 1, ('unified', 'neural', 'network'): 1, ('neural', 'network', 'architecture'): 2, ('network', 'architecture', 'and'): 1, ('architecture', 'and', 'learning'): 1, ('and', 'learning', 'algorithm'): 1, ('learning', 'algorithm', 'that'): 1, ('algorithm', 'that', 'can'): 1, ('that', 'can', 'be'): 1, ('can', 'be', 'applied'): 1, ('be', 'applied', 'to'): 1, ('applied', 'to', 'various'): 1, ('to', 'various', 'natural'): 1, ('various', 'natural', 'language'): 1, ('language', 'processing', 'tasks'): 1, ('processing', 'tasks', 'including'): 1, ('tasks', 'including', 'part-of-speech'): 1, ('including', 'part-of-speech', 'tagging,'): 1, ('part-of-speech', 'tagging,', 'chunking,'): 1, ('tagging,', 'chunking,', 'named'): 1, ('chunking,', 'named', 'entity'): 1, ('named', 'entity', 'recognition,'): 1, ('entity', 'recognition,', 'and'): 1, ('recognition,', 'and', 'semantic'): 1, ('and', 'semantic', 'role'): 1, ('semantic', 'role', 'labeling.'): 1, ('role', 'labeling.', 'This'): 1, ('labeling.', 'This', 'versatility'): 1, ('This', 'versatility', 'is'): 1, ('versatility', 'is', 'achieved'): 1, ('is', 'achieved', 'by'): 1, ('achieved', 'by', 'trying'): 1, ('by', 'trying', 'to'): 1, ('trying', 'to', 'avoid'): 1, ('to', 'avoid', 'task'): 1, ('avoid', 'task', '\"'): 1, ('task', '\"', '\"'): 1, ('\"', '\"', 'Natural'): 2, ('\"', 'Natural', 'Language'): 3, ('Natural', 'Language', 'Processing'): 17, ('Language', 'Processing', 'The'): 1, ('Processing', 'The', 'subject'): 1, ('The', 'subject', 'of'): 1, ('subject', 'of', 'Natural'): 1, ('of', 'Natural', 'Language'): 3, ('Language', 'Processing', 'can'): 1, ('Processing', 'can', 'be'): 1, ('can', 'be', 'considered'): 1, ('be', 'considered', 'in'): 1, ('considered', 'in', 'both'): 1, ('in', 'both', 'broad'): 1, ('both', 'broad', 'and'): 1, ('broad', 'and', 'narrow'): 1, ('and', 'narrow', 'senses.'): 1, ('narrow', 'senses.', 'In'): 1, ('senses.', 'In', 'the'): 1, ('In', 'the', 'broad'): 1, ('the', 'broad', 'sense,'): 1, ('broad', 'sense,', 'it'): 1, ('sense,', 'it', 'covers'): 1, ('it', 'covers', 'processing'): 1, ('covers', 'processing', 'issues'): 1, ('processing', 'issues', 'at'): 1, ('issues', 'at', 'all'): 1, ('at', 'all', 'levels'): 1, ('all', 'levels', 'of'): 1, ('levels', 'of', 'natural'): 1, ('of', 'natural', 'language'): 12, ('natural', 'language', 'understanding,'): 1, ('language', 'understanding,', 'including'): 1, ('understanding,', 'including', 'speech'): 1, ('including', 'speech', 'recognition,'): 1, ('speech', 'recognition,', 'syntactic'): 1, ('recognition,', 'syntactic', 'and'): 1, ('syntactic', 'and', 'semantic'): 1, ('and', 'semantic', 'analysis'): 1, ('semantic', 'analysis', 'of'): 1, ('analysis', 'of', 'sentences'): 1, ('of', 'sentences', '\"'): 1, ('sentences', '\"', 'Robots'): 1, ('\"', 'Robots', 'that'): 1, ('Robots', 'that', 'interact'): 1, ('that', 'interact', 'with'): 1, ('interact', 'with', 'humans'): 1, ('with', 'humans', 'face-to-face'): 1, ('humans', 'face-to-face', 'using'): 1, ('face-to-face', 'using', 'natural'): 1, ('using', 'natural', 'language'): 2, ('natural', 'language', 'need'): 1, ('language', 'need', 'to'): 1, ('need', 'to', 'be'): 2, ('to', 'be', 'responsive'): 1, ('be', 'responsive', 'to'): 1, ('responsive', 'to', 'the'): 1, ('to', 'the', 'way'): 2, ('the', 'way', 'humans'): 2, ('way', 'humans', 'use'): 1, ('humans', 'use', 'language'): 1, ('use', 'language', 'in'): 1, ('language', 'in', 'those'): 1, ('in', 'those', 'situations.'): 1, ('those', 'situations.', 'We'): 1, ('situations.', 'We', 'propose'): 1, ('propose', 'a', 'psychologicallyinspired'): 1, ('a', 'psychologicallyinspired', 'natural'): 1, ('psychologicallyinspired', 'natural', 'language'): 1, ('language', 'processing', 'system'): 1, ('processing', 'system', 'for'): 1, ('system', 'for', 'robots'): 1, ('for', 'robots', 'which'): 1, ('robots', 'which', 'performs'): 1, ('which', 'performs', 'incremental'): 1, ('performs', 'incremental', 'semantic'): 1, ('incremental', 'semantic', 'interpretation'): 1, ('semantic', 'interpretation', 'of'): 1, ('interpretation', 'of', 'spoken'): 1, ('of', 'spoken', 'utterances'): 1, ('spoken', 'utterances', 'Natural'): 1, ('utterances', 'Natural', 'languages'): 1, ('Natural', 'languages', 'are'): 3, ('languages', 'are', 'languages'): 1, ('are', 'languages', 'spoken'): 1, ('languages', 'spoken', 'by'): 1, ('spoken', 'by', 'humans.'): 1, ('by', 'humans.', 'Currently'): 1, ('humans.', 'Currently', 'we'): 1, ('Currently', 'we', 'are'): 1, ('we', 'are', 'not'): 1, ('are', 'not', 'yet'): 1, ('not', 'yet', 'at'): 1, ('yet', 'at', 'the'): 1, ('at', 'the', 'point'): 1, ('the', 'point', 'where'): 1, ('point', 'where', 'these'): 1, ('where', 'these', 'languages'): 1, ('these', 'languages', 'in'): 1, ('languages', 'in', 'all'): 1, ('in', 'all', 'of'): 1, ('all', 'of', 'their'): 1, ('of', 'their', 'unprocessed'): 1, ('their', 'unprocessed', 'forms'): 1, ('unprocessed', 'forms', 'can'): 1, ('forms', 'can', 'be'): 1, ('can', 'be', 'understood'): 1, ('be', 'understood', 'by'): 1, ('understood', 'by', 'computers.'): 1, ('by', 'computers.', 'Natural'): 1, ('computers.', 'Natural', 'language'): 1, ('Natural', 'language', 'processing'): 4, ('language', 'processing', 'is'): 3, ('processing', 'is', 'the'): 3, ('is', 'the', 'collection'): 1, ('the', 'collection', 'of'): 1, ('collection', 'of', 'techniques'): 1, ('of', 'techniques', 'employed'): 1, ('techniques', 'employed', 'to'): 1, ('employed', 'to', 'try'): 1, ('to', 'try', 'and'): 1, ('try', 'and', 'accomplish'): 1, ('and', 'accomplish', 'that'): 1, ('accomplish', 'that', 'goal.'): 1, ('that', 'goal.', 'The'): 1, ('goal.', 'The', 'field'): 1, ('The', 'field', 'of'): 1, ('field', 'of', 'natural'): 1, ('of', 'natural', '\"'): 1, ('natural', '\"', 'ABSTRACT:'): 1, ('\"', 'ABSTRACT:', 'Ambiguity'): 1, ('ABSTRACT:', 'Ambiguity', 'can'): 1, ('Ambiguity', 'can', 'be'): 1, ('can', 'be', 'referred'): 1, ('be', 'referred', 'as'): 1, ('referred', 'as', 'the'): 1, ('as', 'the', 'ability'): 1, ('the', 'ability', 'of'): 1, ('ability', 'of', 'having'): 1, ('of', 'having', 'more'): 1, ('having', 'more', 'than'): 1, ('more', 'than', 'one'): 2, ('than', 'one', 'meaning'): 1, ('one', 'meaning', 'or'): 1, ('meaning', 'or', 'being'): 1, ('or', 'being', 'understood'): 1, ('being', 'understood', 'in'): 1, ('understood', 'in', 'more'): 1, ('in', 'more', 'than'): 1, ('than', 'one', 'way.'): 1, ('one', 'way.', 'Natural'): 1, ('way.', 'Natural', 'languages'): 1, ('languages', 'are', 'ambiguous,'): 1, ('are', 'ambiguous,', 'so'): 1, ('ambiguous,', 'so', 'computers'): 1, ('so', 'computers', 'are'): 1, ('computers', 'are', 'not'): 1, ('are', 'not', 'able'): 1, ('not', 'able', 'to'): 1, ('able', 'to', 'understand'): 1, ('to', 'understand', 'language'): 1, ('understand', 'language', 'the'): 1, ('language', 'the', 'way'): 1, ('the', 'way', 'people'): 1, ('way', 'people', 'do.'): 1, ('people', 'do.', 'Natural'): 1, ('do.', 'Natural', 'Language'): 1, ('Language', 'Processing', '(NLP)'): 8, ('Processing', '(NLP)', 'is'): 4, ('(NLP)', 'is', 'concerned'): 1, ('is', 'concerned', 'with'): 1, ('concerned', 'with', 'the'): 2, ('with', 'the', 'development'): 1, ('the', 'development', '\"'): 1, ('development', '\"', 'Introduction'): 1, ('\"', 'Introduction', 'Statistical'): 1, ('Introduction', 'Statistical', 'natural'): 1, ('Statistical', 'natural', 'language'): 1, ('language', 'processing', '(SNLP)'): 1, ('processing', '(SNLP)', 'is'): 1, ('(SNLP)', 'is', 'a'): 1, ('is', 'a', 'field'): 1, ('a', 'field', 'lying'): 1, ('field', 'lying', 'in'): 1, ('lying', 'in', 'the'): 1, ('in', 'the', 'intersection'): 1, ('the', 'intersection', 'of'): 1, ('intersection', 'of', 'natural'): 1, ('language', 'processing', 'and'): 1, ('processing', 'and', 'machine'): 1, ('and', 'machine', 'learning.'): 1, ('machine', 'learning.', 'SNLP'): 1, ('learning.', 'SNLP', 'di#ers'): 1, ('SNLP', 'di#ers', 'from'): 1, ('di#ers', 'from', 'traditional'): 1, ('from', 'traditional', 'natural'): 1, ('traditional', 'natural', 'language'): 1, ('language', 'processing', 'in'): 1, ('processing', 'in', 'that'): 1, ('in', 'that', 'instead'): 1, ('that', 'instead', 'of'): 1, ('instead', 'of', 'having'): 1, ('of', 'having', 'a'): 1, ('having', 'a', 'linguist'): 1, ('a', 'linguist', 'manually'): 1, ('linguist', 'manually', 'construct'): 1, ('manually', 'construct', 'some'): 1, ('construct', 'some', 'model'): 1, ('some', 'model', 'of'): 1, ('model', 'of', 'a'): 1, ('of', 'a', 'given'): 1, ('a', 'given', 'linguistic'): 1, ('given', 'linguistic', '\"'): 1, ('linguistic', '\"', 'text'): 1, ('\"', 'text', 'directly'): 1, ('text', 'directly', '(rather'): 1, ('directly', '(rather', 'than'): 1, ('(rather', 'than', 'e.g.'): 1, ('than', 'e.g.', 'titles'): 1, ('e.g.', 'titles', 'and'): 1, ('titles', 'and', 'abstracts),'): 1, ('and', 'abstracts),', 'and'): 1, ('abstracts),', 'and', 'suggests'): 1, ('and', 'suggests', 'appropriate'): 1, ('suggests', 'appropriate', 'approaches'): 1, ('appropriate', 'approaches', 'to'): 1, ('approaches', 'to', 'doing'): 1, ('to', 'doing', 'this,'): 1, ('doing', 'this,', 'with'): 1, ('this,', 'with', 'a'): 1, ('with', 'a', 'focus'): 3, ('a', 'focus', 'on'): 3, ('focus', 'on', 'the'): 1, ('on', 'the', 'role'): 1, ('the', 'role', 'of'): 2, ('role', 'of', 'natural'): 1, ('language', 'processing.', 'The'): 2, ('processing.', 'The', 'paper'): 1, ('The', 'paper', 'also'): 1, ('paper', 'also', 'comments'): 1, ('also', 'comments', 'on'): 1, ('comments', 'on', 'possible'): 1, ('on', 'possible', 'connections'): 1, ('possible', 'connections', 'with'): 1, ('connections', 'with', 'data'): 1, ('with', 'data', 'and'): 1, ('data', 'and', 'knowledge'): 1, ('and', 'knowledge', 'retrieval,'): 1, ('knowledge', 'retrieval,', 'and'): 1, ('retrieval,', 'and', 'concludes'): 1, ('and', 'concludes', 'by'): 1, ('concludes', 'by', 'emphasizing'): 1, ('by', 'emphasizing', 'the'): 1, ('emphasizing', 'the', 'importance'): 1, ('the', 'importance', 'of'): 1, ('importance', 'of', 'rigorous'): 1, ('of', 'rigorous', '\"'): 1, ('rigorous', '\"', '\"'): 1, ('\"', '\"', 'ABSTRACT:'): 1, ('\"', 'ABSTRACT:', 'Language'): 1, ('ABSTRACT:', 'Language', 'is'): 1, ('Language', 'is', 'way'): 1, ('is', 'way', 'of'): 1, ('way', 'of', 'communicating'): 1, ('of', 'communicating', 'your'): 1, ('communicating', 'your', 'words'): 1, ('your', 'words', 'Language'): 1, ('words', 'Language', 'helps'): 1, ('Language', 'helps', 'in'): 1, ('helps', 'in', 'understanding'): 1, ('in', 'understanding', 'the'): 1, ('understanding', 'the', 'world,we'): 1, ('the', 'world,we', 'get'): 1, ('world,we', 'get', 'a'): 1, ('get', 'a', 'better'): 1, ('a', 'better', 'insight'): 1, ('better', 'insight', 'of'): 1, ('insight', 'of', 'the'): 1, ('of', 'the', 'world.'): 1, ('the', 'world.', 'Language'): 1, ('world.', 'Language', 'helps'): 1, ('Language', 'helps', 'speakers'): 1, ('helps', 'speakers', 'to'): 1, ('speakers', 'to', 'be'): 1, ('to', 'be', 'as'): 1, ('be', 'as', 'vague'): 1, ('as', 'vague', 'or'): 1, ('vague', 'or', 'as'): 1, ('or', 'as', 'precise'): 1, ('as', 'precise', 'as'): 1, ('precise', 'as', 'they'): 1, ('as', 'they', 'like.'): 1, ('they', 'like.', 'NLP'): 1, ('like.', 'NLP', 'Stands'): 1, ('NLP', 'Stands', 'for'): 1, ('Stands', 'for', 'natural'): 1, ('natural', 'language', 'processing..'): 1, ('language', 'processing..', 'Natural'): 1, ('processing..', 'Natural', 'languages'): 1, ('languages', 'are', 'those'): 1, ('are', 'those', 'languages'): 1, ('those', 'languages', 'that'): 1, ('languages', 'that', 'are'): 1, ('that', 'are', 'spoken'): 1, ('are', 'spoken', '\"'): 1, ('spoken', '\"', '\"'): 1, ('\"', 'We', 'report'): 1, ('We', 'report', 'experiments'): 1, ('report', 'experiments', 'on'): 1, ('experiments', 'on', 'the'): 1, ('on', 'the', 'use'): 1, ('the', 'use', 'of'): 3, ('use', 'of', 'standard'): 1, ('of', 'standard', 'natural'): 1, ('standard', 'natural', 'language'): 1, ('language', 'processing', '(NLP)'): 4, ('processing', '(NLP)', 'tools'): 1, ('(NLP)', 'tools', 'for'): 1, ('tools', 'for', 'the'): 1, ('for', 'the', 'analysis'): 1, ('the', 'analysis', 'of'): 1, ('analysis', 'of', 'music'): 1, ('of', 'music', 'lyrics.'): 1, ('music', 'lyrics.', 'A'): 1, ('lyrics.', 'A', 'significant'): 1, ('A', 'significant', 'amount'): 1, ('significant', 'amount', 'of'): 1, ('amount', 'of', 'music'): 1, ('of', 'music', 'audio'): 1, ('music', 'audio', 'has'): 1, ('audio', 'has', 'lyrics.'): 1, ('has', 'lyrics.', 'Lyrics'): 1, ('lyrics.', 'Lyrics', 'encode'): 1, ('Lyrics', 'encode', 'an'): 1, ('encode', 'an', 'important'): 1, ('an', 'important', 'part'): 1, ('important', 'part', 'of'): 1, ('part', 'of', 'the'): 1, ('of', 'the', 'semantics'): 1, ('the', 'semantics', 'of'): 1, ('semantics', 'of', 'a'): 1, ('of', 'a', 'song,'): 1, ('a', 'song,', 'therefore'): 1, ('song,', 'therefore', 'their'): 1, ('therefore', 'their', 'analysis'): 1, ('their', 'analysis', 'complements'): 1, ('analysis', 'complements', 'that'): 1, ('complements', 'that', 'of'): 1, ('that', 'of', 'acoustic'): 1, ('of', 'acoustic', 'and'): 1, ('acoustic', 'and', 'cultural'): 1, ('and', 'cultural', '\"'): 1, ('cultural', '\"', '\"'): 1, ('\"', '\"', 'this'): 1, ('\"', 'this', 'paper,'): 1, ('this', 'paper,', 'we'): 4, ('paper,', 'we', 'will'): 1, ('we', 'will', 'describe'): 1, ('will', 'describe', 'a'): 1, ('describe', 'a', 'simple'): 1, ('a', 'simple', 'rule-based'): 1, ('simple', 'rule-based', 'approach'): 1, ('rule-based', 'approach', 'to'): 1, ('approach', 'to', 'automated'): 1, ('to', 'automated', 'learning'): 1, ('automated', 'learning', 'of'): 1, ('learning', 'of', 'linguistic'): 1, ('of', 'linguistic', 'knowledge.'): 1, ('linguistic', 'knowledge.', 'This'): 1, ('knowledge.', 'This', 'approach'): 1, ('This', 'approach', 'has'): 1, ('approach', 'has', 'been'): 1, ('has', 'been', 'shown'): 1, ('been', 'shown', 'for'): 1, ('shown', 'for', 'a'): 1, ('for', 'a', 'number'): 1, ('a', 'number', 'of'): 3, ('number', 'of', 'tasks'): 2, ('of', 'tasks', 'to'): 1, ('tasks', 'to', 'capture'): 1, ('to', 'capture', 'information'): 1, ('capture', 'information', 'in'): 1, ('information', 'in', 'a'): 1, ('in', 'a', 'clearer'): 1, ('a', 'clearer', 'and'): 1, ('clearer', 'and', 'more'): 1, ('and', 'more', 'direct'): 1, ('more', 'direct', 'fashion'): 1, ('direct', 'fashion', 'without'): 1, ('fashion', 'without', 'a'): 1, ('without', 'a', 'compromise'): 1, ('a', 'compromise', 'in'): 1, ('compromise', 'in', 'performance.'): 1, ('in', 'performance.', 'We'): 1, ('performance.', 'We', 'present'): 1, ('present', 'a', 'detailed'): 1, ('a', 'detailed', 'case'): 1, ('detailed', 'case', 'study'): 1, ('case', 'study', 'of'): 1, ('study', 'of', 'this'): 1, ('of', 'this', 'learning'): 1, ('this', 'learning', 'method'): 1, ('learning', 'method', 'applied'): 1, ('method', 'applied', 'to'): 1, ('applied', 'to', 'part'): 1, ('to', 'part', 'of'): 1, ('part', 'of', 'speech'): 1, ('of', 'speech', 'tagging'): 1, ('speech', 'tagging', '\"'): 1, ('tagging', '\"', '\"'): 1, ('\"', '\"', 'This'): 2, ('\"', 'This', 'paper'): 5, ('This', 'paper', 'focuses'): 1, ('paper', 'focuses', 'on'): 1, ('focuses', 'on', 'connectionist'): 1, ('on', 'connectionist', 'models'): 1, ('connectionist', 'models', 'in'): 1, ('models', 'in', 'natural'): 1, ('language', 'processing.', 'We'): 3, ('processing.', 'We', 'briefly'): 1, ('We', 'briefly', 'present'): 1, ('briefly', 'present', 'and'): 1, ('present', 'and', 'discuss'): 1, ('and', 'discuss', 'several'): 1, ('discuss', 'several', 'aspects'): 1, ('several', 'aspects', 'of'): 1, ('aspects', 'of', 'high'): 1, ('of', 'high', 'level'): 1, ('high', 'level', 'tasks'): 1, ('level', 'tasks', 'which'): 1, ('tasks', 'which', 'recently'): 1, ('which', 'recently', 'have'): 1, ('recently', 'have', 'been'): 1, ('have', 'been', 'approached'): 1, ('been', 'approached', 'with'): 1, ('approached', 'with', 'connectionism,'): 1, ('with', 'connectionism,', 'either'): 1, ('connectionism,', 'either', 'with'): 1, ('either', 'with', 'localist'): 1, ('with', 'localist', 'or'): 1, ('localist', 'or', 'parallel'): 1, ('or', 'parallel', 'distributed'): 1, ('parallel', 'distributed', 'processing'): 1, ('distributed', 'processing', 'models.'): 1, ('processing', 'models.', 'Several'): 1, ('models.', 'Several', 'interesting'): 1, ('Several', 'interesting', 'architectures'): 1, ('interesting', 'architectures', '\"'): 1, ('architectures', '\"', 'process'): 1, ('\"', 'process', 'of'): 1, ('process', 'of', 'language'): 1, ('of', 'language', 'understanding.'): 1, ('language', 'understanding.', 'This'): 1, ('understanding.', 'This', 'is'): 1, ('This', 'is', 'a'): 1, ('is', 'a', 'new'): 1, ('a', 'new', 'approach'): 1, ('new', 'approach', 'in'): 1, ('approach', 'in', 'natural'): 1, ('language', 'processing', 'based'): 1, ('processing', 'based', 'on'): 1, ('based', 'on', 'the'): 2, ('on', 'the', 'deterministic'): 1, ('the', 'deterministic', 'chaotic'): 1, ('deterministic', 'chaotic', 'behavior'): 1, ('chaotic', 'behavior', 'of'): 1, ('behavior', 'of', 'dynamical'): 1, ('of', 'dynamical', 'systems.'): 1, ('dynamical', 'systems.', '1'): 1, ('systems.', '1', '\"'): 1, ('1', '\"', 'this'): 2, ('\"', 'this', 'paper'): 2, ('this', 'paper', '(see'): 1, ('paper', '(see', '[Schank'): 1, ('(see', '[Schank', '86]'): 1, ('[Schank', '86]', 'for'): 1, ('86]', 'for', 'a'): 1, ('for', 'a', 'theoretical'): 1, ('a', 'theoretical', 'discussion'): 1, ('theoretical', 'discussion', 'and'): 1, ('discussion', 'and', '[Kass'): 1, ('and', '[Kass', '86]'): 1, ('[Kass', '86]', 'and'): 1, ('86]', 'and', '[Leake'): 1, ('and', '[Leake', 'and'): 1, ('[Leake', 'and', 'Owens'): 1, ('and', 'Owens', '86]'): 1, ('Owens', '86]', 'for'): 1, ('86]', 'for', 'brief'): 1, ('for', 'brief', 'discussions'): 1, ('brief', 'discussions', 'of'): 1, ('discussions', 'of', 'a'): 1, ('of', 'a', 'program'): 1, ('a', 'program', 'built'): 1, ('program', 'built', 'around'): 1, ('built', 'around', 'these'): 1, ('around', 'these', '.principles);'): 1, ('these', '.principles);', 'the'): 1, ('.principles);', 'the', 'goal'): 1, ('the', 'goal', 'here'): 1, ('goal', 'here', 'is'): 1, ('here', 'is', 'simply'): 1, ('is', 'simply', 'to'): 1, ('simply', 'to', 'point'): 1, ('to', 'point', 'out'): 1, ('point', 'out', 'how'): 1, ('out', 'how', 'our'): 1, ('how', 'our', 'interest'): 1, ('our', 'interest', 'in'): 1, ('interest', 'in', 'natural'): 1, ('language', 'processing', 'has'): 1, ('processing', 'has', 'led'): 1, ('has', 'led', 'us'): 1, ('led', 'us', 'naturally,'): 1, ('us', 'naturally,', 'and'): 1, ('naturally,', 'and', 'indeed'): 1, ('and', 'indeed', 'inevitably'): 1, ('indeed', 'inevitably', '\"'): 1, ('inevitably', '\"', 'Objectives'): 1, ('\"', 'Objectives', 'To'): 1, ('Objectives', 'To', 'provide'): 1, ('To', 'provide', 'an'): 1, ('provide', 'an', 'overview'): 1, ('an', 'overview', 'and'): 1, ('overview', 'and', 'tutorial'): 1, ('and', 'tutorial', 'of'): 1, ('tutorial', 'of', 'natural'): 1, ('processing', '(NLP)', 'and'): 1, ('(NLP)', 'and', 'modern'): 1, ('and', 'modern', 'NLP-system'): 1, ('modern', 'NLP-system', 'design.'): 1, ('NLP-system', 'design.', 'Target'): 1, ('design.', 'Target', 'audience'): 1, ('Target', 'audience', 'This'): 1, ('audience', 'This', 'tutorial'): 1, ('This', 'tutorial', 'targets'): 1, ('tutorial', 'targets', 'the'): 1, ('targets', 'the', 'medical'): 1, ('the', 'medical', 'informatics'): 1, ('medical', 'informatics', 'generalist'): 1, ('informatics', 'generalist', 'who'): 1, ('generalist', 'who', 'has'): 1, ('who', 'has', 'limited'): 1, ('has', 'limited', 'acquaintance'): 1, ('limited', 'acquaintance', 'with'): 1, ('acquaintance', 'with', 'the'): 1, ('with', 'the', 'principles'): 1, ('the', 'principles', 'behind'): 1, ('principles', 'behind', 'NLP'): 1, ('behind', 'NLP', 'and/or'): 1, ('NLP', 'and/or', 'limited'): 1, ('and/or', 'limited', 'knowledge'): 1, ('limited', 'knowledge', 'of'): 1, ('knowledge', 'of', 'the'): 1, ('of', 'the', 'current'): 2, ('the', 'current', 'state'): 2, ('current', 'state', '\"'): 1, ('state', '\"', 'This'): 1, ('This', 'paper', 'briefly'): 1, ('paper', 'briefly', 'describes'): 1, ('briefly', 'describes', 'the'): 1, ('describes', 'the', 'current'): 1, ('the', 'current', 'implementation'): 1, ('current', 'implementation', 'status'): 1, ('implementation', 'status', 'of'): 1, ('status', 'of', 'an'): 1, ('of', 'an', 'intelligent'): 1, ('an', 'intelligent', 'information'): 1, ('intelligent', 'information', 'retrieval'): 1, ('information', 'retrieval', 'system,'): 1, ('retrieval', 'system,', 'MARIE,'): 1, ('system,', 'MARIE,', 'that'): 1, ('MARIE,', 'that', 'employs'): 1, ('that', 'employs', 'natural'): 1, ('employs', 'natural', 'language'): 1, ('language', 'processing', 'techniques.'): 1, ('processing', 'techniques.', 'Descriptive'): 1, ('techniques.', 'Descriptive', 'captions'): 1, ('Descriptive', 'captions', 'are'): 1, ('captions', 'are', 'used'): 1, ('are', 'used', 'to'): 1, ('used', 'to', 'iden-'): 1, ('to', 'iden-', 'tify'): 1, ('iden-', 'tify', 'photographic'): 1, ('tify', 'photographic', 'images'): 1, ('photographic', 'images', 'concerning'): 1, ('images', 'concerning', 'various'): 1, ('concerning', 'various', 'military'): 1, ('various', 'military', 'projects.'): 1, ('military', 'projects.', 'The'): 1, ('projects.', 'The', 'captions'): 1, ('The', 'captions', 'are'): 1, ('captions', 'are', 'parsed'): 1, ('are', 'parsed', '\"'): 1, ('parsed', '\"', 'based'): 1, ('\"', 'based', 'and'): 1, ('based', 'and', 'literature'): 1, ('and', 'literature', 'resources.'): 1, ('literature', 'resources.', 'We'): 1, ('resources.', 'We', 'describe'): 1, ('We', 'describe', 'here'): 1, ('describe', 'here', 'a'): 1, ('here', 'a', 'system'): 1, ('a', 'system', 'for'): 1, ('system', 'for', 'agent'): 1, ('for', 'agent', 'directed'): 1, ('agent', 'directed', 'natural'): 1, ('directed', 'natural', 'language'): 1, ('language', 'processing', 'to'): 3, ('processing', 'to', 'extract'): 1, ('to', 'extract', 'information'): 1, ('extract', 'information', 'from'): 1, ('information', 'from', 'journal'): 1, ('from', 'journal', 'articles.'): 1, ('journal', 'articles.', 'An'): 1, ('articles.', 'An', 'interface'): 1, ('An', 'interface', 'was'): 1, ('interface', 'was', 'developed'): 1, ('was', 'developed', 'to'): 1, ('developed', 'to', 'permit'): 1, ('to', 'permit', 'curation'): 1, ('permit', 'curation', 'of'): 1, ('curation', 'of', 'the'): 1, ('of', 'the', 'NLP'): 1, ('the', 'NLP', 'results'): 1, ('NLP', 'results', 'and'): 1, ('results', 'and', 'deposition'): 1, ('and', 'deposition', 'of'): 1, ('deposition', 'of', 'accepted'): 1, ('of', 'accepted', 'results'): 1, ('accepted', 'results', 'into'): 1, ('results', 'into', 'a'): 1, ('into', 'a', 'knowledge'): 1, ('a', 'knowledge', 'base.'): 1, ('knowledge', 'base.', 'Motivation:'): 1, ('base.', 'Motivation:', 'The'): 1, ('Motivation:', 'The', 'advent'): 1, ('The', 'advent', 'of'): 1, ('advent', 'of', 'high'): 1, ('of', 'high', '\"'): 1, ('high', '\"', 'to'): 1, ('\"', 'to', 'evaluation'): 1, ('to', 'evaluation', 'in'): 1, ('evaluation', 'in', 'speech'): 1, ('in', 'speech', 'processing.'): 1, ('speech', 'processing.', 'Part'): 1, ('processing.', 'Part', '2'): 1, ('Part', '2', 'surveys'): 1, ('2', 'surveys', 'significant'): 1, ('surveys', 'significant', 'evaluation'): 1, ('significant', 'evaluation', 'work'): 1, ('evaluation', 'work', 'done'): 1, ('work', 'done', 'so'): 1, ('done', 'so', 'far,'): 1, ('so', 'far,', 'for'): 1, ('far,', 'for', 'instance'): 1, ('for', 'instance', 'in'): 1, ('instance', 'in', 'machine'): 1, ('in', 'machine', 'translation,'): 1, ('machine', 'translation,', 'and'): 2, ('translation,', 'and', 'discusses'): 1, ('and', 'discusses', 'the'): 1, ('discusses', 'the', 'particular'): 1, ('the', 'particular', 'problems'): 1, ('particular', 'problems', 'of'): 1, ('problems', 'of', 'generic'): 1, ('of', 'generic', 'system'): 1, ('generic', 'system', 'evaluation.'): 1, ('system', 'evaluation.', 'The'): 1, ('evaluation.', 'The', 'conclusion'): 1, ('The', 'conclusion', 'is'): 1, ('conclusion', 'is', 'that'): 1, ('is', 'that', 'evaluation'): 1, ('that', 'evaluation', 'strategies'): 1, ('evaluation', 'strategies', 'and'): 1, ('strategies', 'and', 'techniques'): 1, ('and', 'techniques', 'for'): 1, ('techniques', 'for', 'NLP'): 1, ('for', 'NLP', 'need'): 1, ('NLP', 'need', 'much'): 1, ('need', 'much', 'more'): 1, ('much', 'more', 'development,'): 1, ('more', 'development,', 'in'): 1, ('development,', 'in', 'particular'): 1, ('in', 'particular', '\"'): 1, ('particular', '\"', '\"'): 1, ('\"', '\"', 'similar'): 1, ('\"', 'similar', 'to'): 1, ('similar', 'to', 'the'): 1, ('way', 'humans', 'intuitively'): 1, ('humans', 'intuitively', 'do'): 1, ('intuitively', 'do', 'in'): 1, ('do', 'in', 'order'): 1, ('in', 'order', 'to'): 1, ('order', 'to', 'eliminate'): 1, ('to', 'eliminate', 'noisy'): 1, ('eliminate', 'noisy', 'content.'): 1, ('noisy', 'content.', 'In'): 1, ('content.', 'In', 'this'): 1, ('In', 'this', 'paper,'): 4, ('paper,', 'we', 'describe'): 2, ('we', 'describe', 'a'): 2, ('describe', 'a', 'combination'): 1, ('a', 'combination', 'of'): 1, ('combination', 'of', 'HTML'): 1, ('of', 'HTML', 'DOM'): 1, ('HTML', 'DOM', 'analysis'): 1, ('DOM', 'analysis', 'and'): 1, ('analysis', 'and', 'Natural'): 1, ('and', 'Natural', 'Language'): 2, ('Processing', '(NLP)', 'techniques'): 2, ('(NLP)', 'techniques', 'for'): 1, ('techniques', 'for', 'automated'): 1, ('for', 'automated', 'extractions'): 1, ('automated', 'extractions', 'of'): 1, ('extractions', 'of', 'main'): 1, ('of', 'main', 'article'): 1, ('main', 'article', 'with'): 1, ('article', 'with', 'associated'): 1, ('with', 'associated', 'images'): 1, ('associated', 'images', 'from'): 1, ('images', 'from', 'web'): 1, ('from', 'web', 'pages.'): 1, ('web', 'pages.', '\"'): 1, ('pages.', '\"', 'Abstract--'): 1, ('\"', 'Abstract--', 'Natural'): 1, ('Abstract--', 'Natural', 'Language'): 1, ('Language', 'Processing', 'is'): 1, ('Processing', 'is', 'a'): 1, ('is', 'a', 'theoretically'): 1, ('a', 'theoretically', 'motivated'): 1, ('theoretically', 'motivated', 'range'): 1, ('motivated', 'range', 'of'): 1, ('range', 'of', 'computational'): 1, ('of', 'computational', 'techniques'): 1, ('computational', 'techniques', 'for'): 1, ('techniques', 'for', 'analysing'): 1, ('for', 'analysing', 'and'): 1, ('analysing', 'and', 'representing'): 1, ('and', 'representing', 'naturally'): 1, ('representing', 'naturally', 'occurring'): 1, ('naturally', 'occurring', 'texts'): 1, ('occurring', 'texts', 'at'): 1, ('texts', 'at', 'one'): 1, ('at', 'one', 'or'): 1, ('one', 'or', 'more'): 1, ('or', 'more', 'levels'): 1, ('more', 'levels', 'of'): 1, ('levels', 'of', 'linguistic'): 1, ('of', 'linguistic', 'analysis'): 1, ('linguistic', 'analysis', 'for'): 1, ('analysis', 'for', 'the'): 1, ('for', 'the', 'purpose'): 1, ('the', 'purpose', 'of'): 1, ('purpose', 'of', 'achieving'): 1, ('of', 'achieving', 'human-like'): 1, ('achieving', 'human-like', 'language'): 1, ('human-like', 'language', 'processing'): 1, ('language', 'processing', 'for'): 2, ('processing', 'for', 'a'): 1, ('for', 'a', 'range'): 1, ('a', 'range', 'of'): 1, ('range', 'of', 'tasks'): 1, ('of', 'tasks', '\"'): 1, ('tasks', '\"', 'This'): 1, ('This', 'paper', 'reviews'): 2, ('paper', 'reviews', 'the'): 2, ('reviews', 'the', 'processes'): 1, ('the', 'processes', 'involved'): 1, ('processes', 'involved', 'in'): 1, ('involved', 'in', 'Natural'): 1, ('in', 'Natural', 'Language'): 2, ('Language', 'Processing', '(NLP).'): 1, ('Processing', '(NLP).', 'It'): 1, ('(NLP).', 'It', 'then'): 1, ('It', 'then', 'demonstrates'): 1, ('then', 'demonstrates', 'the'): 1, ('demonstrates', 'the', 'various'): 1, ('the', 'various', 'kinds'): 1, ('various', 'kinds', 'of'): 1, ('kinds', 'of', 'choices'): 1, ('of', 'choices', 'that'): 1, ('choices', 'that', 'need'): 1, ('that', 'need', 'be'): 1, ('need', 'be', 'taken'): 1, ('be', 'taken', 'during'): 1, ('taken', 'during', 'the'): 1, ('during', 'the', 'execution'): 1, ('the', 'execution', 'of'): 1, ('execution', 'of', 'the'): 1, ('of', 'the', 'word'): 2, ('the', 'word', 'morphology,'): 1, ('word', 'morphology,', 'the'): 1, ('morphology,', 'the', 'syntactic'): 1, ('the', 'syntactic', 'text'): 1, ('syntactic', 'text', 'analysis,'): 1, ('text', 'analysis,', 'or'): 1, ('analysis,', 'or', 'text'): 1, ('or', 'text', 'generation'): 1, ('text', 'generation', 'components.'): 1, ('generation', 'components.', 'It'): 1, ('components.', 'It', 'compares'): 1, ('It', 'compares', 'the'): 1, ('compares', 'the', 'time'): 1, ('the', 'time', 'complexity'): 1, ('time', 'complexity', '\"'): 1, ('complexity', '\"', 'This'): 1, ('\"', 'This', 'article'): 1, ('This', 'article', 'focusses'): 1, ('article', 'focusses', 'on'): 1, ('focusses', 'on', 'the'): 1, ('on', 'the', 'derivation'): 1, ('the', 'derivation', 'of'): 1, ('derivation', 'of', 'large'): 1, ('of', 'large', 'lexicons'): 1, ('large', 'lexicons', 'for'): 1, ('lexicons', 'for', 'natural'): 1, ('processing.', 'We', 'describe'): 1, ('We', 'describe', 'the'): 2, ('describe', 'the', 'development'): 1, ('the', 'development', 'of'): 3, ('development', 'of', 'a'): 1, ('of', 'a', 'dictionary'): 1, ('a', 'dictionary', 'support'): 1, ('dictionary', 'support', 'environment'): 1, ('support', 'environment', 'linking'): 1, ('environment', 'linking', 'a'): 1, ('linking', 'a', 'restructured'): 1, ('a', 'restructured', 'version'): 1, ('restructured', 'version', 'of'): 1, ('version', 'of', 'the'): 1, ('of', 'the', 'Longman'): 1, ('the', 'Longman', 'Dictionary'): 1, ('Longman', 'Dictionary', 'of'): 1, ('Dictionary', 'of', 'Contemporary'): 1, ('of', 'Contemporary', 'English'): 1, ('Contemporary', 'English', 'to'): 1, ('English', 'to', 'natural'): 1, ('to', 'natural', 'language'): 2, ('language', 'processing', 'systems.'): 2, ('processing', 'systems.', 'The'): 2, ('systems.', 'The', 'process'): 1, ('The', 'process', '\"'): 1, ('process', '\"', 'We'): 1, ('\"', 'We', 'introduce'): 1, ('We', 'introduce', 'a'): 1, ('introduce', 'a', 'method'): 1, ('method', 'for', 'analyzing'): 1, ('for', 'analyzing', 'the'): 1, ('analyzing', 'the', 'complexity'): 1, ('the', 'complexity', 'of'): 1, ('complexity', 'of', 'natural'): 1, ('language', 'processing', 'tasks,'): 1, ('processing', 'tasks,', 'and'): 1, ('tasks,', 'and', 'for'): 1, ('and', 'for', 'predicting'): 1, ('for', 'predicting', 'the'): 1, ('predicting', 'the', 'difficulty'): 1, ('the', 'difficulty', 'new'): 1, ('difficulty', 'new', 'NLP'): 1, ('new', 'NLP', 'tasks.'): 1, ('NLP', 'tasks.', 'Our'): 1, ('tasks.', 'Our', 'complexity'): 1, ('Our', 'complexity', 'measures'): 1, ('complexity', 'measures', 'are'): 1, ('measures', 'are', 'derived'): 1, ('are', 'derived', 'from'): 1, ('derived', 'from', 'the'): 1, ('from', 'the', 'Kolmogorov'): 1, ('the', 'Kolmogorov', 'complexity'): 1, ('Kolmogorov', 'complexity', 'of'): 1, ('complexity', 'of', 'a'): 1, ('of', 'a', 'class'): 1, ('a', 'class', 'of'): 1, ('class', 'of', 'automata'): 1, ('of', 'automata', 'â\\x80\\x94'): 1, ('automata', 'â\\x80\\x94', 'meaning'): 1, ('â\\x80\\x94', 'meaning', 'automata,'): 1, ('meaning', 'automata,', 'whose'): 1, ('automata,', 'whose', 'purpose'): 1, ('whose', 'purpose', 'is'): 1, ('purpose', 'is', 'to'): 1, ('is', 'to', 'extract'): 1, ('to', 'extract', 'relevant'): 1, ('extract', 'relevant', 'pieces'): 1, ('relevant', 'pieces', '\"'): 1, ('pieces', '\"', '\"'): 1, ('\"', '\"', ','): 1, ('\"', ',', 'sounds,'): 1, (',', 'sounds,', 'text'): 1, ('sounds,', 'text', 'and'): 1, ('text', 'and', 'motion.'): 1, ('and', 'motion.', 'The'): 1, ('motion.', 'The', 'techniques'): 1, ('The', 'techniques', 'developed'): 1, ('techniques', 'developed', 'from'): 1, ('developed', 'from', 'deep'): 1, ('from', 'deep', 'learning'): 1, ('deep', 'learning', 'research'): 1, ('learning', 'research', 'have'): 1, ('research', 'have', 'already'): 1, ('have', 'already', 'been'): 1, ('already', 'been', 'impacting'): 1, ('been', 'impacting', 'the'): 1, ('impacting', 'the', 'research'): 1, ('the', 'research', 'of'): 1, ('research', 'of', 'natural'): 1, ('natural', 'language', 'process.'): 1, ('language', 'process.', 'This'): 1, ('process.', 'This', 'paper'): 1, ('reviews', 'the', 'recent'): 1, ('the', 'recent', 'research'): 1, ('recent', 'research', 'on'): 1, ('research', 'on', 'deep'): 1, ('on', 'deep', 'learning,'): 1, ('deep', 'learning,', 'its'): 1, ('learning,', 'its', 'applications'): 1, ('its', 'applications', 'and'): 1, ('applications', 'and', 'recent'): 1, ('and', 'recent', 'development'): 1, ('recent', 'development', 'in'): 2, ('development', 'in', 'natural'): 1, ('language', 'processing.', '1'): 1, ('processing.', '1', '\"'): 1, ('1', '\"', 'This'): 1, ('\"', 'This', 'is'): 1, ('This', 'is', 'an'): 1, ('is', 'an', 'author-produced'): 1, ('an', 'author-produced', 'version'): 1, ('author-produced', 'version', 'of'): 1, ('version', 'of', 'a'): 1, ('of', 'a', 'paper'): 1, ('a', 'paper', 'published'): 1, ('paper', 'published', 'in'): 1, ('published', 'in', 'The'): 1, ('in', 'The', '\"'): 1, ('The', '\"', 'Abstractâ\\x80\\x94Natural'): 1, ('\"', 'Abstractâ\\x80\\x94Natural', 'language'): 1, ('Abstractâ\\x80\\x94Natural', 'language', 'processing'): 1, ('processing', '(NLP)', 'is'): 1, ('(NLP)', 'is', 'the'): 1, ('is', 'the', 'application'): 1, ('the', 'application', 'of'): 4, ('application', 'of', 'automated'): 1, ('of', 'automated', 'parsing'): 1, ('automated', 'parsing', 'and'): 1, ('parsing', 'and', 'machine'): 1, ('and', 'machine', 'learning'): 1, ('machine', 'learning', 'techniques'): 2, ('learning', 'techniques', 'to'): 1, ('techniques', 'to', 'analyze'): 1, ('to', 'analyze', 'standard'): 1, ('analyze', 'standard', 'text.'): 1, ('standard', 'text.', 'Applications'): 1, ('text.', 'Applications', 'of'): 1, ('Applications', 'of', 'NLP'): 1, ('of', 'NLP', 'to'): 2, ('NLP', 'to', 'requirements'): 1, ('to', 'requirements', 'engineering'): 1, ('requirements', 'engineering', 'include'): 1, ('engineering', 'include', 'extraction'): 1, ('include', 'extraction', 'of'): 1, ('extraction', 'of', 'ontologies'): 1, ('of', 'ontologies', 'from'): 1, ('ontologies', 'from', 'a'): 1, ('from', 'a', 'requirements'): 1, ('a', 'requirements', 'specification,'): 1, ('requirements', 'specification,', 'and'): 1, ('specification,', 'and', 'use'): 1, ('and', 'use', 'of'): 2, ('use', 'of', 'NLP'): 1, ('NLP', 'to', 'verify'): 1, ('to', 'verify', 'the'): 1, ('verify', 'the', 'consistency'): 1, ('the', 'consistency', '\"'): 1, ('consistency', '\"', 'statistical'): 1, ('\"', 'statistical', 'baseline'): 1, ('statistical', 'baseline', 'including:'): 1, ('baseline', 'including:', 'the'): 1, ('including:', 'the', 'forgiving'): 1, ('the', 'forgiving', 'nature'): 1, ('forgiving', 'nature', 'but'): 1, ('nature', 'but', 'broad'): 1, ('but', 'broad', 'coverage'): 1, ('broad', 'coverage', 'of'): 1, ('coverage', 'of', 'the'): 1, ('of', 'the', 'typical'): 1, ('the', 'typical', 'retrieval'): 1, ('typical', 'retrieval', 'task;'): 1, ('retrieval', 'task;', 'the'): 1, ('task;', 'the', 'lack'): 1, ('the', 'lack', 'of'): 1, ('lack', 'of', 'good'): 1, ('of', 'good', 'weighting'): 1, ('good', 'weighting', 'schemes'): 1, ('weighting', 'schemes', 'for'): 1, ('schemes', 'for', 'compound'): 1, ('for', 'compound', 'index'): 1, ('compound', 'index', 'terms;'): 1, ('index', 'terms;', 'and'): 1, ('terms;', 'and', 'the'): 1, ('and', 'the', 'implicit'): 1, ('the', 'implicit', 'linguistic'): 1, ('implicit', 'linguistic', 'processing'): 1, ('linguistic', 'processing', 'inherent'): 1, ('processing', 'inherent', 'in'): 1, ('inherent', 'in', 'the'): 1, ('in', 'the', 'statistical'): 1, ('the', 'statistical', 'methods.'): 1, ('statistical', 'methods.', 'Natural'): 1, ('methods.', 'Natural', 'language'): 1, ('language', 'processing', 'techniques'): 2, ('processing', 'techniques', 'may'): 1, ('techniques', 'may', 'be'): 1, ('may', 'be', 'more'): 1, ('be', 'more', 'important'): 1, ('more', 'important', '\"'): 1, ('important', '\"', 'Work'): 1, ('\"', 'Work', 'in'): 1, ('Work', 'in', 'computational'): 1, ('in', 'computational', 'linguistics'): 2, ('computational', 'linguistics', 'began'): 1, ('linguistics', 'began', 'very'): 1, ('began', 'very', 'soon'): 1, ('very', 'soon', 'after'): 1, ('soon', 'after', 'the'): 1, ('after', 'the', 'development'): 1, ('development', 'of', 'the'): 2, ('of', 'the', 'first'): 1, ('the', 'first', 'computers'): 1, ('first', 'computers', '(Booth,'): 1, ('computers', '(Booth,', 'Brandwood'): 1, ('(Booth,', 'Brandwood', 'and'): 1, ('Brandwood', 'and', 'Cleave'): 1, ('and', 'Cleave', '1958),'): 1, ('Cleave', '1958),', 'yet'): 1, ('1958),', 'yet', 'in'): 1, ('yet', 'in', 'the'): 1, ('in', 'the', 'intervening'): 1, ('the', 'intervening', 'four'): 1, ('intervening', 'four', 'decades'): 1, ('four', 'decades', 'there'): 1, ('decades', 'there', 'has'): 1, ('there', 'has', 'been'): 1, ('has', 'been', 'a'): 1, ('been', 'a', 'pervasive'): 1, ('a', 'pervasive', 'feeling'): 1, ('pervasive', 'feeling', 'that'): 1, ('feeling', 'that', 'progress'): 1, ('that', 'progress', 'in'): 1, ('progress', 'in', 'computer'): 1, ('in', 'computer', 'understanding'): 1, ('computer', 'understanding', 'of'): 1, ('understanding', 'of', 'natural'): 1, ('natural', 'language', 'has'): 1, ('language', 'has', 'not'): 1, ('has', 'not', 'been'): 1, ('not', 'been', 'commensurate'): 1, ('been', 'commensurate', '\"'): 1, ('commensurate', '\"', 'the'): 1, ('\"', 'the', 'voice'): 1, ('the', 'voice', 'recognition'): 1, ('voice', 'recognition', 'for'): 1, ('recognition', 'for', 'a'): 1, ('for', 'a', 'natural'): 1, ('a', 'natural', 'language'): 2, ('natural', 'language', '(Tamil)'): 1, ('language', '(Tamil)', 'by'): 1, ('(Tamil)', 'by', 'combining'): 1, ('by', 'combining', 'the'): 1, ('combining', 'the', 'digital'): 1, ('the', 'digital', 'and'): 1, ('digital', 'and', 'mathematical'): 1, ('and', 'mathematical', 'knowledge'): 1, ('mathematical', 'knowledge', 'using'): 1, ('knowledge', 'using', 'MFCC'): 1, ('using', 'MFCC', 'and'): 1, ('MFCC', 'and', 'DTW'): 1, ('and', 'DTW', 'to'): 1, ('DTW', 'to', 'extract'): 1, ('to', 'extract', 'and'): 1, ('extract', 'and', 'match'): 1, ('and', 'match', 'the'): 1, ('match', 'the', 'features'): 1, ('the', 'features', 'to'): 1, ('features', 'to', 'improve'): 1, ('to', 'improve', 'the'): 1, ('improve', 'the', 'accuracy'): 1, ('the', 'accuracy', 'for'): 1, ('accuracy', 'for', 'better'): 1, ('for', 'better', 'performance.'): 1, ('better', 'performance.', 'Abstract:'): 1, ('performance.', 'Abstract:', 'Testing'): 1, ('Abstract:', 'Testing', 'against'): 1, ('Testing', 'against', 'natural'): 1, ('against', 'natural', 'language'): 1, ('natural', 'language', 'requirements'): 1, ('language', 'requirements', 'is'): 1, ('requirements', 'is', 'the'): 1, ('is', 'the', 'standard'): 1, ('the', 'standard', 'approach'): 1, ('standard', 'approach', 'for'): 1, ('approach', 'for', 'system'): 1, ('for', 'system', 'and'): 1, ('system', 'and', 'acceptance'): 1, ('and', 'acceptance', 'testing.'): 1, ('acceptance', 'testing.', 'This'): 1, ('testing.', 'This', 'test'): 1, ('This', 'test', 'is'): 1, ('test', 'is', 'often'): 1, ('is', 'often', 'performed'): 1, ('often', 'performed', 'by'): 1, ('performed', 'by', 'an'): 1, ('by', 'an', 'independent'): 1, ('an', 'independent', 'test'): 1, ('independent', 'test', 'organization'): 1, ('test', 'organization', 'unfamiliar'): 1, ('organization', 'unfamiliar', 'with'): 1, ('unfamiliar', 'with', 'the'): 1, ('with', 'the', 'application'): 1, ('the', 'application', 'area.'): 1, ('application', 'area.', 'The'): 1, ('area.', 'The', 'only'): 1, ('The', 'only', 'things'): 1, ('only', 'things', 'the'): 1, ('things', 'the', 'testers'): 1, ('the', 'testers', 'have'): 1, ('testers', 'have', 'to'): 1, ('have', 'to', 'go'): 1, ('to', 'go', 'by'): 1, ('go', 'by', 'are'): 1, ('by', 'are', 'the'): 1, ('are', 'the', 'written'): 1, ('the', 'written', 'requirements.'): 1, ('written', 'requirements.', 'So'): 1, ('requirements.', 'So', 'Abstract'): 1, ('So', 'Abstract', 'not'): 1, ('found', '\"', 'conversational'): 1, ('\"', 'conversational', 'partners.'): 1, ('conversational', 'partners.', 'But'): 1, ('partners.', 'But', 'it'): 1, ('But', 'it', 'also'): 1, ('it', 'also', 'provides'): 1, ('also', 'provides', 'us'): 1, ('provides', 'us', 'with'): 1, ('us', 'with', 'information'): 1, ('with', 'information', 'about'): 1, ('information', 'about', 'being'): 1, ('about', 'being', 'creative,'): 1, ('being', 'creative,', 'making'): 1, ('creative,', 'making', 'associations,'): 1, ('making', 'associations,', 'storytelling'): 1, ('associations,', 'storytelling', 'and'): 1, ('storytelling', 'and', 'language'): 1, ('and', 'language', 'use.'): 1, ('language', 'use.', 'Many'): 1, ('use.', 'Many', 'more'): 1, ('Many', 'more', 'subtleties'): 1, ('more', 'subtleties', 'in'): 1, ('subtleties', 'in', 'face-to-face'): 1, ('in', 'face-to-face', 'and'): 1, ('face-to-face', 'and', 'multiparty'): 1, ('and', 'multiparty', 'interaction'): 1, ('multiparty', 'interaction', 'can'): 1, ('interaction', 'can', 'be'): 1, ('can', 'be', 'added,'): 1, ('be', 'added,', 'such'): 1, ('added,', 'such', 'as'): 1, ('such', 'as', 'using'): 1, ('as', 'using', 'humor'): 1, ('using', 'humor', 'to'): 1, ('humor', 'to', 'persuade'): 1, ('to', 'persuade', 'and'): 1, ('persuade', 'and', 'dominate,'): 1, ('and', 'dominate,', 'to'): 1, ('dominate,', 'to', 'soften'): 1, ('to', 'soften', 'or'): 1, ('soften', 'or', 'avoid'): 1, ('or', 'avoid', 'a'): 1, ('avoid', 'a', 'face'): 1, ('a', 'face', 'threatening'): 1, ('face', 'threatening', 'act'): 1, ('threatening', 'act', '\"'): 1, ('act', '\"', 'Abstract'): 1, ('\"', 'Abstract', 'not'): 3, ('found', '\"', 'In'): 1, ('\"', 'In', 'recent'): 1, ('In', 'recent', 'years,'): 1, ('recent', 'years,', 'machine'): 1, ('years,', 'machine', 'learning'): 1, ('machine', 'learning', '(ML)'): 1, ('learning', '(ML)', 'has'): 1, ('(ML)', 'has', 'been'): 1, ('has', 'been', 'used'): 1, ('been', 'used', 'more'): 1, ('used', 'more', 'and'): 1, ('more', 'and', 'more'): 1, ('and', 'more', 'to'): 1, ('more', 'to', 'solve'): 1, ('to', 'solve', 'complex'): 1, ('solve', 'complex', 'tasks'): 1, ('complex', 'tasks', 'in'): 1, ('tasks', 'in', 'different'): 1, ('in', 'different', 'disciplines,'): 1, ('different', 'disciplines,', 'ranging'): 1, ('disciplines,', 'ranging', 'from'): 1, ('ranging', 'from', 'Data'): 1, ('from', 'Data', 'Mining'): 1, ('Data', 'Mining', 'to'): 1, ('Mining', 'to', 'Information'): 1, ('to', 'Information', '\"'): 1, ('Information', '\"', '\"'): 1, ('\"', 'We', 'argue'): 1, ('We', 'argue', 'that'): 1, ('argue', 'that', 'manual'): 1, ('that', 'manual', 'and'): 1, ('manual', 'and', 'automatic'): 1, ('and', 'automatic', 'thesauruses'): 1, ('automatic', 'thesauruses', 'are'): 1, ('thesauruses', 'are', 'alternative'): 1, ('are', 'alternative', 'resources'): 1, ('alternative', 'resources', 'for'): 1, ('resources', 'for', 'the'): 1, ('for', 'the', 'same'): 1, ('the', 'same', 'NLP'): 1, ('same', 'NLP', 'tasks.'): 1, ('NLP', 'tasks.', 'This'): 1, ('tasks.', 'This', 'involves'): 1, ('This', 'involves', 'the'): 1, ('involves', 'the', 'radical'): 1, ('the', 'radical', 'step'): 1, ('radical', 'step', 'of'): 1, ('step', 'of', 'interpreting'): 1, ('of', 'interpreting', 'manual'): 1, ('interpreting', 'manual', 'thesauruses'): 1, ('manual', 'thesauruses', 'as'): 1, ('thesauruses', 'as', 'classifications'): 1, ('as', 'classifications', 'of'): 1, ('classifications', 'of', 'words'): 1, ('of', 'words', 'rather'): 1, ('words', 'rather', 'than'): 1, ('rather', 'than', 'word'): 1, ('than', 'word', 'senses:'): 1, ('word', 'senses:', 'the'): 1, ('senses:', 'the', 'case'): 1, ('the', 'case', 'for'): 1, ('case', 'for', 'this'): 1, ('for', 'this', 'is'): 1, ('this', 'is', 'made.'): 1, ('is', 'made.', 'The'): 1, ('made.', 'The', 'range'): 1, ('The', 'range', 'of'): 1, ('range', 'of', 'roles'): 1, ('of', 'roles', 'for'): 1, ('roles', 'for', 'thesauruses'): 1, ('for', 'thesauruses', 'within'): 1, ('thesauruses', 'within', 'NLP'): 1, ('within', 'NLP', 'is'): 1, ('NLP', 'is', 'briefly'): 1, ('is', 'briefly', 'presented'): 1, ('briefly', 'presented', 'and'): 1, ('presented', 'and', 'the'): 1, ('and', 'the', 'WASPS'): 1, ('the', 'WASPS', 'thesaurus'): 1, ('WASPS', 'thesaurus', 'is'): 1, ('thesaurus', 'is', 'introduced.'): 1, ('is', 'introduced.', 'Thesaurus'): 1, ('introduced.', 'Thesaurus', 'evaluation'): 1, ('Thesaurus', 'evaluation', 'is'): 1, ('evaluation', 'is', 'now'): 1, ('is', 'now', 'becoming'): 1, ('now', 'becoming', 'urgent.'): 1, ('becoming', 'urgent.', 'A'): 1, ('urgent.', 'A', 'range'): 1, ('A', 'range', 'of'): 1, ('range', 'of', 'evaluation'): 1, ('of', 'evaluation', 'strategies,'): 1, ('evaluation', 'strategies,', 'all'): 1, ('strategies,', 'all', 'embedded'): 1, ('all', 'embedded', 'within'): 1, ('embedded', 'within', 'NLP'): 1, ('within', 'NLP', 'tasks,'): 1, ('NLP', 'tasks,', 'is'): 1, ('tasks,', 'is', 'proposed.'): 1, ('is', 'proposed.', '\"'): 1, ('proposed.', '\"', '\"'): 1, ('\"', '\"', 'Introduction'): 1, ('\"', 'Introduction', 'Patterns'): 1, ('Introduction', 'Patterns', 'in'): 1, ('Patterns', 'in', 'music'): 1, ('in', 'music', 'have'): 1, ('music', 'have', 'been'): 1, ('have', 'been', 'the'): 1, ('been', 'the', 'object'): 1, ('the', 'object', 'of'): 1, ('object', 'of', 'intensive'): 1, ('of', 'intensive', 'studies'): 1, ('intensive', 'studies', 'in'): 1, ('studies', 'in', 'the'): 1, ('in', 'the', 'past'): 1, ('the', 'past', 'years.'): 1, ('past', 'years.', '\\\\One'): 1, ('years.', '\\\\One', 'of'): 1, ('\\\\One', 'of', 'the'): 1, ('of', 'the', 'purposes'): 1, ('the', 'purposes', 'of'): 1, ('purposes', 'of', 'analyzing'): 1, ('of', 'analyzing', 'musical'): 1, ('analyzing', 'musical', 'structure'): 1, ('musical', 'structure', 'and'): 1, ('structure', 'and', 'form'): 1, ('and', 'form', 'is'): 1, ('form', 'is', 'to'): 1, ('is', 'to', 'discover'): 1, ('to', 'discover', 'the'): 1, ('discover', 'the', 'patterns'): 1, ('the', 'patterns', 'that'): 1, ('patterns', 'that', 'are'): 1, ('that', 'are', 'explicit'): 1, ('are', 'explicit', 'or'): 1, ('explicit', 'or', 'implicit'): 1, ('or', 'implicit', 'in'): 1, ('implicit', 'in', 'musical'): 1, ('in', 'musical', 'works\"\"'): 1, ('musical', 'works\"\"', 'Simon'): 1, ('works\"\"', 'Simon', '[13].'): 1, ('Simon', '[13].', 'Patterns'): 1, ('[13].', 'Patterns', 'comprise'): 1, ('Patterns', 'comprise', 'periodicity,'): 1, ('comprise', 'periodicity,', 'make'): 1, ('periodicity,', 'make', 'use'): 1, ('make', 'use', 'of'): 1, ('use', 'of', 'alphabets,'): 1, ('of', 'alphabets,', 'can'): 1, ('alphabets,', 'can', 'be'): 1, ('can', 'be', 'compound'): 1, ('be', 'compound', '(made'): 1, ('compound', '(made', 'up'): 1, ('(made', 'up', 'of'): 1, ('up', 'of', 'subpatterns)'): 1, ('of', 'subpatterns)', 'and'): 1, ('subpatterns)', 'and', 'possess'): 1, ('and', 'possess', 'phrase'): 1, ('possess', 'phrase', 'structure'): 1, ('phrase', 'structure', 'with'): 1, ('structure', 'with', 'various'): 1, ('with', 'various', 'forms'): 1, ('various', 'forms', 'of'): 1, ('forms', 'of', 'punctuation.'): 1, ('of', 'punctuation.', 'Traditionally,'): 1, ('punctuation.', 'Traditionally,', 'composers'): 1, ('Traditionally,', 'composers', 'have'): 1, ('composers', 'have', 'employed'): 1, ('have', 'employed', 'pattern'): 1, ('employed', 'pattern', 'propagation'): 1, ('pattern', 'propagation', 'intuitively,'): 1, ('propagation', 'intuitively,', 'but'): 1, ('intuitively,', 'but', 'algorithmic'): 1, ('but', 'algorithmic', 'composition'): 1, ('algorithmic', 'composition', 'techniques'): 1, ('composition', 'techniques', 'allow'): 1, ('techniques', 'allow', 'the'): 1, ('allow', 'the', 'pattern'): 1, ('the', 'pattern', 'propagation'): 1, ('pattern', 'propagation', 'to'): 1, ('propagation', 'to', 'be'): 1, ('to', 'be', 'formalized,'): 1, ('be', 'formalized,', 'albeit'): 1, ('formalized,', 'albeit', 'a'): 1, ('albeit', 'a', 'high'): 1, ('a', 'high', 'level.'): 1, ('high', 'level.', 'During'): 1, ('level.', 'During', 'composition,'): 1, ('During', 'composition,', 'all'): 1, ('composition,', 'all', 'the'): 1, ('all', 'the', 'musical'): 1, ('the', 'musical', 'patterns'): 1, ('musical', 'patterns', 'evolve'): 1, ('patterns', 'evolve', 'according'): 1, ('evolve', 'according', 'to'): 1, ('according', 'to', 'the'): 1, ('to', 'the', 'rules'): 1, ('the', 'rules', 'and'): 1, ('rules', 'and', 'constraints'): 1, ('and', 'constraints', 'specied'): 1, ('constraints', 'specied', 'at'): 1, ('specied', 'at', 'the'): 1, ('at', 'the', 'design'): 1, ('the', 'design', 'stage.'): 1, ('design', 'stage.', 'In'): 1, ('stage.', 'In', 'jazz'): 1, ('In', 'jazz', 'improvisation,'): 1, ('jazz', 'improvisation,', 'the'): 1, ('improvisation,', 'the', 'musician'): 1, ('the', 'musician', 'invents'): 1, ('musician', 'invents', 'a'): 1, ('invents', 'a', 'solo'): 1, ('a', 'solo', 'guided'): 1, ('solo', 'guided', 'by'): 1, ('guided', 'by', 'a'): 1, ('by', 'a', 'progression'): 1, ('a', 'progression', 'of'): 1, ('progression', 'of', 'chords'): 1, ('of', 'chords', '(the'): 1, ('chords', '(the', 'changes).'): 1, ('(the', 'changes).', 'One'): 1, ('changes).', 'One', 'approach'): 1, ('One', 'approach', '[1]'): 1, ('approach', '[1]', 'to'): 1, ('[1]', 'to', 'learn'): 1, ('to', 'learn', 'improvising'): 1, ('learn', 'improvising', 'is'): 1, ('improvising', 'is', 'to'): 1, ('is', 'to', 'memorize'): 1, ('to', 'memorize', 'patterns'): 1, ('memorize', 'patterns', '(short'): 1, ('patterns', '(short', 'chunks'): 1, ('(short', 'chunks', 'of'): 1, ('chunks', 'of', 'music)'): 1, ('of', 'music)', 'that'): 1, ('music)', 'that', 't'): 1, ('that', 't', 'sub-progressions,'): 1, ('t', 'sub-progressions,', 'and'): 1, ('sub-progressions,', 'and', 'to'): 1, ('and', 'to', 'concatenate'): 1, ('to', 'concatenate', 'them'): 1, ('concatenate', 'them', 'to'): 1, ('them', 'to', 'form'): 1, ('to', 'form', 'a'): 1, ('form', 'a', 'whole'): 1, ('a', 'whole', 'solo'): 1, ('whole', 'solo', 'that'): 1, ('solo', 'that', 'ts'): 1, ('that', 'ts', 'a'): 1, ('ts', 'a', 'whole'): 1, ('a', 'whole', 'progression.'): 1, ('whole', 'progression.', 'One'): 1, ('progression.', 'One', '\"'): 1, ('One', '\"', '\"'): 1, ('\"', '\"', 'Abstract'): 1, ('\"', 'Abstract', 'Many'): 1, ('Abstract', 'Many', 'information'): 1, ('Many', 'information', 'retrieval(IR)'): 1, ('information', 'retrieval(IR)', 'systems'): 1, ('retrieval(IR)', 'systems', 'retrieve'): 1, ('systems', 'retrieve', 'relevant'): 1, ('retrieve', 'relevant', 'documents'): 1, ('relevant', 'documents', 'based'): 1, ('documents', 'based', 'on'): 1, ('based', 'on', 'exact'): 1, ('on', 'exact', 'matching'): 1, ('exact', 'matching', 'of'): 1, ('matching', 'of', 'keywords'): 1, ('of', 'keywords', 'between'): 1, ('keywords', 'between', 'a'): 1, ('between', 'a', 'query'): 1, ('a', 'query', 'and'): 1, ('query', 'and', 'documents.'): 1, ('and', 'documents.', 'This'): 1, ('documents.', 'This', 'method'): 1, ('This', 'method', 'degrades'): 1, ('method', 'degrades', 'precision'): 1, ('degrades', 'precision', 'rate.'): 1, ('precision', 'rate.', 'In'): 1, ('rate.', 'In', 'order'): 1, ('In', 'order', 'to'): 1, ('order', 'to', 'solve'): 1, ('to', 'solve', 'the'): 1, ('solve', 'the', 'problem,'): 1, ('the', 'problem,', 'we'): 1, ('problem,', 'we', 'collected'): 1, ('we', 'collected', 'semantically'): 1, ('collected', 'semantically', 'related'): 1, ('semantically', 'related', 'words'): 1, ('related', 'words', 'and'): 1, ('words', 'and', 'assigned'): 1, ('and', 'assigned', 'semantic'): 1, ('assigned', 'semantic', 'relationships'): 1, ('semantic', 'relationships', 'used'): 1, ('relationships', 'used', 'in'): 1, ('used', 'in', 'general'): 1, ('in', 'general', 'thesaurus'): 1, ('general', 'thesaurus', 'and'): 1, ('thesaurus', 'and', 'a'): 1, ('and', 'a', 'special'): 1, ('a', 'special', 'relationship'): 1, ('special', 'relationship', 'called'): 1, ('relationship', 'called', 'keyfact'): 1, ('called', 'keyfact', 'term(FT)'): 1, ('keyfact', 'term(FT)', 'manually.'): 1, ('term(FT)', 'manually.', 'In'): 1, ('manually.', 'In', 'addition'): 1, ('In', 'addition', 'to'): 1, ('addition', 'to', 'the'): 1, ('to', 'the', 'semantic'): 1, ('the', 'semantic', 'knowledge,'): 1, ('semantic', 'knowledge,', 'we'): 1, ('knowledge,', 'we', 'automatically'): 1, ('we', 'automatically', 'constructed'): 1, ('automatically', 'constructed', 'statistic'): 1, ('constructed', 'statistic', 'knowledge'): 1, ('statistic', 'knowledge', 'based'): 1, ('knowledge', 'based', 'on'): 1, ('on', 'the', 'concept'): 1, ('the', 'concept', 'of'): 1, ('concept', 'of', 'mutual'): 1, ('of', 'mutual', 'information.'): 1, ('mutual', 'information.', 'Keyfact'): 1, ('information.', 'Keyfact', 'is'): 1, ('Keyfact', 'is', 'an'): 1, ('is', 'an', 'extended'): 1, ('an', 'extended', 'concept'): 1, ('extended', 'concept', 'of'): 1, ('concept', 'of', 'keyword'): 1, ('of', 'keyword', 'represented'): 1, ('keyword', 'represented', 'by'): 1, ('represented', 'by', 'noun'): 1, ('by', 'noun', 'and'): 1, ('noun', 'and', 'compound'): 1, ('and', 'compound', 'noun.'): 1, ('compound', 'noun.', 'Keyfact'): 1, ('noun.', 'Keyfact', 'can'): 1, ('Keyfact', 'can', 'be'): 1, ('can', 'be', 'a'): 1, ('be', 'a', 'verb'): 1, ('a', 'verb', 'and'): 1, ('verb', 'and', 'an'): 1, ('and', 'an', 'adjective'): 1, ('an', 'adjective', 'including'): 1, ('adjective', 'including', 'subject'): 1, ('including', 'subject', 'or'): 1, ('subject', 'or', 'object'): 1, ('or', 'object', 'term.'): 1, ('object', 'term.', 'We'): 1, ('term.', 'We', 'first'): 1, ('We', 'first', 'retrieved'): 1, ('first', 'retrieved', 'relevant'): 1, ('retrieved', 'relevant', 'documents'): 1, ('relevant', 'documents', 'with'): 1, ('documents', 'with', 'original'): 1, ('with', 'original', 'query'): 1, ('original', 'query', 'using'): 1, ('query', 'using', 'tf'): 1, ('using', 'tf', '*'): 1, ('tf', '*', 'idf'): 1, ('*', 'idf', 'weighting'): 1, ('idf', 'weighting', 'formula'): 1, ('weighting', 'formula', 'and'): 1, ('formula', 'and', 'then'): 1, ('and', 'then', 'an'): 1, ('then', 'an', 'expanded'): 1, ('an', 'expanded', 'query'): 1, ('expanded', 'query', 'including'): 1, ('query', 'including', 'keyfacts'): 1, ('including', 'keyfacts', 'is'): 1, ('keyfacts', 'is', 'used'): 1, ('is', 'used', 'in'): 1, ('used', 'in', 'both'): 1, ('in', 'both', 'second'): 1, ('both', 'second', 'document'): 1, ('second', 'document', 'ranking'): 1, ('document', 'ranking', 'and'): 1, ('ranking', 'and', 'word'): 1, ('and', 'word', 'sense'): 1, ('word', 'sense', 'disambiguating.'): 1, ('sense', 'disambiguating.', 'So'): 1, ('disambiguating.', 'So', 'we'): 1, ('So', 'we', 'made'): 1, ('we', 'made', 'an'): 1, ('made', 'an', 'improvement'): 1, ('an', 'improvement', 'in'): 1, ('improvement', 'in', 'precision'): 1, ('in', 'precision', 'rate'): 1, ('precision', 'rate', 'using'): 1, ('rate', 'using', 'keyfact'): 1, ('using', 'keyfact', 'network.'): 1, ('keyfact', 'network.', '1'): 1, ('network.', '1', '\"'): 1, ('this', 'paper', 'we'): 2, ('paper', 'we', 'argue'): 1, ('we', 'argue', 'that'): 1, ('argue', 'that', 'questionanswering'): 1, ('that', 'questionanswering', '(QA)'): 1, ('questionanswering', '(QA)', 'over'): 1, ('(QA)', 'over', 'technical'): 1, ('over', 'technical', 'domains'): 1, ('technical', 'domains', 'is'): 1, ('domains', 'is', 'distinctly'): 1, ('is', 'distinctly', 'different'): 1, ('distinctly', 'different', 'from'): 1, ('different', 'from', 'TREC-based'): 1, ('from', 'TREC-based', 'QA'): 1, ('TREC-based', 'QA', 'or'): 1, ('QA', 'or', 'Web-based'): 1, ('or', 'Web-based', 'QA'): 1, ('Web-based', 'QA', 'and'): 1, ('QA', 'and', 'it'): 1, ('and', 'it', 'cannot'): 1, ('it', 'cannot', 'benefit'): 1, ('cannot', 'benefit', 'lom'): 1, ('benefit', 'lom', 'data-intensive'): 1, ('lom', 'data-intensive', 'approaches'): 1, ('data-intensive', 'approaches', 'Universit&quot;at'): 1, ('approaches', 'Universit&quot;at', 'des'): 1, ('Universit&quot;at', 'des', 'Saarlandes'): 1, ('des', 'Saarlandes', 'Proceedings'): 1, ('Saarlandes', 'Proceedings', 'of'): 1, ('Proceedings', 'of', 'the'): 1, ('of', 'the', 'Workshop'): 1, ('the', 'Workshop', 'on'): 1, ('Workshop', 'on', 'uni-hamburg.de'): 1, ('on', 'uni-hamburg.de', 'Abstract'): 1, ('uni-hamburg.de', 'Abstract', 'not'): 1, ('not', 'found', 'Abstract'): 1, ('found', 'Abstract', 'not'): 1, ('not', 'found', 'SRI'): 1, ('found', 'SRI', 'has'): 1, ('SRI', 'has', 'developed'): 1, ('has', 'developed', 'a'): 1, ('developed', 'a', 'new'): 1, ('a', 'new', 'architecture'): 1, ('new', 'architecture', 'for'): 1, ('architecture', 'for', 'integrating'): 1, ('for', 'integrating', 'speech'): 1, ('integrating', 'speech', 'and'): 1, ('speech', 'and', 'natural-language'): 1, ('and', 'natural-language', 'processing'): 1, ('natural-language', 'processing', 'that'): 1, ('processing', 'that', 'applies'): 1, ('that', 'applies', 'linguistic'): 1, ('applies', 'linguistic', 'constraints'): 1, ('linguistic', 'constraints', 'during'): 1, ('constraints', 'during', 'recognition'): 1, ('during', 'recognition', 'by'): 1, ('recognition', 'by', 'incrementally'): 1, ('by', 'incrementally', 'expanding'): 1, ('incrementally', 'expanding', 'the'): 1, ('expanding', 'the', 'state-transition'): 1, ('the', 'state-transition', 'network'): 1, ('state-transition', 'network', 'embodied'): 1, ('network', 'embodied', 'in'): 1, ('embodied', 'in', 'a'): 1, ('in', 'a', 'unification'): 1, ('a', 'unification', 'grammar.'): 1, ('unification', 'grammar.', 'We'): 1, ('grammar.', 'We', 'compare'): 1, ('We', 'compare', 'this'): 1, ('compare', 'this', 'dynamic-gralnlnar-network'): 1, ('this', 'dynamic-gralnlnar-network', '(DGN)'): 1, ('dynamic-gralnlnar-network', '(DGN)', 'approach'): 1, ('(DGN)', 'approach', 'This'): 1, ('approach', 'This', 'chapter'): 1, ('This', 'chapter', 'considers'): 1, ('chapter', 'considers', 'the'): 1, ('considers', 'the', 'revolution'): 1, ('the', 'revolution', 'that'): 1, ('revolution', 'that', 'has'): 1, ('that', 'has', 'taken'): 1, ('has', 'taken', 'place'): 1, ('taken', 'place', 'in'): 1, ('place', 'in', 'natural'): 1, ('language', 'processing', 'research'): 1, ('processing', 'research', 'over'): 1, ('research', 'over', 'the'): 1, ('over', 'the', 'last'): 3, ('the', 'last', 'five'): 1, ('last', 'five', 'years.'): 1, ('five', 'years.', 'It'): 1, ('years.', 'It', 'begins'): 1, ('It', 'begins', 'by'): 1, ('begins', 'by', 'providing'): 1, ('by', 'providing', 'a'): 1, ('providing', 'a', 'brief'): 1, ('a', 'brief', 'guide'): 1, ('brief', 'guide', 'to'): 1, ('guide', 'to', 'the'): 1, ('to', 'the', 'structure'): 1, ('the', 'structure', 'of'): 1, ('structure', 'of', 'the'): 1, ('of', 'the', 'field'): 1, ('the', 'field', 'and'): 1, ('field', 'and', 'then'): 1, ('and', 'then', 'presents'): 1, ('then', 'presents', 'a'): 1, ('presents', 'a', 'caricature'): 1, ('a', 'caricature', 'of'): 1, ('caricature', 'of', 'two'): 1, ('of', 'two', 'competing'): 1, ('two', 'competing', 'paradigms'): 1, ('competing', 'paradigms', 'of'): 1, ('paradigms', 'of', '1980s'): 1, ('of', '1980s', 'NLP'): 1, ('1980s', 'NLP', 'research'): 1, ('NLP', 'research', 'and'): 1, ('research', 'and', 'indicates'): 1, ('and', 'indicates', 'the'): 1, ('indicates', 'the', 'reasons'): 1, ('the', 'reasons', '\"'): 1, ('reasons', '\"', 'visual'): 1, ('\"', 'visual', 'development'): 1, ('visual', 'development', 'environment'): 1, ('development', 'environment', 'to'): 1, ('environment', 'to', 'support'): 1, ('to', 'support', 'the'): 1, ('support', 'the', 'visual'): 1, ('the', 'visual', 'assembly,'): 1, ('visual', 'assembly,', 'execution'): 1, ('assembly,', 'execution', 'and'): 1, ('execution', 'and', 'analysis'): 1, ('and', 'analysis', 'of'): 1, ('analysis', 'of', 'modular'): 1, ('of', 'modular', 'natural'): 1, ('modular', 'natural', 'language'): 1, ('systems.', 'The', 'visual'): 1, ('The', 'visual', 'model'): 1, ('visual', 'model', 'is'): 1, ('model', 'is', 'an'): 1, ('is', 'an', 'executable'): 1, ('an', 'executable', 'data'): 1, ('executable', 'data', 'flow'): 1, ('data', 'flow', 'program'): 1, ('flow', 'program', 'graph,'): 1, ('program', 'graph,', 'automatically'): 1, ('graph,', 'automatically', 'synthesised'): 1, ('automatically', 'synthesised', 'from'): 1, ('synthesised', 'from', 'data'): 1, ('from', 'data', 'dependency'): 1, ('data', 'dependency', 'declarations'): 1, ('dependency', 'declarations', 'of'): 1, ('declarations', 'of', 'language'): 1, ('of', 'language', 'processing'): 2, ('language', 'processing', 'modules.'): 1, ('processing', 'modules.', 'The'): 1, ('modules.', 'The', 'graph'): 1, ('The', 'graph', '\"'): 1, ('graph', '\"', '\"'): 1, ('\"', 'In', 'this'): 3, ('In', 'this', 'Chapter'): 1, ('this', 'Chapter', 'the'): 1, ('Chapter', 'the', 'basic'): 1, ('the', 'basic', 'uses'): 1, ('basic', 'uses', 'of'): 1, ('uses', 'of', 'Description'): 1, ('of', 'Description', 'Logics'): 2, ('Description', 'Logics', 'for'): 1, ('Logics', 'for', 'Natural'): 1, ('for', 'Natural', 'Language'): 1, ('Language', 'Processing', 'will'): 1, ('Processing', 'will', 'be'): 1, ('will', 'be', 'analysed,'): 1, ('be', 'analysed,', 'together'): 1, ('analysed,', 'together', 'with'): 1, ('together', 'with', 'a'): 1, ('with', 'a', 'little'): 1, ('a', 'little', 'bit'): 1, ('little', 'bit', 'of'): 1, ('bit', 'of', 'history,'): 1, ('of', 'history,', 'and'): 1, ('history,', 'and', 'the'): 1, ('and', 'the', 'role'): 1, ('role', 'of', 'Description'): 1, ('Description', 'Logics', 'in'): 1, ('Logics', 'in', 'the'): 1, ('in', 'the', 'current'): 1, ('current', 'state', 'of'): 1, ('state', 'of', 'the'): 3, ('of', 'the', 'art'): 3, ('the', 'art', 'in'): 1, ('art', 'in', 'computational'): 1, ('computational', 'linguistics', 'will'): 1, ('linguistics', 'will', 'be'): 1, ('will', 'be', 'pointed'): 1, ('be', 'pointed', 'out.'): 1, ('pointed', 'out.', '18.1'): 1, ('out.', '18.1', 'Introduction'): 1, ('18.1', 'Introduction', 'Since'): 1, ('Introduction', 'Since', 'the'): 1, ('Since', 'the', 'early'): 1, ('the', 'early', 'days'): 1, ('early', 'days', '\"'): 1, ('days', '\"', '\"'): 1, ('\"', 'We', 'applied'): 1, ('We', 'applied', 'a'): 1, ('applied', 'a', 'structure'): 1, ('a', 'structure', 'learning'): 1, ('structure', 'learning', 'model,'): 1, ('learning', 'model,', 'Max-Margin'): 1, ('model,', 'Max-Margin', 'Structure'): 1, ('Max-Margin', 'Structure', '(MMS),'): 1, ('Structure', '(MMS),', 'to'): 1, ('(MMS),', 'to', 'natural'): 1, ('processing', '(NLP)', 'tasks,'): 1, ('(NLP)', 'tasks,', 'where'): 1, ('tasks,', 'where', 'the'): 1, ('where', 'the', 'aim'): 1, ('the', 'aim', 'is'): 1, ('aim', 'is', 'to'): 1, ('is', 'to', 'capture'): 1, ('to', 'capture', 'the'): 1, ('capture', 'the', 'latent'): 1, ('the', 'latent', 'relationships'): 1, ('latent', 'relationships', 'within'): 1, ('relationships', 'within', 'the'): 1, ('within', 'the', 'output'): 1, ('the', 'output', 'language'): 1, ('output', 'language', 'domain.'): 1, ('language', 'domain.', 'We'): 1, ('domain.', 'We', 'formulate'): 1, ('We', 'formulate', 'this'): 1, ('formulate', 'this', 'model'): 1, ('this', 'model', 'as'): 1, ('model', 'as', 'an'): 1, ('as', 'an', 'extension'): 1, ('an', 'extension', 'of'): 1, ('extension', 'of', 'multiâ\\x80\\x93class'): 1, ('of', 'multiâ\\x80\\x93class', 'Support'): 1, ('multiâ\\x80\\x93class', 'Support', 'Vector'): 1, ('Support', 'Vector', 'Machine'): 1, ('Vector', 'Machine', '(SVM)'): 1, ('Machine', '(SVM)', 'and'): 1, ('(SVM)', 'and', 'present'): 1, ('and', 'present', 'a'): 1, ('present', 'a', '\"'): 1, ('a', '\"', '\"'): 2, ('\"', '\"', '-mation'): 1, ('\"', '-mation', 'Infrastructure,'): 1, ('-mation', 'Infrastructure,', 'digital'): 1, ('Infrastructure,', 'digital', 'libraries,'): 1, ('digital', 'libraries,', 'networked'): 1, ('libraries,', 'networked', 'services,'): 1, ('networked', 'services,', 'digital'): 1, ('services,', 'digital', 'convergence'): 1, ('digital', 'convergence', 'or'): 1, ('convergence', 'or', 'intelligent'): 1, ('or', 'intelligent', 'agents.'): 1, ('intelligent', 'agents.', 'This'): 1, ('agents.', 'This', 'attention'): 1, ('This', 'attention', 'is'): 1, ('attention', 'is', 'moving'): 1, ('is', 'moving', 'natural'): 1, ('moving', 'natural', 'language'): 1, ('language', 'processing', 'along'): 1, ('processing', 'along', 'the'): 1, ('along', 'the', 'critical'): 1, ('the', 'critical', 'path'): 1, ('critical', 'path', 'for'): 1, ('path', 'for', 'all'): 1, ('for', 'all', 'kinds'): 1, ('all', 'kinds', 'of'): 1, ('kinds', 'of', 'novel'): 1, ('of', 'novel', 'applications.'): 1, ('novel', 'applications.', 'This'): 1, ('applications.', 'This', 'article'): 1, ('This', 'article', 'will'): 1, ('article', 'will', 'mention'): 1, ('will', 'mention', 'a'): 1, ('mention', 'a', 'number'): 1, ('number', 'of', 'successful'): 1, ('of', 'successful', 'applications'): 1, ('successful', 'applications', 'of'): 1, ('applications', 'of', 'natural'): 1, ('language', 'processing', '(NLP'): 1, ('processing', '(NLP', '\"'): 1, ('(NLP', '\"', '\"'): 1, ('\"', '\"', 'Over'): 1, ('\"', 'Over', 'the'): 1, ('Over', 'the', 'last'): 1, ('the', 'last', 'few'): 1, ('last', 'few', 'years,'): 1, ('few', 'years,', 'a'): 1, ('years,', 'a', 'number'): 1, ('number', 'of', 'areas'): 1, ('of', 'areas', 'of'): 1, ('areas', 'of', 'natural'): 1, ('language', 'processing', 'have'): 1, ('processing', 'have', 'begun'): 1, ('have', 'begun', 'applying'): 1, ('begun', 'applying', 'graph-based'): 1, ('applying', 'graph-based', 'techniques.'): 1, ('graph-based', 'techniques.', 'These'): 1, ('techniques.', 'These', 'include,'): 1, ('These', 'include,', 'among'): 1, ('include,', 'among', 'others,'): 1, ('among', 'others,', 'text'): 1, ('others,', 'text', 'summarization,'): 1, ('text', 'summarization,', 'syntactic'): 1, ('summarization,', 'syntactic', 'parsing,'): 1, ('syntactic', 'parsing,', 'word'): 1, ('parsing,', 'word', 'sense'): 2, ('word', 'sense', 'disambiguation,'): 1, ('sense', 'disambiguation,', 'ontology'): 1, ('disambiguation,', 'ontology', 'construction,'): 1, ('ontology', 'construction,', 'sentiment'): 1, ('construction,', 'sentiment', 'and'): 1, ('sentiment', 'and', 'subjectivity'): 1, ('and', 'subjectivity', 'analysis,'): 1, ('subjectivity', 'analysis,', 'text'): 1, ('analysis,', 'text', 'clustering'): 1, ('text', 'clustering', '\"'): 1, ('clustering', '\"', '\"'): 1, ('\"', 'In', 'Natural'): 1, ('In', 'Natural', 'Language'): 1, ('Language', 'Processing', '(NLP),'): 2, ('Processing', '(NLP),', 'research'): 1, ('(NLP),', 'research', 'results'): 1, ('research', 'results', 'from'): 1, ('results', 'from', 'software'): 1, ('from', 'software', 'engineering'): 1, ('software', 'engineering', 'and'): 1, ('engineering', 'and', 'software'): 1, ('and', 'software', 'technology'): 1, ('software', 'technology', 'have'): 1, ('technology', 'have', 'often'): 1, ('have', 'often', 'been'): 1, ('often', 'been', 'neglected.'): 1, ('been', 'neglected.', '\"'): 1, ('neglected.', '\"', '\"'): 1, ('\"', '\"', 'of'): 2, ('\"', 'of', 'kernelized'): 1, ('of', 'kernelized', 'sorting'): 1, ('kernelized', 'sorting', 'to'): 1, ('sorting', 'to', 'increase'): 1, ('to', 'increase', 'its'): 1, ('increase', 'its', 'robustness'): 1, ('its', 'robustness', 'and'): 1, ('robustness', 'and', 'performance'): 1, ('and', 'performance', 'on'): 1, ('performance', 'on', 'several'): 1, ('on', 'several', 'Natural'): 1, ('several', 'Natural', 'Language'): 1, ('Processing', '(NLP)', 'tasks:'): 1, ('(NLP)', 'tasks:', 'document'): 1, ('tasks:', 'document', 'matching'): 1, ('document', 'matching', 'from'): 1, ('matching', 'from', 'parallel'): 1, ('from', 'parallel', 'and'): 1, ('parallel', 'and', 'comparable'): 1, ('and', 'comparable', 'corpora,'): 1, ('comparable', 'corpora,', 'machine'): 1, ('corpora,', 'machine', 'transliteration'): 1, ('machine', 'transliteration', 'and'): 1, ('transliteration', 'and', 'even'): 1, ('and', 'even', 'image'): 1, ('even', 'image', 'processing.'): 1, ('image', 'processing.', 'Empirically'): 1, ('processing.', 'Empirically', 'we'): 1, ('Empirically', 'we', 'show'): 1, ('we', 'show', 'that,'): 1, ('show', 'that,', 'on'): 1, ('that,', 'on', 'these'): 1, ('on', 'these', 'tasks,'): 1, ('these', 'tasks,', 'a'): 1, ('tasks,', 'a', 'semi-supervised'): 1, ('a', 'semi-supervised', 'variant'): 1, ('semi-supervised', 'variant', 'of'): 1, ('variant', 'of', 'kernelized'): 1, ('of', 'kernelized', '\"'): 1, ('kernelized', '\"', '\"'): 1, ('\"', '\"', 'will'): 1, ('\"', 'will', 'be'): 1, ('will', 'be', 'structured.'): 1, ('be', 'structured.', 'In'): 1, ('structured.', 'In', 'the'): 1, ('In', 'the', 'words'): 1, ('the', 'words', 'of'): 1, ('words', 'of', 'statistical'): 1, ('of', 'statistical', 'natural'): 1, ('statistical', 'natural', 'language'): 1, ('natural', 'language', 'processing,'): 4, ('language', 'processing,', 'we'): 1, ('processing,', 'we', 'need'): 1, ('we', 'need', 'a'): 1, ('need', 'a', 'sophisticated'): 1, ('a', 'sophisticated', 'statistical'): 1, ('sophisticated', 'statistical', 'model'): 1, ('statistical', 'model', 'of'): 1, ('model', 'of', 'the'): 2, ('of', 'the', 'basic'): 1, ('the', 'basic', 'elements,'): 1, ('basic', 'elements,', 'such'): 1, ('elements,', 'such', 'as'): 1, ('such', 'as', 'words'): 1, ('as', 'words', 'or'): 1, ('words', 'or', 'phrases,'): 1, ('or', 'phrases,', 'to'): 1, ('phrases,', 'to', 'be'): 1, ('to', 'be', 'combined'): 1, ('be', 'combined', 'with'): 1, ('combined', 'with', 'the'): 1, ('with', 'the', 'structural'): 1, ('the', 'structural', 'modeling'): 1, ('structural', 'modeling', 'such'): 1, ('modeling', 'such', 'as'): 1, ('such', 'as', 'syntactic'): 1, ('as', 'syntactic', 'parsing'): 1, ('syntactic', 'parsing', 'or'): 1, ('parsing', 'or', 'dependency'): 1, ('or', 'dependency', 'analysis.'): 1, ('dependency', 'analysis.', 'Since'): 1, ('analysis.', 'Since', 'the'): 1, ('Since', 'the', 'basic'): 1, ('the', 'basic', 'property'): 1, ('basic', 'property', 'of'): 1, ('property', 'of', 'these'): 1, ('of', 'these', 'elements'): 1, ('these', 'elements', '\"'): 1, ('elements', '\"', '\"'): 1, ('describe', 'a', 'framework'): 1, ('a', 'framework', 'for'): 1, ('framework', 'for', 'developing'): 1, ('for', 'developing', 'probabilistic'): 1, ('developing', 'probabilistic', 'classifiers'): 1, ('probabilistic', 'classifiers', 'in'): 1, ('classifiers', 'in', 'natural'): 1, ('language', 'processing.', 'Our'): 1, ('processing.', 'Our', 'focus'): 1, ('Our', 'focus', 'is'): 1, ('focus', 'is', 'on'): 1, ('is', 'on', 'formulating'): 1, ('on', 'formulating', 'models'): 1, ('formulating', 'models', 'that'): 1, ('models', 'that', 'capture'): 1, ('that', 'capture', 'the'): 1, ('capture', 'the', 'most'): 1, ('the', 'most', 'important'): 1, ('most', 'important', 'interdependencies'): 1, ('important', 'interdependencies', 'among'): 1, ('interdependencies', 'among', 'features,'): 1, ('among', 'features,', 'to'): 1, ('features,', 'to', 'avoid'): 1, ('to', 'avoid', 'overfitting'): 1, ('avoid', 'overfitting', 'the'): 1, ('overfitting', 'the', 'data'): 1, ('the', 'data', 'while'): 1, ('data', 'while', 'also'): 1, ('while', 'also', 'characterizing'): 1, ('also', 'characterizing', 'the'): 1, ('characterizing', 'the', 'data'): 1, ('the', 'data', 'well.'): 1, ('data', 'well.', 'The'): 1, ('well.', 'The', 'class'): 1, ('The', 'class', '\"'): 1, ('class', '\"', '\"'): 1, ('\"', '\"', 'Many'): 1, ('\"', 'Many', 'Natural'): 1, ('Many', 'Natural', 'Language'): 1, ('(NLP)', 'techniques', 'have'): 1, ('techniques', 'have', 'been'): 1, ('been', 'used', 'in'): 1, ('used', 'in', 'Information'): 1, ('in', 'Information', 'Retrieval.'): 1, ('Information', 'Retrieval.', 'The'): 1, ('Retrieval.', 'The', 'results'): 1, ('The', 'results', 'are'): 1, ('results', 'are', 'not'): 1, ('are', 'not', 'encouraging.'): 1, ('not', 'encouraging.', 'Simple'): 1, ('encouraging.', 'Simple', 'methods'): 1, ('Simple', 'methods', '(stopwording,'): 1, ('methods', '(stopwording,', 'porter-style'): 1, ('(stopwording,', 'porter-style', 'stemming,'): 1, ('porter-style', 'stemming,', 'etc.)'): 1, ('stemming,', 'etc.)', 'usually'): 1, ('etc.)', 'usually', 'yield'): 1, ('usually', 'yield', 'significant'): 1, ('yield', 'significant', 'improvements,'): 1, ('significant', 'improvements,', 'while'): 1, ('improvements,', 'while', 'higher-level'): 1, ('while', 'higher-level', 'processing'): 1, ('higher-level', 'processing', '(chunking,'): 1, ('processing', '(chunking,', 'parsing,'): 1, ('(chunking,', 'parsing,', 'word'): 1, ('word', 'sense', 'disambiguation'): 1, ('sense', 'disambiguation', '\"'): 1, ('disambiguation', '\"', 'Abstract-'): 1, ('\"', 'Abstract-', 'This'): 1, ('Abstract-', 'This', 'paper'): 1, ('This', 'paper', 'explains'): 1, ('paper', 'explains', 'the'): 1, ('explains', 'the', 'information'): 1, ('the', 'information', 'retrieval'): 1, ('information', 'retrieval', 'using'): 1, ('retrieval', 'using', 'natural'): 1, ('processing', 'for', 'Malayalam'): 1, ('for', 'Malayalam', 'language'): 1, ('Malayalam', 'language', 'in'): 1, ('language', 'in', 'these'): 1, ('in', 'these', 'basic'): 1, ('these', 'basic', '\"'): 1, ('basic', '\"', 'in'): 1, ('\"', 'in', 'the'): 2, ('in', 'the', 'state'): 2, ('the', 'state', 'of'): 2, ('the', 'art', 'plan'): 2, ('art', 'plan', 'recognition'): 2, ('plan', 'recognition', 'systems.'): 2, ('recognition', 'systems.', 'This'): 2, ('systems.', 'This', 'paper'): 2, ('This', 'paper', 'will'): 2, ('paper', 'will', 'outline'): 2, ('will', 'outline', 'the'): 2, ('outline', 'the', 'relations'): 2, ('the', 'relations', 'between'): 2, ('relations', 'between', 'natural'): 2, ('between', 'natural', 'language'): 2, ('natural', 'language', 'processing(NLP)'): 2, ('language', 'processing(NLP)', 'and'): 2, ('processing(NLP)', 'and', 'plan'): 2, ('and', 'plan', 'recognition(PR),'): 2, ('plan', 'recognition(PR),', 'argue'): 2, ('recognition(PR),', 'argue', 'that'): 2, ('argue', 'that', 'each'): 2, ('that', 'each', 'of'): 2, ('each', 'of', 'them'): 2, ('of', 'them', 'can'): 2, ('them', 'can', 'effectively'): 2, ('can', 'effectively', 'inform'): 2, ('effectively', 'inform', 'the'): 2, ('inform', 'the', 'other,'): 2, ('the', 'other,', 'and'): 2, ('other,', 'and', 'then'): 2, ('and', 'then', 'focus'): 2, ('then', 'focus', 'on'): 2, ('focus', 'on', 'key'): 2, ('on', 'key', 'recent'): 2, ('key', 'recent', 'research'): 2, ('recent', 'research', 'results'): 2, ('research', 'results', 'in'): 2, ('results', 'in', 'NLP'): 2, ('in', 'NLP', 'and'): 2, ('NLP', 'and', 'argue'): 2, ('and', 'argue', 'for'): 2, ('argue', 'for', 'their'): 2, ('for', 'their', 'applicability'): 2, ('their', 'applicability', 'to'): 2, ('applicability', 'to', 'PR.'): 2, ('to', 'PR.', '1'): 2, ('PR.', '1', '\"'): 2, ('1', '\"', '\"'): 3, ('\"', '\"', 'in'): 1, ('\"', '\"', 'Information'): 1, ('\"', 'Information', 'retrieval'): 1, ('Information', 'retrieval', 'is'): 1, ('retrieval', 'is', 'the'): 1, ('is', 'the', 'process'): 1, ('the', 'process', 'of'): 2, ('process', 'of', 'finding'): 1, ('of', 'finding', 'the'): 1, ('finding', 'the', 'documents'): 1, ('the', 'documents', 'in'): 1, ('documents', 'in', 'a'): 1, ('in', 'a', 'document'): 1, ('a', 'document', 'collection'): 1, ('document', 'collection', 'that'): 1, ('collection', 'that', 'satisfies'): 1, ('that', 'satisfies', 'the'): 1, ('satisfies', 'the', 'information'): 1, ('the', 'information', 'need'): 1, ('information', 'need', 'of'): 1, ('need', 'of', 'the'): 1, ('of', 'the', 'user.'): 1, ('the', 'user.', 'The'): 1, ('user.', 'The', 'documents'): 1, ('The', 'documents', 'are'): 1, ('documents', 'are', 'natural'): 1, ('are', 'natural', 'language'): 1, ('natural', 'language', 'constructs,'): 1, ('language', 'constructs,', 'and'): 1, ('constructs,', 'and', 'the'): 1, ('and', 'the', 'motivation'): 1, ('the', 'motivation', 'of'): 1, ('motivation', 'of', 'this'): 1, ('of', 'this', 'work'): 1, ('this', 'work', 'is'): 1, ('work', 'is', 'to'): 1, ('is', 'to', 'investigate'): 1, ('to', 'investigate', 'how'): 1, ('investigate', 'how', 'natural'): 1, ('how', 'natural', 'language'): 1, ('language', 'processing', 'can'): 1, ('processing', 'can', 'be'): 1, ('can', 'be', 'used'): 2, ('be', 'used', 'to'): 2, ('used', 'to', 'improve'): 1, ('to', 'improve', '\"'): 1, ('improve', '\"', '\"'): 1, ('\"', 'of', 'logic'): 1, ('of', 'logic', 'programming'): 1, ('logic', 'programming', 'within'): 1, ('programming', 'within', 'both'): 1, ('within', 'both', 'natural'): 1, ('both', 'natural', 'language'): 1, ('natural', 'language', 'research'): 1, ('language', 'research', 'and'): 1, ('research', 'and', 'machine'): 1, ('and', 'machine', 'learning,'): 1, ('machine', 'learning,', 'we'): 1, ('learning,', 'we', 'point'): 1, ('we', 'point', 'out'): 1, ('point', 'out', 'opportunities'): 1, ('out', 'opportunities', 'for'): 1, ('opportunities', 'for', 'induction'): 1, ('for', 'induction', 'of'): 1, ('induction', 'of', 'linguistic'): 1, ('of', 'linguistic', 'knowledge'): 1, ('linguistic', 'knowledge', 'within'): 1, ('knowledge', 'within', 'logic'): 1, ('within', 'logic', '(programming).'): 1, ('logic', '(programming).', 'Keywords:'): 1, ('(programming).', 'Keywords:', 'inductive'): 1, ('Keywords:', 'inductive', 'logic'): 1, ('inductive', 'logic', 'programming,'): 1, ('logic', 'programming,', 'natural'): 1, ('programming,', 'natural', 'language'): 1, ('language', 'processing,', 'logic'): 1, ('processing,', 'logic', 'programming,'): 1, ('logic', 'programming,', 'machine'): 1, ('programming,', 'machine', 'learning.'): 1, ('machine', 'learning.', '1'): 1, ('learning.', '1', 'Introduction'): 1, ('1', 'Introduction', 'There'): 1, ('Introduction', 'There', 'is'): 1, ('There', 'is', 'a'): 1, ('is', 'a', '\"'): 1, ('\"', '\"', 'What'): 1, ('\"', 'What', 'is'): 1, ('What', 'is', 'a'): 1, ('is', 'a', 'statistical'): 2, ('a', 'statistical', 'method'): 1, ('statistical', 'method', 'and'): 1, ('method', 'and', 'how'): 1, ('and', 'how', 'can'): 1, ('how', 'can', 'it'): 1, ('can', 'it', 'be'): 1, ('it', 'be', 'used'): 1, ('be', 'used', 'in'): 1, ('used', 'in', 'natural'): 1, ('language', 'processing', '(NLP)?'): 1, ('processing', '(NLP)?', 'In'): 1, ('(NLP)?', 'In', 'this'): 1, ('paper,', 'we', 'start'): 1, ('we', 'start', 'from'): 1, ('start', 'from', 'a'): 1, ('from', 'a', 'definition'): 1, ('a', 'definition', 'of'): 1, ('definition', 'of', 'NLP'): 1, ('of', 'NLP', 'as'): 1, ('NLP', 'as', 'concerned'): 1, ('as', 'concerned', 'with'): 1, ('with', 'the', 'design'): 1, ('the', 'design', 'and'): 2, ('design', 'and', 'implementation'): 1, ('and', 'implementation', 'of'): 1, ('implementation', 'of', 'effective'): 1, ('of', 'effective', 'natural'): 1, ('effective', 'natural', 'language'): 1, ('natural', 'language', 'input'): 1, ('language', 'input', 'and'): 1, ('input', 'and', 'output'): 1, ('and', 'output', 'components'): 1, ('output', 'components', 'for'): 1, ('components', 'for', 'computational'): 1, ('for', 'computational', 'systems.'): 1, ('computational', 'systems.', 'We'): 1, ('systems.', 'We', 'distinguish'): 1, ('We', 'distinguish', 'three'): 1, ('distinguish', 'three', '\"'): 1, ('three', '\"', '\"'): 1, ('In', 'this', 'report,'): 1, ('this', 'report,', 'some'): 1, ('report,', 'some', 'collaborative'): 1, ('some', 'collaborative', 'work'): 1, ('collaborative', 'work', 'between'): 1, ('work', 'between', 'the'): 1, ('between', 'the', 'fields'): 1, ('the', 'fields', 'of'): 1, ('fields', 'of', 'Machine'): 1, ('of', 'Machine', 'Learning'): 1, ('Machine', 'Learning', '(ML)'): 1, ('Learning', '(ML)', 'and'): 1, ('(ML)', 'and', 'Natural'): 1, ('(NLP)', 'is', 'presented.'): 1, ('is', 'presented.', 'The'): 1, ('presented.', 'The', 'document'): 1, ('The', 'document', 'is'): 1, ('document', 'is', 'structured'): 1, ('is', 'structured', 'in'): 1, ('structured', 'in', 'two'): 1, ('in', 'two', 'parts.'): 1, ('two', 'parts.', 'The'): 1, ('parts.', 'The', 'first'): 1, ('The', 'first', 'part'): 1, ('first', 'part', 'includes'): 1, ('part', 'includes', 'a'): 1, ('includes', 'a', 'superficial'): 1, ('a', 'superficial', 'but'): 1, ('superficial', 'but', 'comprehensive'): 1, ('but', 'comprehensive', 'survey'): 1, ('comprehensive', 'survey', 'covering'): 1, ('survey', 'covering', 'the'): 1, ('covering', 'the', 'state--of--the--art'): 1, ('the', 'state--of--the--art', 'of'): 1, ('state--of--the--art', 'of', 'machine'): 1, ('of', 'machine', 'learning'): 2, ('machine', 'learning', '\"'): 1, ('learning', '\"', '\"'): 1, ('\"', '\"', 'Abstract.'): 1, ('\"', 'Abstract.', 'This'): 1, ('Abstract.', 'This', 'thesis'): 1, ('This', 'thesis', 'examines'): 1, ('thesis', 'examines', 'the'): 1, ('examines', 'the', 'use'): 1, ('use', 'of', 'machine'): 1, ('learning', 'techniques', 'in'): 1, ('techniques', 'in', 'various'): 1, ('in', 'various', 'tasks'): 1, ('various', 'tasks', 'of'): 1, ('tasks', 'of', 'natural'): 1, ('language', 'processing,', 'mainly'): 1, ('processing,', 'mainly', 'for'): 1, ('mainly', 'for', 'the'): 1, ('for', 'the', 'task'): 1, ('the', 'task', 'of'): 1, ('task', 'of', 'information'): 1, ('of', 'information', 'extraction'): 2, ('information', 'extraction', 'from'): 1, ('extraction', 'from', 'texts.'): 1, ('from', 'texts.', 'The'): 1, ('texts.', 'The', 'objectives'): 1, ('The', 'objectives', 'are'): 1, ('objectives', 'are', 'the'): 1, ('are', 'the', 'improvement'): 1, ('the', 'improvement', 'of'): 2, ('improvement', 'of', 'adaptability'): 1, ('of', 'adaptability', 'of'): 1, ('adaptability', 'of', 'information'): 1, ('information', 'extraction', 'systems'): 1, ('extraction', 'systems', 'to'): 1, ('systems', 'to', 'new'): 1, ('to', 'new', 'thematic'): 1, ('new', 'thematic', 'do-mains'): 1, ('thematic', 'do-mains', '(or'): 1, ('do-mains', '(or', 'even'): 1, ('(or', 'even', '\"'): 1, ('even', '\"', 'This'): 1, ('\"', 'This', 'chapter'): 2, ('This', 'chapter', 'examines'): 2, ('chapter', 'examines', 'the'): 2, ('examines', 'the', 'application'): 2, ('application', 'of', 'natural'): 2, ('processing', 'to', 'computerassisted'): 2, ('to', 'computerassisted', 'language'): 2, ('computerassisted', 'language', 'learning'): 2, ('language', 'learning', 'including'): 2, ('learning', 'including', 'the'): 2, ('including', 'the', 'history'): 2, ('the', 'history', 'of'): 2, ('history', 'of', 'work'): 2, ('of', 'work', 'in'): 2, ('work', 'in', 'this'): 2, ('in', 'this', 'field'): 2, ('this', 'field', 'over'): 2, ('field', 'over', 'the'): 2, ('the', 'last', 'thirtyfive'): 2, ('last', 'thirtyfive', 'years'): 2, ('thirtyfive', 'years', 'but'): 2, ('years', 'but', 'with'): 2, ('but', 'with', 'a'): 2, ('focus', 'on', 'current'): 2, ('on', 'current', 'developments'): 2, ('current', 'developments', 'and'): 2, ('developments', 'and', 'opportunities.'): 2, ('and', 'opportunities.', '36.1'): 1, ('opportunities.', '36.1', '\"'): 1, ('36.1', '\"', 'Traditional'): 1, ('\"', 'Traditional', 'approaches'): 1, ('Traditional', 'approaches', 'tointerpretation'): 1, ('approaches', 'tointerpretation', 'in'): 1, ('tointerpretation', 'in', 'natural'): 1, ('language', 'processing', 'typically'): 1, ('processing', 'typically', 'fall'): 1, ('typically', 'fall', 'into'): 1, ('fall', 'into', 'one'): 1, ('into', 'one', 'of'): 1, ('one', 'of', 'three'): 1, ('of', 'three', 'classes:'): 1, ('three', 'classes:', 'syntax-driven,'): 1, ('classes:', 'syntax-driven,', 'semantics-driven,'): 1, ('syntax-driven,', 'semantics-driven,', 'or'): 1, ('semantics-driven,', 'or', 'frame/task'): 1, ('or', 'frame/task', 'based.'): 1, ('frame/task', 'based.', 'Syntax-driven'): 1, ('based.', 'Syntax-driven', 'approaches'): 1, ('Syntax-driven', 'approaches', 'use'): 1, ('approaches', 'use', 'a'): 1, ('use', 'a', 'domain-independent'): 1, ('a', 'domain-independent', 'grammar'): 1, ('domain-independent', 'grammar', 'to'): 1, ('grammar', 'to', 'drive'): 1, ('drive', 'the', 'interpretation'): 1, ('the', 'interpretation', 'process'): 1, ('interpretation', 'process', 'and'): 1, ('process', 'and', 'produce'): 1, ('and', 'produce', 'a'): 1, ('produce', 'a', 'global'): 1, ('a', 'global', 'parse'): 1, ('global', 'parse', '\"'): 1, ('parse', '\"', '\"'): 1, ('(NLP)', 'is', 'a'): 1, ('is', 'a', 'very'): 1, ('a', 'very', 'large'): 1, ('very', 'large', 'and'): 1, ('large', 'and', 'diverse'): 1, ('and', 'diverse', 'subtopic'): 1, ('diverse', 'subtopic', 'of'): 1, ('subtopic', 'of', 'artificial'): 1, ('of', 'artificial', 'intelligence.'): 1, ('artificial', 'intelligence.', 'As'): 1, ('intelligence.', 'As', 'a'): 1, ('As', 'a', 'result,'): 1, ('a', 'result,', 'NLP'): 1, ('result,', 'NLP', 'itself'): 1, ('NLP', 'itself', 'has'): 1, ('itself', 'has', 'many'): 1, ('has', 'many', 'subtopics'): 1, ('many', 'subtopics', 'including'): 1, ('subtopics', 'including', 'optical'): 1, ('including', 'optical', 'character'): 1, ('optical', 'character', 'recognition,'): 1, ('character', 'recognition,', 'text'): 1, ('recognition,', 'text', 'to'): 1, ('text', 'to', 'speech'): 1, ('to', 'speech', 'translators,'): 1, ('speech', 'translators,', 'foreign'): 1, ('translators,', 'foreign', 'language'): 1, ('foreign', 'language', 'reading'): 1, ('language', 'reading', 'and'): 1, ('reading', 'and', 'writing'): 1, ('and', 'writing', 'aids,'): 1, ('writing', 'aids,', 'machine'): 1, ('aids,', 'machine', 'translation,'): 1, ('translation,', 'and', 'speech'): 1, ('and', 'speech', 'recognition'): 1, ('speech', 'recognition', '\"'): 1, ('recognition', '\"', '\"'): 1, ('\"', '\"', 'Probabilistic'): 1, ('\"', 'Probabilistic', 'finite-state'): 1, ('Probabilistic', 'finite-state', 'string'): 1, ('finite-state', 'string', 'transducers'): 1, ('string', 'transducers', '(FSTs)'): 1, ('transducers', '(FSTs)', 'are'): 1, ('(FSTs)', 'are', 'extremely'): 1, ('are', 'extremely', 'popular'): 1, ('extremely', 'popular', 'in'): 1, ('popular', 'in', 'natural'): 1, ('language', 'processing,', 'due'): 1, ('processing,', 'due', 'to'): 1, ('due', 'to', 'powerful'): 1, ('to', 'powerful', 'generic'): 1, ('powerful', 'generic', 'methods'): 1, ('generic', 'methods', 'for'): 1, ('methods', 'for', 'applying,'): 1, ('for', 'applying,', 'composing,'): 1, ('applying,', 'composing,', 'and'): 1, ('composing,', 'and', 'learning'): 1, ('and', 'learning', 'them.'): 1, ('learning', 'them.', 'Unfortunately,'): 1, ('them.', 'Unfortunately,', 'FSTs'): 1, ('Unfortunately,', 'FSTs', 'are'): 1, ('FSTs', 'are', 'not'): 1, ('are', 'not', 'a'): 1, ('not', 'a', 'good'): 1, ('a', 'good', 'fit'): 1, ('good', 'fit', 'for'): 1, ('fit', 'for', 'much'): 1, ('for', 'much', 'of'): 1, ('much', 'of', 'the'): 1, ('the', 'current', 'work'): 1, ('current', 'work', 'on'): 1, ('work', 'on', 'probabilistic'): 1, ('on', 'probabilistic', 'modeling'): 1, ('probabilistic', 'modeling', 'for'): 1, ('modeling', 'for', 'machine'): 1, ('for', 'machine', '\"'): 1, ('machine', '\"', '\"'): 1, ('\"', '\"', 'ABSTRACT.'): 1, ('\"', 'ABSTRACT.', 'In'): 1, ('ABSTRACT.', 'In', 'this'): 1, ('In', 'this', 'special'): 1, ('this', 'special', 'issue'): 1, ('special', 'issue', 'of'): 1, ('issue', 'of', 'TAL,'): 1, ('of', 'TAL,', 'we'): 1, ('TAL,', 'we', 'look'): 1, ('we', 'look', 'at'): 1, ('look', 'at', 'the'): 1, ('at', 'the', 'fundamental'): 1, ('the', 'fundamental', 'principles'): 1, ('fundamental', 'principles', 'underlying'): 1, ('principles', 'underlying', 'evaluation'): 1, ('underlying', 'evaluation', 'in'): 1, ('evaluation', 'in', 'natural'): 1, ('processing.', 'We', 'adopt'): 1, ('We', 'adopt', 'a'): 1, ('adopt', 'a', 'global'): 1, ('a', 'global', 'point'): 1, ('global', 'point', 'of'): 1, ('point', 'of', 'view'): 1, ('of', 'view', 'that'): 1, ('view', 'that', 'goes'): 1, ('that', 'goes', 'beyond'): 1, ('goes', 'beyond', 'the'): 1, ('beyond', 'the', 'horizon'): 1, ('the', 'horizon', 'of'): 1, ('horizon', 'of', 'a'): 1, ('of', 'a', 'single'): 1, ('a', 'single', 'evaluation'): 1, ('single', 'evaluation', 'campaign'): 1, ('evaluation', 'campaign', 'or'): 1, ('campaign', 'or', 'a'): 1, ('or', 'a', 'particular'): 1, ('a', 'particular', 'protocol.'): 1, ('particular', 'protocol.', 'After'): 1, ('protocol.', 'After', 'a'): 1, ('After', 'a', 'brief'): 1, ('a', 'brief', 'review'): 1, ('brief', 'review', 'of'): 1, ('review', 'of', 'history'): 1, ('of', 'history', 'and'): 1, ('history', 'and', 'terminology'): 1, ('and', 'terminology', '\"'): 1, ('terminology', '\"', 'Abstract'): 1, ('found', '\"', 'Natural'): 1, ('\"', 'Natural', 'language'): 1, ('language', 'processing', 'systems'): 2, ('processing', 'systems', '(NLP)'): 1, ('systems', '(NLP)', 'that'): 1, ('(NLP)', 'that', 'extract'): 1, ('that', 'extract', 'clinical'): 1, ('extract', 'clinical', 'information'): 1, ('clinical', 'information', 'from'): 1, ('information', 'from', 'textual'): 1, ('from', 'textual', 'reports'): 1, ('textual', 'reports', 'were'): 1, ('reports', 'were', 'shown'): 1, ('were', 'shown', 'to'): 1, ('shown', 'to', 'be'): 1, ('to', 'be', 'effective'): 1, ('be', 'effective', 'for'): 1, ('effective', 'for', 'limited'): 1, ('for', 'limited', 'domains'): 1, ('limited', 'domains', 'and'): 1, ('domains', 'and', 'for'): 1, ('and', 'for', 'particular'): 1, ('for', 'particular', 'applications.'): 1, ('particular', 'applications.', 'Because'): 1, ('applications.', 'Because', 'an'): 1, ('Because', 'an', 'NLP'): 1, ('an', 'NLP', 'system'): 1, ('NLP', 'system', 'typically'): 1, ('system', 'typically', 'requires'): 1, ('typically', 'requires', 'substantial'): 1, ('requires', 'substantial', 'resources'): 1, ('substantial', 'resources', 'to'): 1, ('resources', 'to', 'develop,'): 1, ('to', 'develop,', 'it'): 1, ('develop,', 'it', 'is'): 1, ('it', 'is', 'beneficial'): 1, ('is', 'beneficial', 'if'): 1, ('beneficial', 'if', 'it'): 1, ('if', 'it', 'is'): 1, ('it', 'is', 'designed'): 1, ('is', 'designed', 'to'): 1, ('designed', 'to', 'be'): 1, ('to', 'be', 'easily'): 1, ('be', 'easily', '\"'): 1, ('easily', '\"', '\"'): 1, ('\"', '\"', 'facts'): 1, ('\"', 'facts', 'forms'): 1, ('facts', 'forms', 'a'): 1, ('forms', 'a', 'link'): 1, ('a', 'link', 'between'): 1, ('link', 'between', 'IE,'): 1, ('between', 'IE,', 'a'): 1, ('IE,', 'a', 'recent'): 1, ('a', 'recent', 'development'): 1, ('development', 'in', 'Natural'): 1, ('Natural', 'Language', 'Processing,'): 2, ('Language', 'Processing,', 'and'): 1, ('Processing,', 'and', 'logic'): 1, ('and', 'logic', 'programming'): 1, ('logic', 'programming', 'with'): 1, ('programming', 'with', 'Prolog.'): 1, ('with', 'Prolog.', '1'): 1, ('Prolog.', '1', '\"'): 1, ('\"', 'We', 'describe'): 2, ('We', 'describe', 'a'): 1, ('describe', 'a', 'single'): 1, ('a', 'single', 'convolutional'): 1, ('single', 'convolutional', 'neural'): 1, ('convolutional', 'neural', 'network'): 1, ('network', 'architecture', 'that,'): 1, ('architecture', 'that,', 'given'): 1, ('that,', 'given', 'a'): 1, ('given', 'a', 'sentence,'): 1, ('a', 'sentence,', 'outputs'): 1, ('sentence,', 'outputs', 'a'): 1, ('outputs', 'a', 'host'): 1, ('a', 'host', 'of'): 1, ('host', 'of', 'language'): 1, ('language', 'processing', 'predictions:'): 1, ('processing', 'predictions:', 'part-of-speech'): 1, ('predictions:', 'part-of-speech', 'tags,'): 1, ('part-of-speech', 'tags,', 'chunks,'): 1, ('tags,', 'chunks,', 'named'): 1, ('chunks,', 'named', 'entity'): 1, ('named', 'entity', 'tags,'): 1, ('entity', 'tags,', 'semantic'): 1, ('tags,', 'semantic', 'roles,'): 1, ('semantic', 'roles,', 'semantically'): 1, ('roles,', 'semantically', 'similar'): 1, ('semantically', 'similar', 'words'): 1, ('similar', 'words', 'and'): 1, ('words', 'and', 'the'): 1, ('and', 'the', 'likelihood'): 1, ('the', 'likelihood', 'that'): 1, ('likelihood', 'that', 'the'): 1, ('that', 'the', 'sentence'): 1, ('the', 'sentence', 'makes'): 1, ('sentence', 'makes', 'sense'): 1, ('makes', 'sense', '(grammatically'): 1, ('sense', '(grammatically', '\"'): 1, ('(grammatically', '\"', 'We'): 1, ('\"', 'We', 'developed'): 1, ('We', 'developed', 'a'): 1, ('developed', 'a', 'prototype'): 1, ('a', 'prototype', 'information'): 1, ('prototype', 'information', 'retrieval'): 1, ('information', 'retrieval', 'system'): 1, ('retrieval', 'system', 'which'): 1, ('system', 'which', 'uses'): 1, ('which', 'uses', 'advanced'): 1, ('uses', 'advanced', 'natural'): 1, ('advanced', 'natural', 'language'): 1, ('processing', 'techniques', 'to'): 1, ('techniques', 'to', 'enhance'): 1, ('to', 'enhance', 'the'): 1, ('enhance', 'the', 'effectiveness'): 1, ('the', 'effectiveness', 'of'): 1, ('effectiveness', 'of', 'traditional'): 1, ('of', 'traditional', 'key-word'): 1, ('traditional', 'key-word', 'based'): 1, ('key-word', 'based', 'document'): 1, ('based', 'document', 'retrieval.'): 1, ('document', 'retrieval.', 'The'): 1, ('retrieval.', 'The', 'backbone'): 1, ('The', 'backbone', 'of'): 1, ('backbone', 'of', 'our'): 1, ('of', 'our', 'system'): 1, ('our', 'system', 'is'): 1, ('system', 'is', 'a'): 1, ('a', 'statistical', 'retrieval'): 1, ('statistical', 'retrieval', 'engine'): 1, ('retrieval', 'engine', 'which'): 1, ('engine', 'which', 'performs'): 1, ('which', 'performs', 'automated'): 1, ('performs', 'automated', 'indexing'): 1, ('automated', 'indexing', 'Abstract'): 1, ('indexing', 'Abstract', 'not'): 1, ('not', 'found', 'In'): 1, ('found', 'In', 'this'): 1, ('In', 'this', 'paper'): 1, ('paper', 'we', 'will'): 1, ('we', 'will', 'discuss'): 1, ('will', 'discuss', 'several'): 1, ('discuss', 'several', 'issues'): 1, ('several', 'issues', 'and'): 1, ('issues', 'and', 'requirements'): 1, ('and', 'requirements', 'for'): 1, ('requirements', 'for', 'enabling'): 1, ('for', 'enabling', 'natural'): 1, ('enabling', 'natural', 'language'): 1, ('processing', 'systems', 'to'): 1, ('systems', 'to', 'become'): 1, ('to', 'become', 'context-adaptive.'): 1, ('become', 'context-adaptive.', 'Given'): 1, ('context-adaptive.', 'Given', 'the'): 1, ('Given', 'the', 'fact'): 1, ('the', 'fact', 'that'): 1, ('fact', 'that', 'emerging'): 1, ('that', 'emerging', 'systems'): 1, ('emerging', 'systems', 'feature'): 1, ('systems', 'feature', 'speaker'): 1, ('feature', 'speaker', 'independent'): 1, ('speaker', 'independent', 'continuous'): 1, ('independent', 'continuous', 'speech'): 1, ('continuous', 'speech', 'recognition'): 1, ('speech', 'recognition', 'restricted'): 1, ('recognition', 'restricted', 'to'): 1, ('restricted', 'to', 'individual'): 1, ('to', 'individual', 'domains'): 1, ('individual', 'domains', 'and'): 1, ('domains', 'and', 'are'): 1, ('and', 'are', 'equipped'): 1, ('are', 'equipped', 'with'): 1, ('equipped', 'with', 'syntactic'): 1, ('with', 'syntactic', '\"'): 1, ('syntactic', '\"', 'In'): 1, ('\"', 'In', 'Fall'): 1, ('In', 'Fall', '2004'): 1, ('Fall', '2004', 'I'): 1, ('2004', 'I', 'introduced'): 1, ('I', 'introduced', 'a'): 1, ('introduced', 'a', 'new'): 1, ('a', 'new', 'course'): 1, ('new', 'course', 'called'): 1, ('course', 'called', 'Applied'): 1, ('called', 'Applied', 'Natural'): 1, ('Applied', 'Natural', 'Language'): 1, ('Language', 'Processing,', 'in'): 1, ('Processing,', 'in', 'which'): 1, ('in', 'which', 'students'): 1, ('which', 'students', 'acquire'): 1, ('students', 'acquire', 'an'): 1, ('acquire', 'an', 'understanding'): 1, ('an', 'understanding', 'of'): 1, ('understanding', 'of', 'which'): 1, ('of', 'which', 'text'): 1, ('which', 'text', 'analysis'): 1, ('text', 'analysis', 'techniques'): 1, ('analysis', 'techniques', 'are'): 1, ('techniques', 'are', 'currently'): 1, ('are', 'currently', 'feasible'): 1, ('currently', 'feasible', 'for'): 1, ('feasible', 'for', 'practical'): 1, ('for', 'practical', 'applications.'): 1, ('practical', 'applications.', '\"'): 1, ('applications.', '\"', 'Abstract'): 1, ('not', 'found', 'Abstract:'): 1, ('found', 'Abstract:', 'Natural'): 1, ('Abstract:', 'Natural', 'language'): 1, ('is', 'the', 'study'): 1, ('the', 'study', 'of'): 1, ('study', 'of', 'mathematical'): 1, ('of', 'mathematical', 'and'): 1, ('mathematical', 'and', 'computational'): 1, ('and', 'computational', 'modelling'): 1, ('computational', 'modelling', 'of'): 1, ('modelling', 'of', 'various'): 1, ('of', 'various', 'aspects'): 1, ('various', 'aspects', 'of'): 1, ('aspects', 'of', 'language'): 1, ('of', 'language', 'and'): 1, ('language', 'and', 'the'): 2, ('and', 'the', 'improvement'): 1, ('improvement', 'of', 'a'): 1, ('of', 'a', 'wide'): 1, ('a', 'wide', 'range'): 2, ('wide', 'range', 'of'): 2, ('range', 'of', 'systems.'): 1, ('of', 'systems.', 'Natural'): 1, ('systems.', 'Natural', 'language'): 1, ('Natural', 'language', 'is'): 1, ('language', 'is', 'any'): 1, ('is', 'any', 'language'): 1, ('any', 'language', 'that'): 1, ('language', 'that', 'arises'): 1, ('that', 'arises', 'as'): 1, ('arises', 'as', 'an'): 1, ('as', 'an', 'innate'): 1, ('an', 'innate', 'facility'): 1, ('innate', 'facility', 'for'): 1, ('facility', 'for', 'language'): 1, ('for', 'language', 'possessed'): 1, ('language', 'possessed', 'by'): 1, ('possessed', 'by', 'the'): 1, ('by', 'the', 'human'): 1, ('the', 'human', 'intellect;'): 1, ('human', 'intellect;', 'it'): 1, ('intellect;', 'it', 'may'): 1, ('it', 'may', '\"'): 1, ('may', '\"', 'Natural'): 1, ('Processing', '(NLP),', 'which'): 1, ('(NLP),', 'which', 'is'): 1, ('which', 'is', 'a'): 1, ('is', 'a', 'branch'): 1, ('a', 'branch', 'of'): 1, ('branch', 'of', 'artificial'): 1, ('of', 'artificial', 'intelligence,'): 1, ('artificial', 'intelligence,', 'includes'): 1, ('intelligence,', 'includes', 'speech'): 1, ('includes', 'speech', 'synthesis,'): 1, ('speech', 'synthesis,', 'Speech'): 1, ('synthesis,', 'Speech', 'recognition,'): 1, ('Speech', 'recognition,', 'and'): 1, ('recognition,', 'and', 'Machine'): 1, ('and', 'Machine', 'translation.'): 1, ('Machine', 'translation.', 'Natural'): 1, ('translation.', 'Natural', 'Language'): 1, ('Language', 'Processing', 'has'): 1, ('Processing', 'has', 'a'): 1, ('has', 'a', 'wide'): 1, ('range', 'of', 'applications'): 1, ('of', 'applications', 'in'): 1, ('applications', 'in', 'the'): 1, ('in', 'the', 'Indian'): 1, ('the', 'Indian', 'context.'): 1, ('Indian', 'context.', 'Most'): 1, ('context.', 'Most', 'of'): 1, ('Most', 'of', 'the'): 1, ('of', 'the', 'rural'): 1, ('the', 'rural', 'Indian'): 1, ('rural', 'Indian', 'community'): 1, ('Indian', 'community', 'is'): 1, ('community', 'is', 'unable'): 1, ('is', 'unable', 'to'): 1, ('unable', 'to', 'make'): 1, ('to', 'make', 'use'): 1, ('make', 'use', '\"'): 1, ('use', '\"', '\"'): 1, ('\"', '\"', 'An'): 1, ('\"', 'An', 'Evaluation'): 1, ('An', 'Evaluation', 'of'): 1, ('Evaluation', 'of', 'LOLITA'): 1, ('of', 'LOLITA', 'and'): 1, ('LOLITA', 'and', 'related'): 1, ('and', 'related', 'Natural'): 1, ('related', 'Natural', 'Language'): 1, ('Language', 'Processing', 'Systems'): 1, ('Processing', 'Systems', 'Paul'): 1, ('Systems', 'Paul', 'Callaghan'): 1, ('Paul', 'Callaghan', 'Submitted'): 1, ('Callaghan', 'Submitted', 'to'): 1, ('Submitted', 'to', 'the'): 1, ('to', 'the', 'University'): 1, ('the', 'University', 'of'): 1, ('University', 'of', 'Durham'): 1, ('of', 'Durham', 'for'): 1, ('Durham', 'for', 'the'): 1, ('for', 'the', 'degree'): 1, ('the', 'degree', 'of'): 1, ('degree', 'of', 'Ph.D.,'): 1, ('of', 'Ph.D.,', 'August'): 1, ('Ph.D.,', 'August', '1997'): 1, ('August', '1997', '---------------------'): 1, ('1997', '---------------------', 'This'): 1, ('---------------------', 'This', 'research'): 1, ('This', 'research', 'addresses'): 1, ('research', 'addresses', 'the'): 1, ('addresses', 'the', 'question,'): 1, ('the', 'question,', '\"\"how'): 1, ('question,', '\"\"how', 'do'): 1, ('\"\"how', 'do', 'we'): 1, ('do', 'we', 'evaluate'): 1, ('we', 'evaluate', 'systems'): 1, ('evaluate', 'systems', 'like'): 1, ('systems', 'like', 'LOLITA?\"\"'): 1, ('like', 'LOLITA?\"\"', 'LOLITA'): 1, ('LOLITA?\"\"', 'LOLITA', 'is'): 1, ('LOLITA', 'is', 'the'): 1, ('is', 'the', 'Natural'): 1, ('the', 'Natural', '\"'): 1, ('Natural', '\"', '\"'): 1, ('\"', '\"', 'Previous'): 1, ('\"', 'Previous', 'work'): 1, ('Previous', 'work', 'demonstrated'): 1, ('work', 'demonstrated', 'that'): 1, ('demonstrated', 'that', 'Web'): 1, ('that', 'Web', 'counts'): 1, ('Web', 'counts', 'can'): 1, ('counts', 'can', 'be'): 1, ('used', 'to', 'approximate'): 1, ('to', 'approximate', 'bigram'): 1, ('approximate', 'bigram', 'counts,'): 1, ('bigram', 'counts,', 'suggesting'): 1, ('counts,', 'suggesting', 'that'): 1, ('suggesting', 'that', 'Web-based'): 1, ('that', 'Web-based', 'frequencies'): 1, ('Web-based', 'frequencies', 'should'): 1, ('frequencies', 'should', 'be'): 1, ('should', 'be', 'useful'): 1, ('be', 'useful', 'for'): 1, ('useful', 'for', 'a'): 1, ('for', 'a', 'wide'): 1, ('a', 'wide', 'variety'): 1, ('wide', 'variety', 'of'): 1, ('variety', 'of', 'Natural'): 1, ('Processing', '(NLP)', 'tasks.'): 1, ('(NLP)', 'tasks.', 'However,'): 1, ('tasks.', 'However,', 'only'): 1, ('However,', 'only', 'a'): 1, ('only', 'a', 'limited'): 1, ('a', 'limited', 'number'): 1, ('limited', 'number', 'of'): 1, ('of', 'tasks', 'have'): 1, ('tasks', 'have', 'so'): 1, ('have', 'so', 'far'): 1, ('so', 'far', 'been'): 1, ('far', 'been', 'tested'): 1, ('been', 'tested', 'using'): 1, ('tested', 'using', 'Web-scale'): 1, ('using', 'Web-scale', 'data'): 1, ('Web-scale', 'data', 'sets'): 1, ('data', 'sets', '\"'): 1, ('sets', '\"', 'This'): 1, ('and', 'opportunities.', '16.1'): 1, ('opportunities.', '16.1', 'Introduction'): 1, ('16.1', 'Introduction', 'This'): 1, ('Introduction', 'This', 'chapter'): 1, ('This', 'chapter', 'focuses'): 1, ('chapter', 'focuses', 'on'): 1, ('focuses', 'on', 'applications'): 1, ('on', 'applications', '\"'): 1, ('applications', '\"', 'This'): 1, ('This', 'paper', 'describes'): 1, ('paper', 'describes', 'a'): 1, ('describes', 'a', 'natural'): 1, ('natural', 'language', 'system'): 1, ('language', 'system', 'which'): 1, ('system', 'which', 'improves'): 1, ('which', 'improves', 'its'): 1, ('improves', 'its', 'own'): 1, ('its', 'own', 'performance'): 1, ('own', 'performance', 'through'): 1, ('performance', 'through', 'learning.'): 1, ('through', 'learning.', 'The'): 1, ('learning.', 'The', 'system'): 1, ('The', 'system', 'processes'): 1, ('system', 'processes', 'short'): 1, ('processes', 'short', 'English'): 1, ('short', 'English', 'narratives'): 1, ('English', 'narratives', 'and'): 1, ('narratives', 'and', 'is'): 1, ('and', 'is', 'able'): 1, ('is', 'able', 'to'): 1, ('able', 'to', 'acquire,'): 1, ('to', 'acquire,', 'from'): 1, ('acquire,', 'from', 'a'): 1, ('from', 'a', 'single'): 1, ('a', 'single', 'narrative,'): 1, ('single', 'narrative,', 'a'): 1, ('narrative,', 'a', 'new'): 1, ('a', 'new', 'schema'): 1, ('new', 'schema', 'for'): 1, ('schema', 'for', 'a'): 1, ('for', 'a', 'stereotypical'): 1, ('a', 'stereotypical', 'set'): 1, ('stereotypical', 'set', 'of'): 1, ('set', 'of', 'actions.'): 1, ('of', 'actions.', 'During'): 1, ('actions.', 'During', 'the'): 1, ('During', 'the', 'understanding'): 1, ('the', 'understanding', 'process,'): 1, ('understanding', 'process,', 'the'): 1, ('process,', 'the', 'system'): 1, ('the', 'system', 'attempts'): 1, ('system', 'attempts', '\"'): 1, ('attempts', '\"', '\"'): 1, ('\"', 'We', 'classify'): 1, ('We', 'classify', 'and'): 1, ('classify', 'and', 'review'): 1, ('and', 'review', 'current'): 1, ('review', 'current', 'approaches'): 1, ('current', 'approaches', 'to'): 1, ('approaches', 'to', 'software'): 1, ('to', 'software', 'infrastructure'): 1, ('software', 'infrastructure', 'for'): 1, ('infrastructure', 'for', 'research,'): 1, ('for', 'research,', 'development'): 1, ('research,', 'development', 'and'): 1, ('development', 'and', 'delivery'): 1, ('and', 'delivery', 'of'): 1, ('delivery', 'of', 'NLP'): 1, ('of', 'NLP', 'systems.'): 1, ('NLP', 'systems.', 'The'): 1, ('systems.', 'The', 'task'): 1, ('The', 'task', '\"'): 1, ('task', '\"', 'Confidence'): 1, ('\"', 'Confidence', 'measures'): 1, ('Confidence', 'measures', 'are'): 1, ('measures', 'are', 'a'): 1, ('are', 'a', 'practical'): 1, ('a', 'practical', 'solution'): 1, ('practical', 'solution', 'for'): 1, ('solution', 'for', 'improving'): 1, ('for', 'improving', 'the'): 1, ('improving', 'the', 'usefulness'): 1, ('the', 'usefulness', 'of'): 1, ('usefulness', 'of', 'Natural'): 1, ('Language', 'Processing', 'applications.'): 1, ('Processing', 'applications.', 'Confidence'): 1, ('applications.', 'Confidence', 'estimation'): 1, ('Confidence', 'estimation', 'is'): 1, ('estimation', 'is', 'a'): 1, ('is', 'a', 'generic'): 1, ('a', 'generic', 'machine'): 1, ('generic', 'machine', 'learning'): 1, ('machine', 'learning', 'approach'): 1, ('learning', 'approach', 'for'): 1, ('approach', 'for', 'deriving'): 1, ('for', 'deriving', 'confidence'): 1, ('deriving', 'confidence', 'measures.'): 1, ('confidence', 'measures.', 'We'): 1, ('measures.', 'We', 'give'): 1, ('We', 'give', 'an'): 1, ('give', 'an', 'overview'): 1, ('an', 'overview', 'of'): 1, ('overview', 'of', 'the'): 1, ('of', 'the', 'application'): 1, ('application', 'of', 'confidence'): 1, ('of', 'confidence', 'estimation'): 1, ('confidence', 'estimation', 'in'): 1, ('estimation', 'in', 'various'): 1, ('in', 'various', 'fields'): 1, ('various', 'fields', '\"'): 1, ('fields', '\"', '!'): 1, ('\"', '!', 'lex-sign'): 1, ('!', 'lex-sign', 'sense-id'): 3, ('lex-sign', 'sense-id', ':'): 3, ('sense-id', ':', 'sense-id'): 3, (':', 'sense-id', 'dictionary'): 1, ('sense-id', 'dictionary', '?'): 1, ('dictionary', '?', '='): 1, ('?', '=', '\"\"LDOCE\"\"'): 1, ('=', '\"\"LDOCE\"\"', '!'): 1, ('\"\"LDOCE\"\"', '!', 'lex-sign'): 1, (':', 'sense-id', 'ldb-entry-no'): 1, ('sense-id', 'ldb-entry-no', '?'): 1, ('ldb-entry-no', '?', '='): 1, ('?', '=', '\"\"12364\"\"'): 1, ('=', '\"\"12364\"\"', '!'): 1, ('\"\"12364\"\"', '!', 'lex-sign'): 1, (':', 'sense-id', 'sense-no'): 1, ('sense-id', 'sense-no', '?'): 1, ('sense-no', '?', '='): 1, ('?', '=', '\"\"0\"\".'): 1, ('=', '\"\"0\"\".', 'When'): 1, ('\"\"0\"\".', 'When', 'loaded'): 1, ('When', 'loaded', 'into'): 1, ('loaded', 'into', 'the'): 1, ('into', 'the', 'LKB,'): 1, ('the', 'LKB,', '(9)'): 1, ('LKB,', '(9)', 'will'): 1, ('(9)', 'will', 'be'): 1, ('will', 'be', 'expanded'): 1, ('be', 'expanded', 'into'): 1, ('expanded', 'into', 'a'): 1, ('into', 'a', 'fully-fledged'): 1, ('a', 'fully-fledged', 'representation'): 1, ('fully-fledged', 'representation', 'for'): 1, ('representation', 'for', 'the'): 1, ('for', 'the', 'transitive'): 1, ('the', 'transitive', 'use'): 1, ('transitive', 'use', 'of'): 1, ('use', 'of', 'experience;'): 1, ('of', 'experience;', 'by'): 1, ('experience;', 'by', 'integrating'): 1, ('by', 'integrating', 'word-specific'): 1, ('integrating', 'word-specific', 'information'): 1, ('word-specific', 'information', 'provided'): 1, ('information', 'provided', 'by'): 1, ('provided', 'by', '(9)'): 1, ('by', '(9)', 'with'): 1, ('(9)', 'with', 'the'): 1, ('with', 'the', 'information'): 1, ('the', 'information', 'encoded'): 1, ('information', 'encoded', 'by'): 1, ('encoded', 'by', 'the'): 1, ('by', 'the', 'LKB'): 1, ('the', 'LKB', 'type'): 1, ('LKB', 'type', 'strict-trans-sign.'): 1, ('type', 'strict-trans-sign.', 'Thus,'): 1, ('strict-trans-sign.', 'Thus,', 'although'): 1, ('Thus,', 'although', 'neither'): 1, ('although', 'neither', 'LDOCE,'): 1, ('neither', 'LDOCE,', 'LLCE'): 1, ('LDOCE,', 'LLCE', 'or'): 1, ('LLCE', 'or', 'the'): 1, ('or', 'the', 'earlier'): 1, ('the', 'earlier', 'subcategorised'): 1, ('earlier', 'subcategorised', 'lexicon'): 1, ('subcategorised', 'lexicon', 'contain'): 1, ('lexicon', 'contain', 'all'): 1, ('contain', 'all', 'the'): 1, ('all', 'the', 'information'): 1, ('the', 'information', 'about'): 1, ('information', 'about', 'psychological'): 1, ('about', 'psychological', 'verbs'): 1, ('psychological', 'verbs', 'defined'): 1, ('verbs', 'defined', 'in'): 1, ('defined', 'in', 'Sanfilippo&aposs'): 1, ('in', 'Sanfilippo&aposs', 'type'): 1, ('Sanfilippo&aposs', 'type', 'system,'): 1, ('type', 'system,', 'by'): 1, ('system,', 'by', 'using'): 1, ('by', 'using', 'the'): 1, ('using', 'the', 'conjunction'): 1, ('the', 'conjunction', 'of'): 1, ('conjunction', 'of', 'information'): 1, ('of', 'information', 'available'): 1, ('information', 'available', 'from'): 1, ('available', 'from', 'all'): 1, ('from', 'all', 'three,'): 1, ('all', 'three,', 'it'): 1, ('three,', 'it', 'proved'): 1, ('it', 'proved', 'possible'): 1, ('proved', 'possible', 'to'): 1, ('possible', 'to', 'effectively'): 1, ('to', 'effectively', 'enrich'): 1, ('effectively', 'enrich', 'this'): 1, ('enrich', 'this', 'information'): 1, ('this', 'information', 'at'): 1, ('information', 'at', 'the'): 1, ('at', 'the', 'same'): 1, ('the', 'same', 'time'): 1, ('same', 'time', 'as'): 1, ('time', 'as', 'mapping'): 1, ('as', 'mapping', 'it'): 1, ('mapping', 'it', 'into'): 1, ('it', 'into', 'a'): 1, ('into', 'a', 'formal'): 1, ('a', 'formal', 'representation.'): 1, ('formal', 'representation.', '4.2.5'): 1, ('representation.', '4.2.5', 'Towards'): 1, ('4.2.5', 'Towards', 'a'): 1, ('Towards', 'a', 'Multilingual'): 1, ('a', 'Multilingual', 'LKB'): 1, ('Multilingual', 'LKB', 'A'): 1, ('LKB', 'A', 'goal'): 1, ('A', 'goal', 'of'): 1, ('goal', 'of', 'ACQUILEX'): 1, ('of', 'ACQUILEX', 'is'): 1, ('ACQUILEX', 'is', 'to'): 1, ('is', 'to', 'demonstrate'): 1, ('to', 'demonstrate', 'that'): 1, ('demonstrate', 'that', 'an'): 1, ('that', 'an', 'LKB'): 1, ('an', 'LKB', 'can'): 1, ('LKB', 'can', 'be'): 1, ('can', 'be', 'produced'): 1, ('be', 'produced', 'that'): 1, ('produced', 'that', 'usefully'): 1, ('that', 'usefully', 'exploits'): 1, ('usefully', 'exploits', 'various'): 1, ('exploits', 'various', 'MRD'): 1, ('various', 'MRD', 'sources'): 1, ('MRD', 'sources', 'and'): 1, ('sources', 'and', 'integrates'): 1, ('and', 'integrates', 'multilingual'): 1, ('integrates', 'multilingual', 'information.'): 1, ('multilingual', 'information.', 'The'): 1, ('information.', 'The', 'use'): 1, ('The', 'use', 'of'): 1, ('use', 'of', 'a'): 1, ('of', 'a', 'common'): 1, ('a', 'common', 'LRL'): 1, ('common', 'LRL', 'with'): 1, ('LRL', 'with', 'a'): 1, ('with', 'a', 'common'): 1, ('a', 'common', 'type'): 1, ('common', 'type', 'system,'): 1, ('type', 'system,', 'makes'): 1, ('system,', 'makes', 'it'): 1, ('makes', 'it', 'possi...'): 1, ('it', 'possi...', '\"'): 1, ('possi...', '\"', '\"'): 1, ('describe', 'the', 'design'): 1, ('design', 'and', 'use'): 1, ('use', 'of', 'the'): 2, ('of', 'the', 'Stanford'): 1, ('the', 'Stanford', 'CoreNLP'): 1, ('Stanford', 'CoreNLP', 'toolkit,'): 1, ('CoreNLP', 'toolkit,', 'an'): 1, ('toolkit,', 'an', 'extensible'): 1, ('an', 'extensible', 'pipeline'): 1, ('extensible', 'pipeline', 'that'): 1, ('pipeline', 'that', 'provides'): 1, ('that', 'provides', 'core'): 1, ('provides', 'core', 'natural'): 1, ('core', 'natural', 'lan-guage'): 1, ('natural', 'lan-guage', 'analysis.'): 1, ('lan-guage', 'analysis.', 'This'): 1, ('analysis.', 'This', 'toolkit'): 1, ('This', 'toolkit', 'is'): 1, ('toolkit', 'is', 'quite'): 1, ('is', 'quite', 'widely'): 1, ('quite', 'widely', 'used,'): 1, ('widely', 'used,', 'both'): 1, ('used,', 'both', 'in'): 1, ('both', 'in', 'the'): 1, ('in', 'the', 'research'): 1, ('the', 'research', 'NLP'): 1, ('research', 'NLP', 'community'): 1, ('NLP', 'community', 'and'): 1, ('community', 'and', 'also'): 1, ('and', 'also', 'among'): 1, ('also', 'among', 'commercial'): 1, ('among', 'commercial', 'and'): 1, ('commercial', 'and', 'govern-ment'): 1, ('and', 'govern-ment', 'users'): 1, ('govern-ment', 'users', 'of'): 1, ('users', 'of', 'open'): 1, ('of', 'open', 'source'): 1, ('open', 'source', 'NLP'): 1, ('source', 'NLP', 'technol-ogy.'): 1, ('NLP', 'technol-ogy.', 'We'): 1, ('technol-ogy.', 'We', 'suggest'): 1, ('We', 'suggest', '\"'): 1, ('suggest', '\"', '\"'): 1, ('\"', '\"', 'Gaussian'): 1, ('\"', 'Gaussian', 'Processes'): 1, ('Gaussian', 'Processes', '(GPs)'): 1, ('Processes', '(GPs)', 'are'): 1, ('(GPs)', 'are', 'a'): 1, ('are', 'a', 'powerful'): 1, ('a', 'powerful', 'mod-elling'): 1, ('powerful', 'mod-elling', 'framework'): 1, ('mod-elling', 'framework', 'incorporating'): 1, ('framework', 'incorporating', 'kernels'): 1, ('incorporating', 'kernels', 'and'): 1, ('kernels', 'and', 'Bayesian'): 1, ('and', 'Bayesian', 'inference,'): 1, ('Bayesian', 'inference,', 'and'): 1, ('inference,', 'and', 'are'): 1, ('and', 'are', 'recognised'): 1, ('are', 'recognised', 'as'): 1, ('recognised', 'as', 'state-of-the-art'): 1, ('as', 'state-of-the-art', 'for'): 1, ('state-of-the-art', 'for', 'many'): 1, ('for', 'many', 'machine'): 1, ('many', 'machine', 'learning'): 1, ('machine', 'learning', 'tasks.'): 1, ('learning', 'tasks.', '\"'): 1, ('tasks.', '\"', ':'): 1, ('\"', ':', 'A'): 1, (':', 'A', 'fundamental'): 1, ('A', 'fundamental', 'issue'): 1, ('fundamental', 'issue', 'in'): 1, ('issue', 'in', 'natural'): 1, ('is', 'the', 'prerequisite'): 1, ('the', 'prerequisite', 'of'): 1, ('prerequisite', 'of', 'an'): 1, ('of', 'an', 'enormous'): 1, ('an', 'enormous', 'quantity'): 1, ('enormous', 'quantity', 'of'): 1, ('quantity', 'of', 'preprogrammed'): 1, ('of', 'preprogrammed', 'knowledge'): 1, ('preprogrammed', 'knowledge', 'concerning'): 1, ('knowledge', 'concerning', 'both'): 1, ('concerning', 'both', 'the'): 1, ('both', 'the', 'language'): 1, ('the', 'language', 'and'): 1, ('and', 'the', 'domain'): 1, ('the', 'domain', 'under'): 1, ('domain', 'under', 'examination.'): 1, ('under', 'examination.', 'Manual'): 1, ('examination.', 'Manual', 'acquisition'): 1, ('Manual', 'acquisition', 'of'): 1, ('acquisition', 'of', 'this'): 1, ('of', 'this', 'knowledge'): 1, ('this', 'knowledge', 'is'): 1, ('knowledge', 'is', 'tedious'): 1, ('is', 'tedious', 'and'): 1, ('tedious', 'and', 'error'): 1, ('and', 'error', 'prone.'): 1, ('error', 'prone.', 'Development'): 1, ('prone.', 'Development', 'of'): 1, ('Development', 'of', 'an'): 1, ('of', 'an', 'automated'): 1, ('an', 'automated', 'acquisition'): 1, ('automated', 'acquisition', '\"'): 1, ('acquisition', '\"', '\"\"'): 1, ('\"', '\"\"', 'that'): 1, ('\"\"', 'that', 'supports'): 1, ('that', 'supports', 'sophisticated'): 1, ('supports', 'sophisticated', 'natural'): 1, ('sophisticated', 'natural', 'language'): 1, ('language', 'processing', 'while'): 1, ('processing', 'while', 'significantly'): 1, ('while', 'significantly', 'simplifying'): 1, ('significantly', 'simplifying', 'the'): 1, ('simplifying', 'the', 'interface'): 1, ('the', 'interface', 'between'): 1, ('interface', 'between', 'domain-specific'): 1, ('between', 'domain-specific', 'knowledge'): 1, ('domain-specific', 'knowledge', 'and'): 1, ('knowledge', 'and', 'general'): 1, ('and', 'general', 'linguis-'): 1, ('general', 'linguis-', 'tic'): 1, ('linguis-', 'tic', 'resources.'): 1, ('tic', 'resources.', 'This'): 1, ('resources.', 'This', 'paper'): 1, ('This', 'paper', 'presents'): 2, ('paper', 'presents', 'the'): 1, ('presents', 'the', 'results'): 1, ('the', 'results', 'of'): 1, ('results', 'of', 'our'): 1, ('of', 'our', 'experiences'): 1, ('our', 'experiences', 'in'): 1, ('experiences', 'in', 'designing'): 1, ('in', 'designing', 'and'): 1, ('designing', 'and', 'using'): 1, ('and', 'using', 'the'): 1, ('using', 'the', 'upper'): 1, ('the', 'upper', 'model'): 1, ('upper', 'model', 'in'): 1, ('model', 'in', 'a'): 1, ('in', 'a', 'variety'): 1, ('a', 'variety', 'of'): 1, ('variety', 'of', 'applications'): 1, ('of', 'applications', 'over'): 1, ('applications', 'over', 'the'): 1, ('over', 'the', 'past'): 1, ('the', 'past', '5'): 1, ('past', '5', 'years'): 1, ('5', 'years', '\"'): 1, ('years', '\"', '\"'): 1, ('\"', '\"', 'into'): 1, ('\"', 'into', 'the'): 1, ('into', 'the', 'same'): 1, ('the', 'same', 'or'): 1, ('same', 'or', 'neighboring'): 1, ('or', 'neighboring', 'map'): 1, ('neighboring', 'map', 'nodes.'): 1, ('map', 'nodes.', 'Nodes'): 1, ('nodes.', 'Nodes', 'may'): 1, ('Nodes', 'may', 'thus'): 1, ('may', 'thus', 'be'): 1, ('thus', 'be', 'viewed'): 1, ('be', 'viewed', 'as'): 1, ('viewed', 'as', 'word'): 1, ('as', 'word', 'categories.'): 1, ('word', 'categories.', 'Although'): 1, ('categories.', 'Although', 'no'): 1, ('Although', 'no', 'a'): 1, ('no', 'a', 'priori'): 1, ('a', 'priori', 'information'): 1, ('priori', 'information', 'about'): 1, ('information', 'about', 'classes'): 1, ('about', 'classes', 'is'): 1, ('classes', 'is', 'given,'): 1, ('is', 'given,', 'during'): 1, ('given,', 'during', 'the'): 1, ('during', 'the', 'self-organizing'): 1, ('the', 'self-organizing', 'process'): 1, ('self-organizing', 'process', 'a'): 1, ('process', 'a', 'model'): 1, ('a', 'model', 'of'): 1, ('the', 'word', 'classes'): 1, ('word', 'classes', 'emerges.'): 1, ('classes', 'emerges.', 'The'): 1, ('emerges.', 'The', 'central'): 1, ('The', 'central', 'topic'): 1, ('central', 'topic', 'of'): 1, ('topic', 'of', 'the'): 1, ('of', 'the', 'thesis'): 1, ('the', 'thesis', 'is'): 1, ('thesis', 'is', 'the'): 1, ('is', 'the', 'use'): 1, ('of', 'the', 'SOM'): 1, ('the', 'SOM', 'in'): 1, ('SOM', 'in', 'natural'): 1, ('processing.', 'The', 'approach'): 1, ('The', 'approach', '\"'): 1, ('approach', '\"', '\"'): 1, ('paper', 'presents', 'a'): 1, ('presents', 'a', 'workbench'): 1, ('a', 'workbench', 'built'): 1, ('workbench', 'built', 'by'): 1, ('built', 'by', 'Priberam'): 1, ('by', 'Priberam', 'InformÃ¡tica'): 1, ('Priberam', 'InformÃ¡tica', 'for'): 1, ('InformÃ¡tica', 'for', 'the'): 1, ('for', 'the', 'development'): 1, ('of', 'the', 'companyâ\\x80\\x99s'): 1, ('the', 'companyâ\\x80\\x99s', 'natural'): 1, ('companyâ\\x80\\x99s', 'natural', 'language'): 1, ('language', 'processing', 'technology.'): 1, ('processing', 'technology.', 'This'): 1, ('technology.', 'This', 'workbench'): 1, ('This', 'workbench', 'includes'): 1, ('workbench', 'includes', 'a'): 1, ('includes', 'a', 'set'): 1, ('a', 'set', 'of'): 1, ('set', 'of', 'linguistic'): 1, ('of', 'linguistic', 'resources'): 1, ('linguistic', 'resources', 'and'): 1, ('resources', 'and', 'software'): 1, ('and', 'software', 'tools'): 1, ('software', 'tools', 'that'): 1, ('tools', 'that', 'have'): 1, ('that', 'have', 'been'): 1, ('have', 'been', 'applied'): 1, ('been', 'applied', 'in'): 1, ('applied', 'in', 'a'): 1, ('in', 'a', 'considerable'): 1, ('a', 'considerable', 'number'): 1, ('considerable', 'number', 'of'): 1, ('number', 'of', 'practical'): 1, ('of', 'practical', 'purposes,'): 1, ('practical', 'purposes,', 'covering'): 1, ('purposes,', 'covering', '\"'): 1, ('covering', '\"', 'Abstractâ\\x80\\x94Natural'): 1, ('\"', 'Abstractâ\\x80\\x94Natural', 'Language'): 1, ('Abstractâ\\x80\\x94Natural', 'Language', 'Processing'): 1, ('(NLP)', 'is', 'an'): 1, ('is', 'an', 'effective'): 1, ('an', 'effective', 'approach'): 1, ('effective', 'approach', 'for'): 1, ('approach', 'for', 'bringing'): 1, ('for', 'bringing', 'improvement'): 1, ('bringing', 'improvement', 'in'): 1, ('improvement', 'in', 'educational'): 1, ('in', 'educational', 'setting.'): 1, ('educational', 'setting.', 'Implementing'): 1, ('setting.', 'Implementing', 'NLP'): 1, ('Implementing', 'NLP', 'involves'): 1, ('NLP', 'involves', 'initiating'): 1, ('involves', 'initiating', 'the'): 1, ('initiating', 'the', 'process'): 1, ('process', 'of', 'learning'): 1, ('of', 'learning', 'through'): 1, ('learning', 'through', 'the'): 1, ('through', 'the', 'natural'): 1, ('the', 'natural', 'acquisition'): 1, ('natural', 'acquisition', 'in'): 1, ('acquisition', 'in', 'the'): 1, ('in', 'the', 'educational'): 1, ('the', 'educational', 'systems.'): 1, ('educational', 'systems.', 'It'): 1, ('systems.', 'It', 'is'): 1, ('It', 'is', 'based'): 1, ('is', 'based', 'on'): 1, ('based', 'on', 'effective'): 1, ('on', 'effective', 'approaches'): 1, ('effective', 'approaches', 'for'): 1, ('approaches', 'for', 'providing'): 1, ('for', 'providing', 'a'): 1, ('providing', 'a', 'solution'): 1, ('a', 'solution', '\"'): 1, ('solution', '\"', 'ABSTRACT:'): 1, ('\"', 'ABSTRACT:', 'After'): 1, ('ABSTRACT:', 'After', 'twenty'): 1, ('After', 'twenty', 'years'): 1, ('twenty', 'years', 'of'): 1, ('years', 'of', 'disfavor,'): 1, ('of', 'disfavor,', 'a'): 1, ('disfavor,', 'a', 'technology'): 1, ('a', 'technology', 'has'): 1, ('technology', 'has', 'returned'): 1, ('has', 'returned', 'which'): 1, ('returned', 'which', 'imitates'): 1, ('which', 'imitates', 'the'): 1, ('imitates', 'the', 'processes'): 1, ('the', 'processes', 'of'): 1, ('processes', 'of', 'the'): 1, ('of', 'the', 'brain.'): 1, ('the', 'brain.', 'Natural'): 1, ('brain.', 'Natural', 'language'): 1, ('Natural', 'language', 'experiments'): 1, ('language', 'experiments', '(Sejnowski'): 1, ('experiments', '(Sejnowski', '&'): 1, ('(Sejnowski', '&', 'Rosenberg:'): 1, ('&', 'Rosenberg:', '1986)'): 1, ('Rosenberg:', '1986)', 'demonstrate'): 1, ('1986)', 'demonstrate', 'that'): 1, ('demonstrate', 'that', 'neural'): 1, ('that', 'neural', 'network'): 1, ('neural', 'network', 'computing'): 1, ('network', 'computing', 'architecture'): 1, ('computing', 'architecture', 'can'): 1, ('architecture', 'can', 'learn'): 1, ('can', 'learn', 'from'): 1, ('learn', 'from', 'actual'): 1, ('from', 'actual', 'spoken'): 1, ('actual', 'spoken', 'language,'): 1, ('spoken', 'language,', 'observe'): 1, ('language,', 'observe', 'rules'): 1, ('observe', 'rules', 'of'): 1, ('rules', 'of', 'pronunciation'): 1, ('of', 'pronunciation', '\"'): 1, ('pronunciation', '\"', '\"'): 1, ('\"', '\"', 'Text'): 1, ('\"', 'Text', 'statistics'): 1, ('Text', 'statistics', 'are'): 1, ('statistics', 'are', 'frequently'): 1, ('are', 'frequently', 'used'): 1, ('frequently', 'used', 'in'): 1, ('used', 'in', 'stylometry'): 1, ('in', 'stylometry', 'and'): 1, ('stylometry', 'and', 'cryptography'): 1, ('and', 'cryptography', 'studies.'): 1, ('cryptography', 'studies.', 'In'): 1, ('studies.', 'In', 'this'): 1, ('this', 'paper,', 'some'): 1, ('paper,', 'some', 'text'): 1, ('some', 'text', 'statistics'): 1, ('text', 'statistics', 'tools'): 1, ('statistics', 'tools', 'are'): 1, ('tools', 'are', 'developed'): 1, ('are', 'developed', 'in'): 1, ('developed', 'in', 'ISO'): 1, ('in', 'ISO', 'Prolog'): 1, ('ISO', 'Prolog', 'for'): 1, ('Prolog', 'for', 'natural'): 1, ('language', 'processing.', 'Details'): 1, ('processing.', 'Details', 'are'): 1, ('Details', 'are', 'given'): 1, ('are', 'given', 'on'): 1, ('given', 'on', 'the'): 1, ('on', 'the', 'usage'): 1, ('the', 'usage', 'of'): 1, ('usage', 'of', '21'): 1, ('of', '21', 'user-callable'): 1, ('21', 'user-callable', 'predicates.'): 1, ('user-callable', 'predicates.', 'Logic'): 1, ('predicates.', 'Logic', 'and'): 1, ('Logic', 'and', 'limitations'): 1, ('and', 'limitations', 'of'): 1, ('limitations', 'of', 'the'): 1, ('of', 'the', 'program'): 1, ('the', 'program', 'are'): 1, ('program', 'are', 'also'): 1, ('are', 'also', 'discussed'): 1, ('also', 'discussed', '\"'): 1, ('discussed', '\"', '\"'): 1, ('\"', 'We', 'summarize'): 1, ('We', 'summarize', 'our'): 1, ('summarize', 'our', 'experience'): 1, ('our', 'experience', 'using'): 1, ('experience', 'using', 'FrameNet'): 1, ('using', 'FrameNet', 'in'): 1, ('FrameNet', 'in', 'two'): 1, ('in', 'two', 'rather'): 1, ('two', 'rather', 'different'): 1, ('rather', 'different', 'projects'): 1, ('different', 'projects', 'in'): 1, ('projects', 'in', 'natural'): 1, ('language', 'processing', '(NLP).'): 1, ('processing', '(NLP).', 'We'): 1, ('(NLP).', 'We', 'conclude'): 1, ('We', 'conclude', 'that'): 1, ('conclude', 'that', 'NLP'): 1, ('that', 'NLP', 'can'): 1, ('NLP', 'can', 'benefit'): 1, ('can', 'benefit', 'from'): 1, ('benefit', 'from', 'FrameNet'): 1, ('from', 'FrameNet', 'in'): 1, ('FrameNet', 'in', 'different'): 1, ('in', 'different', 'ways,'): 1, ('different', 'ways,', 'but'): 1, ('ways,', 'but', 'we'): 1, ('but', 'we', 'sketch'): 1, ('we', 'sketch', 'some'): 1, ('sketch', 'some', 'problems'): 1, ('some', 'problems', 'that'): 1, ('problems', 'that', 'need'): 1, ('that', 'need', 'to'): 1, ('to', 'be', 'overcome.'): 1, ('be', 'overcome.', '1'): 1, ('overcome.', '1', '\"'): 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yM4f0LdalPD",
        "outputId": "180a4e21-529e-4ab0-b3d2-8c289ec8f7e3"
      },
      "source": [
        "from __future__ import division\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "\r\n",
        "f = open('/content/Abstractfile.csv', 'r')\r\n",
        "bigramfile = f.read()\r\n",
        "from nltk.tokenize import sent_tokenize\r\n",
        "sent_tokenize_list = sent_tokenize(bigramfile)\r\n",
        "print(\"count of w2,w1/w1\")\r\n",
        "for i in sent_tokenize_list:\r\n",
        "    tokens = i.split()\r\n",
        "    bigrams = (tuple(nltk.bigrams(tokens)))\r\n",
        "    bigrams_frequency = nltk.FreqDist(bigrams)\r\n",
        "    for key , value  in bigrams_frequency.items():\r\n",
        "        \r\n",
        "        unigrams = tokens.count(key[0])\r\n",
        "        final_output = value / unigrams\r\n",
        "        print('{}  : {}' .format(key , final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count of w2,w1/w1\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', '\"')  : 1.0\n",
            "('\"', 'describe')  : 1.0\n",
            "('describe', 'a')  : 1.0\n",
            "('a', 'method')  : 1.0\n",
            "('method', 'for')  : 1.0\n",
            "('for', 'statistical')  : 1.0\n",
            "('statistical', 'modeling')  : 1.0\n",
            "('modeling', 'based')  : 1.0\n",
            "('based', 'on')  : 1.0\n",
            "('on', 'maximum')  : 1.0\n",
            "('maximum', 'entropy.')  : 1.0\n",
            "('We', 'present')  : 1.0\n",
            "('present', 'a')  : 1.0\n",
            "('a', 'maximum-likelihood')  : 1.0\n",
            "('maximum-likelihood', 'approach')  : 1.0\n",
            "('approach', 'for')  : 0.5\n",
            "('for', 'automatically')  : 1.0\n",
            "('automatically', 'constructing')  : 1.0\n",
            "('constructing', 'maximum')  : 1.0\n",
            "('maximum', 'entropy')  : 1.0\n",
            "('entropy', 'models')  : 1.0\n",
            "('models', 'and')  : 1.0\n",
            "('and', 'describe')  : 1.0\n",
            "('describe', 'how')  : 1.0\n",
            "('how', 'to')  : 1.0\n",
            "('to', 'implement')  : 1.0\n",
            "('implement', 'this')  : 1.0\n",
            "('this', 'approach')  : 1.0\n",
            "('approach', 'efficiently,')  : 0.5\n",
            "('efficiently,', 'using')  : 1.0\n",
            "('using', 'as')  : 1.0\n",
            "('as', 'examples')  : 1.0\n",
            "('examples', 'several')  : 1.0\n",
            "('several', 'problems')  : 1.0\n",
            "('problems', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('processing.', '\"')  : 1.0\n",
            "('Scaling', 'conditional')  : 1.0\n",
            "('conditional', 'random')  : 1.0\n",
            "('random', 'fields')  : 1.0\n",
            "('fields', 'for')  : 1.0\n",
            "('for', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'Terms')  : 0.5\n",
            "('Terms', 'and')  : 1.0\n",
            "('and', 'Conditions:')  : 0.4\n",
            "('Conditions:', 'Terms')  : 0.5\n",
            "('Conditions:', 'Copyright')  : 0.5\n",
            "('Copyright', 'in')  : 1.0\n",
            "('in', 'works')  : 0.25\n",
            "('works', 'deposited')  : 1.0\n",
            "('deposited', 'in')  : 1.0\n",
            "('in', 'Minerva')  : 0.25\n",
            "('Minerva', 'Access')  : 1.0\n",
            "('Access', 'is')  : 1.0\n",
            "('is', 'retained')  : 1.0\n",
            "('retained', 'by')  : 1.0\n",
            "('by', 'the')  : 1.0\n",
            "('the', '\"')  : 0.5\n",
            "('\"', 'The')  : 1.0\n",
            "('The', 'paper')  : 1.0\n",
            "('paper', 'addresses')  : 1.0\n",
            "('addresses', 'the')  : 1.0\n",
            "('the', 'issue')  : 0.5\n",
            "('issue', 'of')  : 1.0\n",
            "('of', 'cooperation')  : 1.0\n",
            "('cooperation', 'between')  : 1.0\n",
            "('between', 'linguistics')  : 1.0\n",
            "('linguistics', 'and')  : 1.0\n",
            "('and', 'natural')  : 0.2\n",
            "('processing', '(NLP),')  : 0.5\n",
            "('(NLP),', 'in')  : 1.0\n",
            "('in', 'general,')  : 0.25\n",
            "('general,', 'and')  : 1.0\n",
            "('and', 'between')  : 0.2\n",
            "('and', 'machine')  : 0.2\n",
            "('machine', 'translation')  : 1.0\n",
            "('translation', '(MT),')  : 1.0\n",
            "('(MT),', 'in')  : 1.0\n",
            "('in', 'particular.')  : 0.25\n",
            "('It', 'focuses')  : 1.0\n",
            "('focuses', 'on')  : 1.0\n",
            "('on', 'just')  : 1.0\n",
            "('just', 'one')  : 1.0\n",
            "('one', 'direction')  : 1.0\n",
            "('direction', 'of')  : 1.0\n",
            "('of', 'such')  : 0.5\n",
            "('such', 'cooperation,')  : 1.0\n",
            "('cooperation,', 'namely')  : 1.0\n",
            "('namely', 'applications')  : 1.0\n",
            "('applications', 'of')  : 1.0\n",
            "('of', 'linguistics')  : 0.5\n",
            "('linguistics', 'to')  : 1.0\n",
            "('to', 'NLP,')  : 0.3333333333333333\n",
            "('NLP,', 'virtually')  : 1.0\n",
            "('virtually', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'In')  : 0.5\n",
            "('In', 'most')  : 1.0\n",
            "('most', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'applications,')  : 1.0\n",
            "('applications,', 'Description')  : 1.0\n",
            "('Description', 'Logics')  : 1.0\n",
            "('Logics', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', 'used')  : 1.0\n",
            "('used', 'to')  : 1.0\n",
            "('to', 'encode')  : 0.3333333333333333\n",
            "('encode', 'in')  : 1.0\n",
            "('in', 'a')  : 1.0\n",
            "('a', 'knowledge')  : 1.0\n",
            "('knowledge', 'base')  : 1.0\n",
            "('base', 'some')  : 1.0\n",
            "('some', 'syntactic,')  : 1.0\n",
            "('syntactic,', 'semantic,')  : 1.0\n",
            "('semantic,', 'and')  : 1.0\n",
            "('and', 'pragmatic')  : 0.5\n",
            "('pragmatic', 'elements')  : 1.0\n",
            "('elements', 'needed')  : 1.0\n",
            "('needed', 'to')  : 1.0\n",
            "('to', 'drive')  : 0.3333333333333333\n",
            "('drive', 'the')  : 1.0\n",
            "('the', 'semantic')  : 0.5\n",
            "('semantic', 'interpretation')  : 1.0\n",
            "('interpretation', 'and')  : 1.0\n",
            "('and', 'the')  : 0.5\n",
            "('the', 'natural')  : 0.5\n",
            "('language', 'generation')  : 0.5\n",
            "('generation', 'processes.')  : 1.0\n",
            "('More', 'recently,')  : 1.0\n",
            "('recently,', 'Description')  : 1.0\n",
            "('Description', 'Logics')  : 1.0\n",
            "('Logics', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'propose')  : 1.0\n",
            "('propose', 'a')  : 1.0\n",
            "('a', 'unified')  : 1.0\n",
            "('unified', 'neural')  : 1.0\n",
            "('neural', 'network')  : 1.0\n",
            "('network', 'architecture')  : 1.0\n",
            "('architecture', 'and')  : 1.0\n",
            "('and', 'learning')  : 0.5\n",
            "('learning', 'algorithm')  : 1.0\n",
            "('algorithm', 'that')  : 1.0\n",
            "('that', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'applied')  : 1.0\n",
            "('applied', 'to')  : 1.0\n",
            "('to', 'various')  : 1.0\n",
            "('various', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'tasks')  : 1.0\n",
            "('tasks', 'including')  : 1.0\n",
            "('including', 'part-of-speech')  : 1.0\n",
            "('part-of-speech', 'tagging,')  : 1.0\n",
            "('tagging,', 'chunking,')  : 1.0\n",
            "('chunking,', 'named')  : 1.0\n",
            "('named', 'entity')  : 1.0\n",
            "('entity', 'recognition,')  : 1.0\n",
            "('recognition,', 'and')  : 1.0\n",
            "('and', 'semantic')  : 0.5\n",
            "('semantic', 'role')  : 1.0\n",
            "('role', 'labeling.')  : 1.0\n",
            "('This', 'versatility')  : 1.0\n",
            "('versatility', 'is')  : 1.0\n",
            "('is', 'achieved')  : 1.0\n",
            "('achieved', 'by')  : 1.0\n",
            "('by', 'trying')  : 1.0\n",
            "('trying', 'to')  : 1.0\n",
            "('to', 'avoid')  : 1.0\n",
            "('avoid', 'task')  : 1.0\n",
            "('task', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Natural')  : 0.5\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'The')  : 0.5\n",
            "('The', 'subject')  : 1.0\n",
            "('subject', 'of')  : 1.0\n",
            "('of', 'Natural')  : 1.0\n",
            "('Processing', 'can')  : 0.5\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'considered')  : 1.0\n",
            "('considered', 'in')  : 1.0\n",
            "('in', 'both')  : 1.0\n",
            "('both', 'broad')  : 1.0\n",
            "('broad', 'and')  : 1.0\n",
            "('and', 'narrow')  : 1.0\n",
            "('narrow', 'senses.')  : 1.0\n",
            "('In', 'the')  : 1.0\n",
            "('the', 'broad')  : 0.5\n",
            "('broad', 'sense,')  : 1.0\n",
            "('sense,', 'it')  : 1.0\n",
            "('it', 'covers')  : 1.0\n",
            "('covers', 'processing')  : 1.0\n",
            "('processing', 'issues')  : 1.0\n",
            "('issues', 'at')  : 1.0\n",
            "('at', 'all')  : 1.0\n",
            "('all', 'levels')  : 1.0\n",
            "('levels', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'understanding,')  : 0.3333333333333333\n",
            "('understanding,', 'including')  : 1.0\n",
            "('including', 'speech')  : 1.0\n",
            "('speech', 'recognition,')  : 1.0\n",
            "('recognition,', 'syntactic')  : 1.0\n",
            "('syntactic', 'and')  : 1.0\n",
            "('and', 'semantic')  : 1.0\n",
            "('semantic', 'analysis')  : 1.0\n",
            "('analysis', 'of')  : 1.0\n",
            "('of', 'sentences')  : 0.5\n",
            "('sentences', '\"')  : 1.0\n",
            "('\"', 'Robots')  : 1.0\n",
            "('Robots', 'that')  : 1.0\n",
            "('that', 'interact')  : 1.0\n",
            "('interact', 'with')  : 1.0\n",
            "('with', 'humans')  : 1.0\n",
            "('humans', 'face-to-face')  : 0.5\n",
            "('face-to-face', 'using')  : 1.0\n",
            "('using', 'natural')  : 1.0\n",
            "('language', 'need')  : 0.3333333333333333\n",
            "('need', 'to')  : 1.0\n",
            "('to', 'be')  : 0.5\n",
            "('be', 'responsive')  : 1.0\n",
            "('responsive', 'to')  : 1.0\n",
            "('to', 'the')  : 0.5\n",
            "('the', 'way')  : 0.5\n",
            "('way', 'humans')  : 1.0\n",
            "('humans', 'use')  : 0.5\n",
            "('use', 'language')  : 1.0\n",
            "('language', 'in')  : 0.3333333333333333\n",
            "('in', 'those')  : 1.0\n",
            "('those', 'situations.')  : 1.0\n",
            "('We', 'propose')  : 1.0\n",
            "('propose', 'a')  : 1.0\n",
            "('a', 'psychologicallyinspired')  : 1.0\n",
            "('psychologicallyinspired', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'system')  : 1.0\n",
            "('system', 'for')  : 1.0\n",
            "('for', 'robots')  : 1.0\n",
            "('robots', 'which')  : 1.0\n",
            "('which', 'performs')  : 1.0\n",
            "('performs', 'incremental')  : 1.0\n",
            "('incremental', 'semantic')  : 1.0\n",
            "('semantic', 'interpretation')  : 1.0\n",
            "('interpretation', 'of')  : 1.0\n",
            "('of', 'spoken')  : 1.0\n",
            "('spoken', 'utterances')  : 0.5\n",
            "('utterances', 'Natural')  : 1.0\n",
            "('Natural', 'languages')  : 1.0\n",
            "('languages', 'are')  : 0.5\n",
            "('are', 'languages')  : 1.0\n",
            "('languages', 'spoken')  : 0.5\n",
            "('spoken', 'by')  : 0.5\n",
            "('by', 'humans.')  : 1.0\n",
            "('Currently', 'we')  : 1.0\n",
            "('we', 'are')  : 1.0\n",
            "('are', 'not')  : 1.0\n",
            "('not', 'yet')  : 1.0\n",
            "('yet', 'at')  : 1.0\n",
            "('at', 'the')  : 1.0\n",
            "('the', 'point')  : 1.0\n",
            "('point', 'where')  : 1.0\n",
            "('where', 'these')  : 1.0\n",
            "('these', 'languages')  : 1.0\n",
            "('languages', 'in')  : 1.0\n",
            "('in', 'all')  : 1.0\n",
            "('all', 'of')  : 1.0\n",
            "('of', 'their')  : 1.0\n",
            "('their', 'unprocessed')  : 1.0\n",
            "('unprocessed', 'forms')  : 1.0\n",
            "('forms', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'understood')  : 1.0\n",
            "('understood', 'by')  : 1.0\n",
            "('by', 'computers.')  : 1.0\n",
            "('Natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'collection')  : 1.0\n",
            "('collection', 'of')  : 1.0\n",
            "('of', 'techniques')  : 1.0\n",
            "('techniques', 'employed')  : 1.0\n",
            "('employed', 'to')  : 1.0\n",
            "('to', 'try')  : 1.0\n",
            "('try', 'and')  : 1.0\n",
            "('and', 'accomplish')  : 1.0\n",
            "('accomplish', 'that')  : 1.0\n",
            "('that', 'goal.')  : 1.0\n",
            "('The', 'field')  : 1.0\n",
            "('field', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.5\n",
            "('natural', '\"')  : 1.0\n",
            "('\"', 'ABSTRACT:')  : 1.0\n",
            "('ABSTRACT:', 'Ambiguity')  : 1.0\n",
            "('Ambiguity', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'referred')  : 1.0\n",
            "('referred', 'as')  : 1.0\n",
            "('as', 'the')  : 1.0\n",
            "('the', 'ability')  : 1.0\n",
            "('ability', 'of')  : 1.0\n",
            "('of', 'having')  : 0.5\n",
            "('having', 'more')  : 1.0\n",
            "('more', 'than')  : 1.0\n",
            "('than', 'one')  : 1.0\n",
            "('one', 'meaning')  : 0.5\n",
            "('meaning', 'or')  : 1.0\n",
            "('or', 'being')  : 1.0\n",
            "('being', 'understood')  : 1.0\n",
            "('understood', 'in')  : 1.0\n",
            "('in', 'more')  : 1.0\n",
            "('one', 'way.')  : 0.5\n",
            "('Natural', 'languages')  : 1.0\n",
            "('languages', 'are')  : 1.0\n",
            "('are', 'ambiguous,')  : 0.5\n",
            "('ambiguous,', 'so')  : 1.0\n",
            "('so', 'computers')  : 1.0\n",
            "('computers', 'are')  : 1.0\n",
            "('are', 'not')  : 0.5\n",
            "('not', 'able')  : 1.0\n",
            "('able', 'to')  : 1.0\n",
            "('to', 'understand')  : 1.0\n",
            "('understand', 'language')  : 1.0\n",
            "('language', 'the')  : 1.0\n",
            "('the', 'way')  : 1.0\n",
            "('way', 'people')  : 1.0\n",
            "('people', 'do.')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'is')  : 1.0\n",
            "('is', 'concerned')  : 0.5\n",
            "('concerned', 'with')  : 1.0\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'development')  : 0.5\n",
            "('development', '\"')  : 1.0\n",
            "('\"', 'Introduction')  : 1.0\n",
            "('Introduction', 'Statistical')  : 1.0\n",
            "('Statistical', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', '(SNLP)')  : 0.5\n",
            "('(SNLP)', 'is')  : 1.0\n",
            "('is', 'a')  : 0.5\n",
            "('a', 'field')  : 1.0\n",
            "('field', 'lying')  : 1.0\n",
            "('lying', 'in')  : 1.0\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'intersection')  : 0.5\n",
            "('intersection', 'of')  : 1.0\n",
            "('of', 'natural')  : 1.0\n",
            "('processing', 'and')  : 0.5\n",
            "('and', 'machine')  : 1.0\n",
            "('machine', 'learning.')  : 1.0\n",
            "('SNLP', 'di#ers')  : 1.0\n",
            "('di#ers', 'from')  : 1.0\n",
            "('from', 'traditional')  : 1.0\n",
            "('traditional', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'in')  : 1.0\n",
            "('in', 'that')  : 1.0\n",
            "('that', 'instead')  : 1.0\n",
            "('instead', 'of')  : 1.0\n",
            "('of', 'having')  : 0.5\n",
            "('having', 'a')  : 1.0\n",
            "('a', 'linguist')  : 0.5\n",
            "('linguist', 'manually')  : 1.0\n",
            "('manually', 'construct')  : 1.0\n",
            "('construct', 'some')  : 1.0\n",
            "('some', 'model')  : 1.0\n",
            "('model', 'of')  : 1.0\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'given')  : 0.5\n",
            "('given', 'linguistic')  : 1.0\n",
            "('linguistic', '\"')  : 1.0\n",
            "('\"', 'text')  : 1.0\n",
            "('text', 'directly')  : 1.0\n",
            "('directly', '(rather')  : 1.0\n",
            "('(rather', 'than')  : 1.0\n",
            "('than', 'e.g.')  : 1.0\n",
            "('titles', 'and')  : 1.0\n",
            "('and', 'abstracts),')  : 0.5\n",
            "('abstracts),', 'and')  : 1.0\n",
            "('and', 'suggests')  : 0.5\n",
            "('suggests', 'appropriate')  : 1.0\n",
            "('appropriate', 'approaches')  : 1.0\n",
            "('approaches', 'to')  : 1.0\n",
            "('to', 'doing')  : 1.0\n",
            "('doing', 'this,')  : 1.0\n",
            "('this,', 'with')  : 1.0\n",
            "('with', 'a')  : 1.0\n",
            "('a', 'focus')  : 1.0\n",
            "('focus', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'role')  : 1.0\n",
            "('role', 'of')  : 1.0\n",
            "('of', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('The', 'paper')  : 1.0\n",
            "('paper', 'also')  : 1.0\n",
            "('also', 'comments')  : 1.0\n",
            "('comments', 'on')  : 1.0\n",
            "('on', 'possible')  : 1.0\n",
            "('possible', 'connections')  : 1.0\n",
            "('connections', 'with')  : 1.0\n",
            "('with', 'data')  : 1.0\n",
            "('data', 'and')  : 1.0\n",
            "('and', 'knowledge')  : 0.5\n",
            "('knowledge', 'retrieval,')  : 1.0\n",
            "('retrieval,', 'and')  : 1.0\n",
            "('and', 'concludes')  : 0.5\n",
            "('concludes', 'by')  : 1.0\n",
            "('by', 'emphasizing')  : 1.0\n",
            "('emphasizing', 'the')  : 1.0\n",
            "('the', 'importance')  : 0.3333333333333333\n",
            "('importance', 'of')  : 1.0\n",
            "('of', 'rigorous')  : 0.3333333333333333\n",
            "('rigorous', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'ABSTRACT:')  : 0.5\n",
            "('ABSTRACT:', 'Language')  : 1.0\n",
            "('Language', 'is')  : 0.5\n",
            "('is', 'way')  : 1.0\n",
            "('way', 'of')  : 1.0\n",
            "('of', 'communicating')  : 0.3333333333333333\n",
            "('communicating', 'your')  : 1.0\n",
            "('your', 'words')  : 1.0\n",
            "('words', 'Language')  : 1.0\n",
            "('Language', 'helps')  : 0.5\n",
            "('helps', 'in')  : 1.0\n",
            "('in', 'understanding')  : 1.0\n",
            "('understanding', 'the')  : 1.0\n",
            "('the', 'world,we')  : 0.3333333333333333\n",
            "('world,we', 'get')  : 1.0\n",
            "('get', 'a')  : 1.0\n",
            "('a', 'better')  : 1.0\n",
            "('better', 'insight')  : 1.0\n",
            "('insight', 'of')  : 1.0\n",
            "('of', 'the')  : 0.3333333333333333\n",
            "('the', 'world.')  : 0.3333333333333333\n",
            "('Language', 'helps')  : 1.0\n",
            "('helps', 'speakers')  : 1.0\n",
            "('speakers', 'to')  : 1.0\n",
            "('to', 'be')  : 1.0\n",
            "('be', 'as')  : 1.0\n",
            "('as', 'vague')  : 0.3333333333333333\n",
            "('vague', 'or')  : 1.0\n",
            "('or', 'as')  : 1.0\n",
            "('as', 'precise')  : 0.3333333333333333\n",
            "('precise', 'as')  : 1.0\n",
            "('as', 'they')  : 0.3333333333333333\n",
            "('they', 'like.')  : 1.0\n",
            "('NLP', 'Stands')  : 1.0\n",
            "('Stands', 'for')  : 1.0\n",
            "('for', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing..')  : 0.5\n",
            "('processing..', 'Natural')  : 1.0\n",
            "('Natural', 'languages')  : 1.0\n",
            "('languages', 'are')  : 0.5\n",
            "('are', 'those')  : 0.5\n",
            "('those', 'languages')  : 1.0\n",
            "('languages', 'that')  : 0.5\n",
            "('that', 'are')  : 1.0\n",
            "('are', 'spoken')  : 0.5\n",
            "('spoken', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'report')  : 1.0\n",
            "('report', 'experiments')  : 1.0\n",
            "('experiments', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'use')  : 0.5\n",
            "('use', 'of')  : 1.0\n",
            "('of', 'standard')  : 0.5\n",
            "('standard', 'natural')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'tools')  : 1.0\n",
            "('tools', 'for')  : 1.0\n",
            "('for', 'the')  : 0.5\n",
            "('the', 'analysis')  : 0.5\n",
            "('analysis', 'of')  : 1.0\n",
            "('of', 'music')  : 0.5\n",
            "('music', 'lyrics.')  : 1.0\n",
            "('A', 'significant')  : 1.0\n",
            "('significant', 'amount')  : 1.0\n",
            "('amount', 'of')  : 1.0\n",
            "('of', 'music')  : 1.0\n",
            "('music', 'audio')  : 1.0\n",
            "('audio', 'has')  : 1.0\n",
            "('has', 'lyrics.')  : 1.0\n",
            "('Lyrics', 'encode')  : 1.0\n",
            "('encode', 'an')  : 1.0\n",
            "('an', 'important')  : 1.0\n",
            "('important', 'part')  : 1.0\n",
            "('part', 'of')  : 1.0\n",
            "('of', 'the')  : 0.25\n",
            "('the', 'semantics')  : 1.0\n",
            "('semantics', 'of')  : 1.0\n",
            "('of', 'a')  : 0.25\n",
            "('a', 'song,')  : 0.5\n",
            "('song,', 'therefore')  : 1.0\n",
            "('therefore', 'their')  : 1.0\n",
            "('their', 'analysis')  : 1.0\n",
            "('analysis', 'complements')  : 1.0\n",
            "('complements', 'that')  : 1.0\n",
            "('that', 'of')  : 1.0\n",
            "('of', 'acoustic')  : 0.25\n",
            "('acoustic', 'and')  : 1.0\n",
            "('and', 'cultural')  : 1.0\n",
            "('cultural', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'this')  : 0.5\n",
            "('this', 'paper,')  : 1.0\n",
            "('paper,', 'we')  : 1.0\n",
            "('we', 'will')  : 1.0\n",
            "('will', 'describe')  : 1.0\n",
            "('describe', 'a')  : 1.0\n",
            "('a', 'simple')  : 0.5\n",
            "('simple', 'rule-based')  : 1.0\n",
            "('rule-based', 'approach')  : 1.0\n",
            "('approach', 'to')  : 1.0\n",
            "('to', 'automated')  : 1.0\n",
            "('automated', 'learning')  : 1.0\n",
            "('learning', 'of')  : 1.0\n",
            "('of', 'linguistic')  : 0.25\n",
            "('linguistic', 'knowledge.')  : 1.0\n",
            "('This', 'approach')  : 1.0\n",
            "('approach', 'has')  : 1.0\n",
            "('has', 'been')  : 1.0\n",
            "('been', 'shown')  : 1.0\n",
            "('shown', 'for')  : 1.0\n",
            "('for', 'a')  : 1.0\n",
            "('a', 'number')  : 0.3333333333333333\n",
            "('number', 'of')  : 1.0\n",
            "('of', 'tasks')  : 1.0\n",
            "('tasks', 'to')  : 1.0\n",
            "('to', 'capture')  : 1.0\n",
            "('capture', 'information')  : 1.0\n",
            "('information', 'in')  : 1.0\n",
            "('in', 'a')  : 0.5\n",
            "('a', 'clearer')  : 0.3333333333333333\n",
            "('clearer', 'and')  : 1.0\n",
            "('and', 'more')  : 1.0\n",
            "('more', 'direct')  : 1.0\n",
            "('direct', 'fashion')  : 1.0\n",
            "('fashion', 'without')  : 1.0\n",
            "('without', 'a')  : 1.0\n",
            "('a', 'compromise')  : 0.3333333333333333\n",
            "('compromise', 'in')  : 1.0\n",
            "('in', 'performance.')  : 0.5\n",
            "('We', 'present')  : 1.0\n",
            "('present', 'a')  : 1.0\n",
            "('a', 'detailed')  : 1.0\n",
            "('detailed', 'case')  : 1.0\n",
            "('case', 'study')  : 1.0\n",
            "('study', 'of')  : 1.0\n",
            "('of', 'this')  : 0.5\n",
            "('this', 'learning')  : 1.0\n",
            "('learning', 'method')  : 1.0\n",
            "('method', 'applied')  : 1.0\n",
            "('applied', 'to')  : 1.0\n",
            "('to', 'part')  : 1.0\n",
            "('part', 'of')  : 1.0\n",
            "('of', 'speech')  : 0.5\n",
            "('speech', 'tagging')  : 1.0\n",
            "('tagging', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'This')  : 0.5\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'focuses')  : 1.0\n",
            "('focuses', 'on')  : 1.0\n",
            "('on', 'connectionist')  : 1.0\n",
            "('connectionist', 'models')  : 1.0\n",
            "('models', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('We', 'briefly')  : 1.0\n",
            "('briefly', 'present')  : 1.0\n",
            "('present', 'and')  : 1.0\n",
            "('and', 'discuss')  : 1.0\n",
            "('discuss', 'several')  : 1.0\n",
            "('several', 'aspects')  : 1.0\n",
            "('aspects', 'of')  : 1.0\n",
            "('of', 'high')  : 1.0\n",
            "('high', 'level')  : 1.0\n",
            "('level', 'tasks')  : 1.0\n",
            "('tasks', 'which')  : 1.0\n",
            "('which', 'recently')  : 1.0\n",
            "('recently', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', 'approached')  : 1.0\n",
            "('approached', 'with')  : 1.0\n",
            "('with', 'connectionism,')  : 0.5\n",
            "('connectionism,', 'either')  : 1.0\n",
            "('either', 'with')  : 1.0\n",
            "('with', 'localist')  : 0.5\n",
            "('localist', 'or')  : 1.0\n",
            "('or', 'parallel')  : 1.0\n",
            "('parallel', 'distributed')  : 1.0\n",
            "('distributed', 'processing')  : 1.0\n",
            "('processing', 'models.')  : 1.0\n",
            "('Several', 'interesting')  : 1.0\n",
            "('interesting', 'architectures')  : 1.0\n",
            "('architectures', '\"')  : 1.0\n",
            "('\"', 'process')  : 1.0\n",
            "('process', 'of')  : 1.0\n",
            "('of', 'language')  : 1.0\n",
            "('language', 'understanding.')  : 1.0\n",
            "('This', 'is')  : 1.0\n",
            "('is', 'a')  : 1.0\n",
            "('a', 'new')  : 1.0\n",
            "('new', 'approach')  : 1.0\n",
            "('approach', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'based')  : 1.0\n",
            "('based', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'deterministic')  : 1.0\n",
            "('deterministic', 'chaotic')  : 1.0\n",
            "('chaotic', 'behavior')  : 1.0\n",
            "('behavior', 'of')  : 1.0\n",
            "('of', 'dynamical')  : 1.0\n",
            "('dynamical', 'systems.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', 'this')  : 0.5\n",
            "('this', 'paper')  : 1.0\n",
            "('paper', '(see')  : 1.0\n",
            "('(see', '[Schank')  : 1.0\n",
            "('[Schank', '86]')  : 1.0\n",
            "('86]', 'for')  : 0.6666666666666666\n",
            "('for', 'a')  : 0.5\n",
            "('a', 'theoretical')  : 0.5\n",
            "('theoretical', 'discussion')  : 1.0\n",
            "('discussion', 'and')  : 1.0\n",
            "('and', '[Kass')  : 0.16666666666666666\n",
            "('[Kass', '86]')  : 1.0\n",
            "('86]', 'and')  : 0.3333333333333333\n",
            "('and', '[Leake')  : 0.16666666666666666\n",
            "('[Leake', 'and')  : 1.0\n",
            "('and', 'Owens')  : 0.16666666666666666\n",
            "('Owens', '86]')  : 1.0\n",
            "('for', 'brief')  : 0.5\n",
            "('brief', 'discussions')  : 1.0\n",
            "('discussions', 'of')  : 1.0\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'program')  : 0.5\n",
            "('program', 'built')  : 1.0\n",
            "('built', 'around')  : 1.0\n",
            "('around', 'these')  : 1.0\n",
            "('these', '.principles);')  : 1.0\n",
            "('.principles);', 'the')  : 1.0\n",
            "('the', 'goal')  : 1.0\n",
            "('goal', 'here')  : 1.0\n",
            "('here', 'is')  : 1.0\n",
            "('is', 'simply')  : 1.0\n",
            "('simply', 'to')  : 1.0\n",
            "('to', 'point')  : 1.0\n",
            "('point', 'out')  : 1.0\n",
            "('out', 'how')  : 1.0\n",
            "('how', 'our')  : 1.0\n",
            "('our', 'interest')  : 1.0\n",
            "('interest', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'has')  : 0.5\n",
            "('has', 'led')  : 1.0\n",
            "('led', 'us')  : 1.0\n",
            "('us', 'naturally,')  : 1.0\n",
            "('naturally,', 'and')  : 1.0\n",
            "('and', 'indeed')  : 0.16666666666666666\n",
            "('indeed', 'inevitably')  : 1.0\n",
            "('inevitably', '\"')  : 1.0\n",
            "('\"', 'Objectives')  : 0.5\n",
            "('Objectives', 'To')  : 1.0\n",
            "('To', 'provide')  : 1.0\n",
            "('provide', 'an')  : 1.0\n",
            "('an', 'overview')  : 1.0\n",
            "('overview', 'and')  : 1.0\n",
            "('and', 'tutorial')  : 0.16666666666666666\n",
            "('tutorial', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.5\n",
            "('processing', '(NLP)')  : 0.5\n",
            "('(NLP)', 'and')  : 1.0\n",
            "('and', 'modern')  : 0.16666666666666666\n",
            "('modern', 'NLP-system')  : 1.0\n",
            "('NLP-system', 'design.')  : 1.0\n",
            "('Target', 'audience')  : 1.0\n",
            "('audience', 'This')  : 1.0\n",
            "('This', 'tutorial')  : 0.5\n",
            "('tutorial', 'targets')  : 1.0\n",
            "('targets', 'the')  : 1.0\n",
            "('the', 'medical')  : 0.25\n",
            "('medical', 'informatics')  : 1.0\n",
            "('informatics', 'generalist')  : 1.0\n",
            "('generalist', 'who')  : 1.0\n",
            "('who', 'has')  : 1.0\n",
            "('has', 'limited')  : 1.0\n",
            "('limited', 'acquaintance')  : 0.5\n",
            "('acquaintance', 'with')  : 1.0\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'principles')  : 0.25\n",
            "('principles', 'behind')  : 1.0\n",
            "('behind', 'NLP')  : 1.0\n",
            "('NLP', 'and/or')  : 1.0\n",
            "('and/or', 'limited')  : 1.0\n",
            "('limited', 'knowledge')  : 0.5\n",
            "('knowledge', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'current')  : 0.5\n",
            "('current', 'state')  : 0.5\n",
            "('state', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'paper')  : 0.5\n",
            "('paper', 'briefly')  : 1.0\n",
            "('briefly', 'describes')  : 1.0\n",
            "('describes', 'the')  : 1.0\n",
            "('current', 'implementation')  : 0.5\n",
            "('implementation', 'status')  : 1.0\n",
            "('status', 'of')  : 1.0\n",
            "('of', 'an')  : 0.5\n",
            "('an', 'intelligent')  : 1.0\n",
            "('intelligent', 'information')  : 1.0\n",
            "('information', 'retrieval')  : 1.0\n",
            "('retrieval', 'system,')  : 1.0\n",
            "('system,', 'MARIE,')  : 1.0\n",
            "('MARIE,', 'that')  : 1.0\n",
            "('that', 'employs')  : 1.0\n",
            "('employs', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'techniques.')  : 1.0\n",
            "('Descriptive', 'captions')  : 1.0\n",
            "('captions', 'are')  : 1.0\n",
            "('are', 'used')  : 1.0\n",
            "('used', 'to')  : 1.0\n",
            "('to', 'iden-')  : 1.0\n",
            "('iden-', 'tify')  : 1.0\n",
            "('tify', 'photographic')  : 1.0\n",
            "('photographic', 'images')  : 1.0\n",
            "('images', 'concerning')  : 1.0\n",
            "('concerning', 'various')  : 1.0\n",
            "('various', 'military')  : 1.0\n",
            "('military', 'projects.')  : 1.0\n",
            "('The', 'captions')  : 1.0\n",
            "('captions', 'are')  : 1.0\n",
            "('are', 'parsed')  : 1.0\n",
            "('parsed', '\"')  : 1.0\n",
            "('\"', 'based')  : 1.0\n",
            "('based', 'and')  : 1.0\n",
            "('and', 'literature')  : 1.0\n",
            "('literature', 'resources.')  : 1.0\n",
            "('We', 'describe')  : 1.0\n",
            "('describe', 'here')  : 1.0\n",
            "('here', 'a')  : 1.0\n",
            "('a', 'system')  : 1.0\n",
            "('system', 'for')  : 1.0\n",
            "('for', 'agent')  : 1.0\n",
            "('agent', 'directed')  : 1.0\n",
            "('directed', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'to')  : 1.0\n",
            "('to', 'extract')  : 1.0\n",
            "('extract', 'information')  : 1.0\n",
            "('information', 'from')  : 1.0\n",
            "('from', 'journal')  : 1.0\n",
            "('journal', 'articles.')  : 1.0\n",
            "('An', 'interface')  : 1.0\n",
            "('interface', 'was')  : 1.0\n",
            "('was', 'developed')  : 1.0\n",
            "('developed', 'to')  : 1.0\n",
            "('to', 'permit')  : 1.0\n",
            "('permit', 'curation')  : 1.0\n",
            "('curation', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'NLP')  : 1.0\n",
            "('NLP', 'results')  : 1.0\n",
            "('results', 'and')  : 0.5\n",
            "('and', 'deposition')  : 1.0\n",
            "('deposition', 'of')  : 1.0\n",
            "('of', 'accepted')  : 0.5\n",
            "('accepted', 'results')  : 1.0\n",
            "('results', 'into')  : 0.5\n",
            "('into', 'a')  : 1.0\n",
            "('a', 'knowledge')  : 1.0\n",
            "('knowledge', 'base.')  : 1.0\n",
            "('Motivation:', 'The')  : 1.0\n",
            "('The', 'advent')  : 1.0\n",
            "('advent', 'of')  : 1.0\n",
            "('of', 'high')  : 1.0\n",
            "('high', '\"')  : 1.0\n",
            "('\"', 'to')  : 1.0\n",
            "('to', 'evaluation')  : 1.0\n",
            "('evaluation', 'in')  : 1.0\n",
            "('in', 'speech')  : 1.0\n",
            "('speech', 'processing.')  : 1.0\n",
            "('Part', '2')  : 1.0\n",
            "('2', 'surveys')  : 1.0\n",
            "('surveys', 'significant')  : 1.0\n",
            "('significant', 'evaluation')  : 1.0\n",
            "('evaluation', 'work')  : 1.0\n",
            "('work', 'done')  : 1.0\n",
            "('done', 'so')  : 1.0\n",
            "('so', 'far,')  : 1.0\n",
            "('far,', 'for')  : 1.0\n",
            "('for', 'instance')  : 1.0\n",
            "('instance', 'in')  : 1.0\n",
            "('in', 'machine')  : 1.0\n",
            "('machine', 'translation,')  : 1.0\n",
            "('translation,', 'and')  : 1.0\n",
            "('and', 'discusses')  : 1.0\n",
            "('discusses', 'the')  : 1.0\n",
            "('the', 'particular')  : 1.0\n",
            "('particular', 'problems')  : 1.0\n",
            "('problems', 'of')  : 1.0\n",
            "('of', 'generic')  : 1.0\n",
            "('generic', 'system')  : 1.0\n",
            "('system', 'evaluation.')  : 1.0\n",
            "('The', 'conclusion')  : 1.0\n",
            "('conclusion', 'is')  : 1.0\n",
            "('is', 'that')  : 1.0\n",
            "('that', 'evaluation')  : 1.0\n",
            "('evaluation', 'strategies')  : 1.0\n",
            "('strategies', 'and')  : 1.0\n",
            "('and', 'techniques')  : 1.0\n",
            "('techniques', 'for')  : 1.0\n",
            "('for', 'NLP')  : 1.0\n",
            "('NLP', 'need')  : 1.0\n",
            "('need', 'much')  : 1.0\n",
            "('much', 'more')  : 1.0\n",
            "('more', 'development,')  : 1.0\n",
            "('development,', 'in')  : 1.0\n",
            "('in', 'particular')  : 0.5\n",
            "('particular', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'similar')  : 0.5\n",
            "('similar', 'to')  : 1.0\n",
            "('to', 'the')  : 0.5\n",
            "('the', 'way')  : 1.0\n",
            "('way', 'humans')  : 1.0\n",
            "('humans', 'intuitively')  : 1.0\n",
            "('intuitively', 'do')  : 1.0\n",
            "('do', 'in')  : 1.0\n",
            "('in', 'order')  : 0.5\n",
            "('order', 'to')  : 1.0\n",
            "('to', 'eliminate')  : 0.5\n",
            "('eliminate', 'noisy')  : 1.0\n",
            "('noisy', 'content.')  : 1.0\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'paper,')  : 1.0\n",
            "('paper,', 'we')  : 1.0\n",
            "('we', 'describe')  : 1.0\n",
            "('describe', 'a')  : 1.0\n",
            "('a', 'combination')  : 1.0\n",
            "('combination', 'of')  : 1.0\n",
            "('of', 'HTML')  : 0.5\n",
            "('HTML', 'DOM')  : 1.0\n",
            "('DOM', 'analysis')  : 1.0\n",
            "('analysis', 'and')  : 1.0\n",
            "('and', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'techniques')  : 1.0\n",
            "('techniques', 'for')  : 1.0\n",
            "('for', 'automated')  : 1.0\n",
            "('automated', 'extractions')  : 1.0\n",
            "('extractions', 'of')  : 1.0\n",
            "('of', 'main')  : 0.5\n",
            "('main', 'article')  : 1.0\n",
            "('article', 'with')  : 1.0\n",
            "('with', 'associated')  : 1.0\n",
            "('associated', 'images')  : 1.0\n",
            "('images', 'from')  : 1.0\n",
            "('from', 'web')  : 1.0\n",
            "('web', 'pages.')  : 1.0\n",
            "('pages.', '\"')  : 1.0\n",
            "('Abstract--', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'is')  : 0.5\n",
            "('is', 'a')  : 1.0\n",
            "('a', 'theoretically')  : 0.5\n",
            "('theoretically', 'motivated')  : 1.0\n",
            "('motivated', 'range')  : 1.0\n",
            "('range', 'of')  : 1.0\n",
            "('of', 'computational')  : 0.25\n",
            "('computational', 'techniques')  : 1.0\n",
            "('techniques', 'for')  : 1.0\n",
            "('for', 'analysing')  : 0.3333333333333333\n",
            "('analysing', 'and')  : 1.0\n",
            "('and', 'representing')  : 1.0\n",
            "('representing', 'naturally')  : 1.0\n",
            "('naturally', 'occurring')  : 1.0\n",
            "('occurring', 'texts')  : 1.0\n",
            "('texts', 'at')  : 1.0\n",
            "('at', 'one')  : 1.0\n",
            "('one', 'or')  : 1.0\n",
            "('or', 'more')  : 1.0\n",
            "('more', 'levels')  : 1.0\n",
            "('levels', 'of')  : 1.0\n",
            "('of', 'linguistic')  : 0.25\n",
            "('linguistic', 'analysis')  : 1.0\n",
            "('analysis', 'for')  : 1.0\n",
            "('for', 'the')  : 0.3333333333333333\n",
            "('the', 'purpose')  : 0.5\n",
            "('purpose', 'of')  : 1.0\n",
            "('of', 'achieving')  : 0.25\n",
            "('achieving', 'human-like')  : 1.0\n",
            "('human-like', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'for')  : 1.0\n",
            "('for', 'a')  : 0.3333333333333333\n",
            "('a', 'range')  : 0.5\n",
            "('of', 'tasks')  : 0.25\n",
            "('tasks', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'reviews')  : 1.0\n",
            "('reviews', 'the')  : 1.0\n",
            "('the', 'processes')  : 0.5\n",
            "('processes', 'involved')  : 1.0\n",
            "('involved', 'in')  : 1.0\n",
            "('in', 'Natural')  : 1.0\n",
            "('Processing', '(NLP).')  : 0.5\n",
            "('It', 'then')  : 1.0\n",
            "('then', 'demonstrates')  : 1.0\n",
            "('demonstrates', 'the')  : 1.0\n",
            "('the', 'various')  : 0.25\n",
            "('various', 'kinds')  : 1.0\n",
            "('kinds', 'of')  : 1.0\n",
            "('of', 'choices')  : 0.5\n",
            "('choices', 'that')  : 1.0\n",
            "('that', 'need')  : 1.0\n",
            "('need', 'be')  : 1.0\n",
            "('be', 'taken')  : 1.0\n",
            "('taken', 'during')  : 1.0\n",
            "('during', 'the')  : 1.0\n",
            "('the', 'execution')  : 0.25\n",
            "('execution', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'word')  : 0.25\n",
            "('word', 'morphology,')  : 1.0\n",
            "('morphology,', 'the')  : 1.0\n",
            "('the', 'syntactic')  : 0.25\n",
            "('syntactic', 'text')  : 1.0\n",
            "('text', 'analysis,')  : 0.5\n",
            "('analysis,', 'or')  : 1.0\n",
            "('or', 'text')  : 1.0\n",
            "('text', 'generation')  : 0.5\n",
            "('generation', 'components.')  : 1.0\n",
            "('It', 'compares')  : 1.0\n",
            "('compares', 'the')  : 1.0\n",
            "('the', 'time')  : 0.5\n",
            "('time', 'complexity')  : 1.0\n",
            "('complexity', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'article')  : 1.0\n",
            "('article', 'focusses')  : 1.0\n",
            "('focusses', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'derivation')  : 0.5\n",
            "('derivation', 'of')  : 1.0\n",
            "('of', 'large')  : 1.0\n",
            "('large', 'lexicons')  : 1.0\n",
            "('lexicons', 'for')  : 1.0\n",
            "('for', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('We', 'describe')  : 1.0\n",
            "('describe', 'the')  : 1.0\n",
            "('the', 'development')  : 0.5\n",
            "('development', 'of')  : 1.0\n",
            "('of', 'a')  : 0.3333333333333333\n",
            "('a', 'dictionary')  : 0.5\n",
            "('dictionary', 'support')  : 1.0\n",
            "('support', 'environment')  : 1.0\n",
            "('environment', 'linking')  : 1.0\n",
            "('linking', 'a')  : 1.0\n",
            "('a', 'restructured')  : 0.5\n",
            "('restructured', 'version')  : 1.0\n",
            "('version', 'of')  : 1.0\n",
            "('of', 'the')  : 0.3333333333333333\n",
            "('the', 'Longman')  : 0.5\n",
            "('Longman', 'Dictionary')  : 1.0\n",
            "('Dictionary', 'of')  : 1.0\n",
            "('of', 'Contemporary')  : 0.3333333333333333\n",
            "('Contemporary', 'English')  : 1.0\n",
            "('English', 'to')  : 1.0\n",
            "('to', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'systems.')  : 1.0\n",
            "('The', 'process')  : 1.0\n",
            "('process', '\"')  : 1.0\n",
            "('\"', 'We')  : 1.0\n",
            "('We', 'introduce')  : 1.0\n",
            "('introduce', 'a')  : 1.0\n",
            "('a', 'method')  : 1.0\n",
            "('method', 'for')  : 1.0\n",
            "('for', 'analyzing')  : 0.5\n",
            "('analyzing', 'the')  : 1.0\n",
            "('the', 'complexity')  : 0.5\n",
            "('complexity', 'of')  : 1.0\n",
            "('of', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'tasks,')  : 1.0\n",
            "('tasks,', 'and')  : 1.0\n",
            "('and', 'for')  : 1.0\n",
            "('for', 'predicting')  : 0.5\n",
            "('predicting', 'the')  : 1.0\n",
            "('the', 'difficulty')  : 0.5\n",
            "('difficulty', 'new')  : 1.0\n",
            "('new', 'NLP')  : 1.0\n",
            "('NLP', 'tasks.')  : 1.0\n",
            "('Our', 'complexity')  : 1.0\n",
            "('complexity', 'measures')  : 0.5\n",
            "('measures', 'are')  : 1.0\n",
            "('are', 'derived')  : 1.0\n",
            "('derived', 'from')  : 1.0\n",
            "('from', 'the')  : 1.0\n",
            "('the', 'Kolmogorov')  : 1.0\n",
            "('Kolmogorov', 'complexity')  : 1.0\n",
            "('complexity', 'of')  : 0.5\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'class')  : 1.0\n",
            "('class', 'of')  : 1.0\n",
            "('of', 'automata')  : 0.5\n",
            "('automata', '—')  : 1.0\n",
            "('—', 'meaning')  : 1.0\n",
            "('meaning', 'automata,')  : 1.0\n",
            "('automata,', 'whose')  : 1.0\n",
            "('whose', 'purpose')  : 1.0\n",
            "('purpose', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'extract')  : 1.0\n",
            "('extract', 'relevant')  : 1.0\n",
            "('relevant', 'pieces')  : 1.0\n",
            "('pieces', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', ',')  : 0.5\n",
            "(',', 'sounds,')  : 1.0\n",
            "('sounds,', 'text')  : 1.0\n",
            "('text', 'and')  : 1.0\n",
            "('and', 'motion.')  : 1.0\n",
            "('The', 'techniques')  : 1.0\n",
            "('techniques', 'developed')  : 1.0\n",
            "('developed', 'from')  : 1.0\n",
            "('from', 'deep')  : 1.0\n",
            "('deep', 'learning')  : 1.0\n",
            "('learning', 'research')  : 1.0\n",
            "('research', 'have')  : 0.5\n",
            "('have', 'already')  : 1.0\n",
            "('already', 'been')  : 1.0\n",
            "('been', 'impacting')  : 1.0\n",
            "('impacting', 'the')  : 1.0\n",
            "('the', 'research')  : 1.0\n",
            "('research', 'of')  : 0.5\n",
            "('of', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'process.')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'reviews')  : 1.0\n",
            "('reviews', 'the')  : 1.0\n",
            "('the', 'recent')  : 1.0\n",
            "('recent', 'research')  : 0.5\n",
            "('research', 'on')  : 1.0\n",
            "('on', 'deep')  : 1.0\n",
            "('deep', 'learning,')  : 1.0\n",
            "('learning,', 'its')  : 1.0\n",
            "('its', 'applications')  : 1.0\n",
            "('applications', 'and')  : 1.0\n",
            "('and', 'recent')  : 1.0\n",
            "('recent', 'development')  : 0.5\n",
            "('development', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', 'This')  : 0.5\n",
            "('This', 'is')  : 1.0\n",
            "('is', 'an')  : 0.5\n",
            "('an', 'author-produced')  : 1.0\n",
            "('author-produced', 'version')  : 1.0\n",
            "('version', 'of')  : 1.0\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'paper')  : 1.0\n",
            "('paper', 'published')  : 1.0\n",
            "('published', 'in')  : 1.0\n",
            "('in', 'The')  : 1.0\n",
            "('The', '\"')  : 1.0\n",
            "('\"', 'Abstract—Natural')  : 0.5\n",
            "('Abstract—Natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'is')  : 1.0\n",
            "('is', 'the')  : 0.5\n",
            "('the', 'application')  : 1.0\n",
            "('application', 'of')  : 1.0\n",
            "('of', 'automated')  : 0.5\n",
            "('automated', 'parsing')  : 1.0\n",
            "('parsing', 'and')  : 1.0\n",
            "('and', 'machine')  : 1.0\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', 'techniques')  : 1.0\n",
            "('techniques', 'to')  : 1.0\n",
            "('to', 'analyze')  : 1.0\n",
            "('analyze', 'standard')  : 1.0\n",
            "('standard', 'text.')  : 1.0\n",
            "('Applications', 'of')  : 1.0\n",
            "('of', 'NLP')  : 0.4\n",
            "('NLP', 'to')  : 1.0\n",
            "('to', 'requirements')  : 0.5\n",
            "('requirements', 'engineering')  : 0.5\n",
            "('engineering', 'include')  : 1.0\n",
            "('include', 'extraction')  : 1.0\n",
            "('extraction', 'of')  : 1.0\n",
            "('of', 'ontologies')  : 0.2\n",
            "('ontologies', 'from')  : 1.0\n",
            "('from', 'a')  : 1.0\n",
            "('a', 'requirements')  : 1.0\n",
            "('requirements', 'specification,')  : 0.5\n",
            "('specification,', 'and')  : 1.0\n",
            "('and', 'use')  : 0.5\n",
            "('use', 'of')  : 1.0\n",
            "('to', 'verify')  : 0.5\n",
            "('verify', 'the')  : 1.0\n",
            "('the', 'consistency')  : 0.16666666666666666\n",
            "('consistency', '\"')  : 1.0\n",
            "('\"', 'statistical')  : 1.0\n",
            "('statistical', 'baseline')  : 0.5\n",
            "('baseline', 'including:')  : 1.0\n",
            "('including:', 'the')  : 1.0\n",
            "('the', 'forgiving')  : 0.16666666666666666\n",
            "('forgiving', 'nature')  : 1.0\n",
            "('nature', 'but')  : 1.0\n",
            "('but', 'broad')  : 1.0\n",
            "('broad', 'coverage')  : 1.0\n",
            "('coverage', 'of')  : 1.0\n",
            "('of', 'the')  : 0.2\n",
            "('the', 'typical')  : 0.16666666666666666\n",
            "('typical', 'retrieval')  : 1.0\n",
            "('retrieval', 'task;')  : 1.0\n",
            "('task;', 'the')  : 1.0\n",
            "('the', 'lack')  : 0.16666666666666666\n",
            "('lack', 'of')  : 1.0\n",
            "('of', 'good')  : 0.2\n",
            "('good', 'weighting')  : 1.0\n",
            "('weighting', 'schemes')  : 1.0\n",
            "('schemes', 'for')  : 1.0\n",
            "('for', 'compound')  : 1.0\n",
            "('compound', 'index')  : 1.0\n",
            "('index', 'terms;')  : 1.0\n",
            "('terms;', 'and')  : 1.0\n",
            "('and', 'the')  : 0.5\n",
            "('the', 'implicit')  : 0.16666666666666666\n",
            "('implicit', 'linguistic')  : 1.0\n",
            "('linguistic', 'processing')  : 1.0\n",
            "('processing', 'inherent')  : 1.0\n",
            "('inherent', 'in')  : 1.0\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'statistical')  : 0.16666666666666666\n",
            "('statistical', 'methods.')  : 0.5\n",
            "('Natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.3333333333333333\n",
            "('processing', 'techniques')  : 1.0\n",
            "('techniques', 'may')  : 1.0\n",
            "('may', 'be')  : 1.0\n",
            "('be', 'more')  : 1.0\n",
            "('more', 'important')  : 1.0\n",
            "('important', '\"')  : 1.0\n",
            "('\"', 'Work')  : 0.5\n",
            "('Work', 'in')  : 1.0\n",
            "('in', 'computational')  : 0.3333333333333333\n",
            "('computational', 'linguistics')  : 1.0\n",
            "('linguistics', 'began')  : 1.0\n",
            "('began', 'very')  : 1.0\n",
            "('very', 'soon')  : 1.0\n",
            "('soon', 'after')  : 1.0\n",
            "('after', 'the')  : 1.0\n",
            "('the', 'development')  : 0.14285714285714285\n",
            "('development', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'first')  : 0.14285714285714285\n",
            "('first', 'computers')  : 1.0\n",
            "('computers', '(Booth,')  : 1.0\n",
            "('(Booth,', 'Brandwood')  : 1.0\n",
            "('Brandwood', 'and')  : 1.0\n",
            "('and', 'Cleave')  : 0.25\n",
            "('Cleave', '1958),')  : 1.0\n",
            "('1958),', 'yet')  : 1.0\n",
            "('yet', 'in')  : 1.0\n",
            "('in', 'the')  : 0.3333333333333333\n",
            "('the', 'intervening')  : 0.14285714285714285\n",
            "('intervening', 'four')  : 1.0\n",
            "('four', 'decades')  : 1.0\n",
            "('decades', 'there')  : 1.0\n",
            "('there', 'has')  : 1.0\n",
            "('has', 'been')  : 0.5\n",
            "('been', 'a')  : 0.5\n",
            "('a', 'pervasive')  : 0.5\n",
            "('pervasive', 'feeling')  : 1.0\n",
            "('feeling', 'that')  : 1.0\n",
            "('that', 'progress')  : 1.0\n",
            "('progress', 'in')  : 1.0\n",
            "('in', 'computer')  : 0.3333333333333333\n",
            "('computer', 'understanding')  : 1.0\n",
            "('understanding', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'has')  : 0.3333333333333333\n",
            "('has', 'not')  : 0.5\n",
            "('not', 'been')  : 1.0\n",
            "('been', 'commensurate')  : 0.5\n",
            "('commensurate', '\"')  : 1.0\n",
            "('\"', 'the')  : 0.5\n",
            "('the', 'voice')  : 0.14285714285714285\n",
            "('voice', 'recognition')  : 1.0\n",
            "('recognition', 'for')  : 1.0\n",
            "('for', 'a')  : 0.5\n",
            "('a', 'natural')  : 0.5\n",
            "('language', '(Tamil)')  : 0.3333333333333333\n",
            "('(Tamil)', 'by')  : 1.0\n",
            "('by', 'combining')  : 1.0\n",
            "('combining', 'the')  : 1.0\n",
            "('the', 'digital')  : 0.14285714285714285\n",
            "('digital', 'and')  : 1.0\n",
            "('and', 'mathematical')  : 0.25\n",
            "('mathematical', 'knowledge')  : 1.0\n",
            "('knowledge', 'using')  : 1.0\n",
            "('using', 'MFCC')  : 1.0\n",
            "('MFCC', 'and')  : 1.0\n",
            "('and', 'DTW')  : 0.25\n",
            "('DTW', 'to')  : 1.0\n",
            "('to', 'extract')  : 0.5\n",
            "('extract', 'and')  : 1.0\n",
            "('and', 'match')  : 0.25\n",
            "('match', 'the')  : 1.0\n",
            "('the', 'features')  : 0.14285714285714285\n",
            "('features', 'to')  : 1.0\n",
            "('to', 'improve')  : 0.5\n",
            "('improve', 'the')  : 1.0\n",
            "('the', 'accuracy')  : 0.14285714285714285\n",
            "('accuracy', 'for')  : 1.0\n",
            "('for', 'better')  : 0.5\n",
            "('better', 'performance.')  : 1.0\n",
            "('Abstract:', 'Testing')  : 1.0\n",
            "('Testing', 'against')  : 1.0\n",
            "('against', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'requirements')  : 1.0\n",
            "('requirements', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'standard')  : 1.0\n",
            "('standard', 'approach')  : 1.0\n",
            "('approach', 'for')  : 1.0\n",
            "('for', 'system')  : 1.0\n",
            "('system', 'and')  : 1.0\n",
            "('and', 'acceptance')  : 1.0\n",
            "('acceptance', 'testing.')  : 1.0\n",
            "('This', 'test')  : 1.0\n",
            "('test', 'is')  : 0.5\n",
            "('is', 'often')  : 1.0\n",
            "('often', 'performed')  : 1.0\n",
            "('performed', 'by')  : 1.0\n",
            "('by', 'an')  : 1.0\n",
            "('an', 'independent')  : 1.0\n",
            "('independent', 'test')  : 1.0\n",
            "('test', 'organization')  : 0.5\n",
            "('organization', 'unfamiliar')  : 1.0\n",
            "('unfamiliar', 'with')  : 1.0\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'application')  : 1.0\n",
            "('application', 'area.')  : 1.0\n",
            "('The', 'only')  : 1.0\n",
            "('only', 'things')  : 1.0\n",
            "('things', 'the')  : 1.0\n",
            "('the', 'testers')  : 0.5\n",
            "('testers', 'have')  : 1.0\n",
            "('have', 'to')  : 1.0\n",
            "('to', 'go')  : 1.0\n",
            "('go', 'by')  : 1.0\n",
            "('by', 'are')  : 1.0\n",
            "('are', 'the')  : 1.0\n",
            "('the', 'written')  : 0.5\n",
            "('written', 'requirements.')  : 1.0\n",
            "('So', 'Abstract')  : 1.0\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', '\"')  : 1.0\n",
            "('\"', 'conversational')  : 1.0\n",
            "('conversational', 'partners.')  : 1.0\n",
            "('But', 'it')  : 1.0\n",
            "('it', 'also')  : 1.0\n",
            "('also', 'provides')  : 1.0\n",
            "('provides', 'us')  : 1.0\n",
            "('us', 'with')  : 1.0\n",
            "('with', 'information')  : 1.0\n",
            "('information', 'about')  : 1.0\n",
            "('about', 'being')  : 1.0\n",
            "('being', 'creative,')  : 1.0\n",
            "('creative,', 'making')  : 1.0\n",
            "('making', 'associations,')  : 1.0\n",
            "('associations,', 'storytelling')  : 1.0\n",
            "('storytelling', 'and')  : 1.0\n",
            "('and', 'language')  : 1.0\n",
            "('language', 'use.')  : 1.0\n",
            "('Many', 'more')  : 1.0\n",
            "('more', 'subtleties')  : 0.3333333333333333\n",
            "('subtleties', 'in')  : 1.0\n",
            "('in', 'face-to-face')  : 0.5\n",
            "('face-to-face', 'and')  : 1.0\n",
            "('and', 'multiparty')  : 0.25\n",
            "('multiparty', 'interaction')  : 1.0\n",
            "('interaction', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'added,')  : 1.0\n",
            "('added,', 'such')  : 1.0\n",
            "('such', 'as')  : 1.0\n",
            "('as', 'using')  : 1.0\n",
            "('using', 'humor')  : 1.0\n",
            "('humor', 'to')  : 1.0\n",
            "('to', 'persuade')  : 0.25\n",
            "('persuade', 'and')  : 1.0\n",
            "('and', 'dominate,')  : 0.25\n",
            "('dominate,', 'to')  : 1.0\n",
            "('to', 'soften')  : 0.25\n",
            "('soften', 'or')  : 1.0\n",
            "('or', 'avoid')  : 1.0\n",
            "('avoid', 'a')  : 1.0\n",
            "('a', 'face')  : 1.0\n",
            "('face', 'threatening')  : 1.0\n",
            "('threatening', 'act')  : 1.0\n",
            "('act', '\"')  : 1.0\n",
            "('\"', 'Abstract')  : 0.25\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', '\"')  : 1.0\n",
            "('\"', 'In')  : 0.25\n",
            "('In', 'recent')  : 1.0\n",
            "('recent', 'years,')  : 1.0\n",
            "('years,', 'machine')  : 1.0\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', '(ML)')  : 1.0\n",
            "('(ML)', 'has')  : 1.0\n",
            "('has', 'been')  : 1.0\n",
            "('been', 'used')  : 1.0\n",
            "('used', 'more')  : 1.0\n",
            "('more', 'and')  : 0.3333333333333333\n",
            "('and', 'more')  : 0.25\n",
            "('more', 'to')  : 0.3333333333333333\n",
            "('to', 'solve')  : 0.25\n",
            "('solve', 'complex')  : 1.0\n",
            "('complex', 'tasks')  : 1.0\n",
            "('tasks', 'in')  : 1.0\n",
            "('in', 'different')  : 0.5\n",
            "('different', 'disciplines,')  : 1.0\n",
            "('disciplines,', 'ranging')  : 1.0\n",
            "('ranging', 'from')  : 1.0\n",
            "('from', 'Data')  : 1.0\n",
            "('Data', 'Mining')  : 1.0\n",
            "('Mining', 'to')  : 1.0\n",
            "('to', 'Information')  : 0.25\n",
            "('Information', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.25\n",
            "('\"', 'We')  : 0.25\n",
            "('We', 'argue')  : 1.0\n",
            "('argue', 'that')  : 1.0\n",
            "('that', 'manual')  : 1.0\n",
            "('manual', 'and')  : 1.0\n",
            "('and', 'automatic')  : 0.25\n",
            "('automatic', 'thesauruses')  : 1.0\n",
            "('thesauruses', 'are')  : 1.0\n",
            "('are', 'alternative')  : 1.0\n",
            "('alternative', 'resources')  : 1.0\n",
            "('resources', 'for')  : 1.0\n",
            "('for', 'the')  : 1.0\n",
            "('the', 'same')  : 1.0\n",
            "('same', 'NLP')  : 1.0\n",
            "('NLP', 'tasks.')  : 1.0\n",
            "('This', 'involves')  : 1.0\n",
            "('involves', 'the')  : 1.0\n",
            "('the', 'radical')  : 0.5\n",
            "('radical', 'step')  : 1.0\n",
            "('step', 'of')  : 1.0\n",
            "('of', 'interpreting')  : 0.5\n",
            "('interpreting', 'manual')  : 1.0\n",
            "('manual', 'thesauruses')  : 1.0\n",
            "('thesauruses', 'as')  : 1.0\n",
            "('as', 'classifications')  : 1.0\n",
            "('classifications', 'of')  : 1.0\n",
            "('of', 'words')  : 0.5\n",
            "('words', 'rather')  : 1.0\n",
            "('rather', 'than')  : 1.0\n",
            "('than', 'word')  : 1.0\n",
            "('word', 'senses:')  : 1.0\n",
            "('senses:', 'the')  : 1.0\n",
            "('the', 'case')  : 0.5\n",
            "('case', 'for')  : 1.0\n",
            "('for', 'this')  : 1.0\n",
            "('this', 'is')  : 1.0\n",
            "('is', 'made.')  : 1.0\n",
            "('The', 'range')  : 1.0\n",
            "('range', 'of')  : 1.0\n",
            "('of', 'roles')  : 1.0\n",
            "('roles', 'for')  : 1.0\n",
            "('for', 'thesauruses')  : 1.0\n",
            "('thesauruses', 'within')  : 1.0\n",
            "('within', 'NLP')  : 1.0\n",
            "('NLP', 'is')  : 1.0\n",
            "('is', 'briefly')  : 0.5\n",
            "('briefly', 'presented')  : 1.0\n",
            "('presented', 'and')  : 1.0\n",
            "('and', 'the')  : 1.0\n",
            "('the', 'WASPS')  : 1.0\n",
            "('WASPS', 'thesaurus')  : 1.0\n",
            "('thesaurus', 'is')  : 1.0\n",
            "('is', 'introduced.')  : 0.5\n",
            "('Thesaurus', 'evaluation')  : 1.0\n",
            "('evaluation', 'is')  : 1.0\n",
            "('is', 'now')  : 1.0\n",
            "('now', 'becoming')  : 1.0\n",
            "('becoming', 'urgent.')  : 1.0\n",
            "('A', 'range')  : 1.0\n",
            "('range', 'of')  : 1.0\n",
            "('of', 'evaluation')  : 1.0\n",
            "('evaluation', 'strategies,')  : 1.0\n",
            "('strategies,', 'all')  : 1.0\n",
            "('all', 'embedded')  : 1.0\n",
            "('embedded', 'within')  : 1.0\n",
            "('within', 'NLP')  : 1.0\n",
            "('NLP', 'tasks,')  : 1.0\n",
            "('tasks,', 'is')  : 1.0\n",
            "('is', 'proposed.')  : 1.0\n",
            "('proposed.', '\"')  : 1.0\n",
            "('\"', 'Introduction')  : 1.0\n",
            "('Introduction', 'Patterns')  : 1.0\n",
            "('Patterns', 'in')  : 1.0\n",
            "('in', 'music')  : 0.5\n",
            "('music', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', 'the')  : 1.0\n",
            "('the', 'object')  : 0.5\n",
            "('object', 'of')  : 1.0\n",
            "('of', 'intensive')  : 1.0\n",
            "('intensive', 'studies')  : 1.0\n",
            "('studies', 'in')  : 1.0\n",
            "('in', 'the')  : 0.5\n",
            "('the', 'past')  : 0.5\n",
            "('past', 'years.')  : 1.0\n",
            "('\\\\One', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'purposes')  : 0.5\n",
            "('purposes', 'of')  : 1.0\n",
            "('of', 'analyzing')  : 0.5\n",
            "('analyzing', 'musical')  : 1.0\n",
            "('musical', 'structure')  : 0.5\n",
            "('structure', 'and')  : 1.0\n",
            "('and', 'form')  : 1.0\n",
            "('form', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'discover')  : 1.0\n",
            "('discover', 'the')  : 1.0\n",
            "('the', 'patterns')  : 0.5\n",
            "('patterns', 'that')  : 1.0\n",
            "('that', 'are')  : 1.0\n",
            "('are', 'explicit')  : 1.0\n",
            "('explicit', 'or')  : 1.0\n",
            "('or', 'implicit')  : 1.0\n",
            "('implicit', 'in')  : 1.0\n",
            "('in', 'musical')  : 1.0\n",
            "('musical', 'works\"\"')  : 0.5\n",
            "('works\"\"', 'Simon')  : 1.0\n",
            "('Simon', '[13].')  : 1.0\n",
            "('Patterns', 'comprise')  : 1.0\n",
            "('comprise', 'periodicity,')  : 1.0\n",
            "('periodicity,', 'make')  : 1.0\n",
            "('make', 'use')  : 1.0\n",
            "('use', 'of')  : 1.0\n",
            "('of', 'alphabets,')  : 0.3333333333333333\n",
            "('alphabets,', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'compound')  : 1.0\n",
            "('compound', '(made')  : 1.0\n",
            "('(made', 'up')  : 1.0\n",
            "('up', 'of')  : 1.0\n",
            "('of', 'subpatterns)')  : 0.3333333333333333\n",
            "('subpatterns)', 'and')  : 1.0\n",
            "('and', 'possess')  : 1.0\n",
            "('possess', 'phrase')  : 1.0\n",
            "('phrase', 'structure')  : 1.0\n",
            "('structure', 'with')  : 1.0\n",
            "('with', 'various')  : 1.0\n",
            "('various', 'forms')  : 1.0\n",
            "('forms', 'of')  : 1.0\n",
            "('of', 'punctuation.')  : 0.3333333333333333\n",
            "('Traditionally,', 'composers')  : 1.0\n",
            "('composers', 'have')  : 1.0\n",
            "('have', 'employed')  : 1.0\n",
            "('employed', 'pattern')  : 1.0\n",
            "('pattern', 'propagation')  : 1.0\n",
            "('propagation', 'intuitively,')  : 0.5\n",
            "('intuitively,', 'but')  : 1.0\n",
            "('but', 'algorithmic')  : 1.0\n",
            "('algorithmic', 'composition')  : 1.0\n",
            "('composition', 'techniques')  : 1.0\n",
            "('techniques', 'allow')  : 1.0\n",
            "('allow', 'the')  : 1.0\n",
            "('the', 'pattern')  : 1.0\n",
            "('propagation', 'to')  : 0.5\n",
            "('to', 'be')  : 1.0\n",
            "('be', 'formalized,')  : 1.0\n",
            "('formalized,', 'albeit')  : 1.0\n",
            "('albeit', 'a')  : 1.0\n",
            "('a', 'high')  : 1.0\n",
            "('high', 'level.')  : 1.0\n",
            "('During', 'composition,')  : 1.0\n",
            "('composition,', 'all')  : 1.0\n",
            "('all', 'the')  : 1.0\n",
            "('the', 'musical')  : 0.3333333333333333\n",
            "('musical', 'patterns')  : 1.0\n",
            "('patterns', 'evolve')  : 1.0\n",
            "('evolve', 'according')  : 1.0\n",
            "('according', 'to')  : 1.0\n",
            "('to', 'the')  : 1.0\n",
            "('the', 'rules')  : 0.3333333333333333\n",
            "('rules', 'and')  : 1.0\n",
            "('and', 'constraints')  : 1.0\n",
            "('constraints', 'specied')  : 1.0\n",
            "('specied', 'at')  : 1.0\n",
            "('at', 'the')  : 1.0\n",
            "('the', 'design')  : 0.3333333333333333\n",
            "('design', 'stage.')  : 1.0\n",
            "('In', 'jazz')  : 1.0\n",
            "('jazz', 'improvisation,')  : 1.0\n",
            "('improvisation,', 'the')  : 1.0\n",
            "('the', 'musician')  : 1.0\n",
            "('musician', 'invents')  : 1.0\n",
            "('invents', 'a')  : 1.0\n",
            "('a', 'solo')  : 0.5\n",
            "('solo', 'guided')  : 1.0\n",
            "('guided', 'by')  : 1.0\n",
            "('by', 'a')  : 1.0\n",
            "('a', 'progression')  : 0.5\n",
            "('progression', 'of')  : 1.0\n",
            "('of', 'chords')  : 1.0\n",
            "('chords', '(the')  : 1.0\n",
            "('(the', 'changes).')  : 1.0\n",
            "('One', 'approach')  : 1.0\n",
            "('approach', '[1]')  : 1.0\n",
            "('[1]', 'to')  : 1.0\n",
            "('to', 'learn')  : 0.25\n",
            "('learn', 'improvising')  : 1.0\n",
            "('improvising', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'memorize')  : 0.25\n",
            "('memorize', 'patterns')  : 1.0\n",
            "('patterns', '(short')  : 1.0\n",
            "('(short', 'chunks')  : 1.0\n",
            "('chunks', 'of')  : 1.0\n",
            "('of', 'music)')  : 1.0\n",
            "('music)', 'that')  : 1.0\n",
            "('that', 't')  : 0.5\n",
            "('t', 'sub-progressions,')  : 1.0\n",
            "('sub-progressions,', 'and')  : 1.0\n",
            "('and', 'to')  : 1.0\n",
            "('to', 'concatenate')  : 0.25\n",
            "('concatenate', 'them')  : 1.0\n",
            "('them', 'to')  : 1.0\n",
            "('to', 'form')  : 0.25\n",
            "('form', 'a')  : 1.0\n",
            "('a', 'whole')  : 1.0\n",
            "('whole', 'solo')  : 0.5\n",
            "('solo', 'that')  : 1.0\n",
            "('that', 'ts')  : 0.5\n",
            "('ts', 'a')  : 1.0\n",
            "('whole', 'progression.')  : 0.5\n",
            "('One', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Abstract')  : 0.5\n",
            "('Abstract', 'Many')  : 1.0\n",
            "('Many', 'information')  : 1.0\n",
            "('information', 'retrieval(IR)')  : 1.0\n",
            "('retrieval(IR)', 'systems')  : 1.0\n",
            "('systems', 'retrieve')  : 1.0\n",
            "('retrieve', 'relevant')  : 1.0\n",
            "('relevant', 'documents')  : 1.0\n",
            "('documents', 'based')  : 1.0\n",
            "('based', 'on')  : 1.0\n",
            "('on', 'exact')  : 1.0\n",
            "('exact', 'matching')  : 1.0\n",
            "('matching', 'of')  : 1.0\n",
            "('of', 'keywords')  : 1.0\n",
            "('keywords', 'between')  : 1.0\n",
            "('between', 'a')  : 1.0\n",
            "('a', 'query')  : 1.0\n",
            "('query', 'and')  : 1.0\n",
            "('and', 'documents.')  : 1.0\n",
            "('This', 'method')  : 1.0\n",
            "('method', 'degrades')  : 1.0\n",
            "('degrades', 'precision')  : 1.0\n",
            "('precision', 'rate.')  : 1.0\n",
            "('In', 'order')  : 1.0\n",
            "('order', 'to')  : 1.0\n",
            "('to', 'solve')  : 1.0\n",
            "('solve', 'the')  : 1.0\n",
            "('the', 'problem,')  : 1.0\n",
            "('problem,', 'we')  : 1.0\n",
            "('we', 'collected')  : 1.0\n",
            "('collected', 'semantically')  : 1.0\n",
            "('semantically', 'related')  : 1.0\n",
            "('related', 'words')  : 1.0\n",
            "('words', 'and')  : 1.0\n",
            "('and', 'assigned')  : 0.5\n",
            "('assigned', 'semantic')  : 1.0\n",
            "('semantic', 'relationships')  : 1.0\n",
            "('relationships', 'used')  : 1.0\n",
            "('used', 'in')  : 1.0\n",
            "('in', 'general')  : 1.0\n",
            "('general', 'thesaurus')  : 1.0\n",
            "('thesaurus', 'and')  : 1.0\n",
            "('and', 'a')  : 0.5\n",
            "('a', 'special')  : 1.0\n",
            "('special', 'relationship')  : 1.0\n",
            "('relationship', 'called')  : 1.0\n",
            "('called', 'keyfact')  : 1.0\n",
            "('keyfact', 'term(FT)')  : 1.0\n",
            "('term(FT)', 'manually.')  : 1.0\n",
            "('In', 'addition')  : 1.0\n",
            "('addition', 'to')  : 1.0\n",
            "('to', 'the')  : 1.0\n",
            "('the', 'semantic')  : 0.5\n",
            "('semantic', 'knowledge,')  : 1.0\n",
            "('knowledge,', 'we')  : 1.0\n",
            "('we', 'automatically')  : 1.0\n",
            "('automatically', 'constructed')  : 1.0\n",
            "('constructed', 'statistic')  : 1.0\n",
            "('statistic', 'knowledge')  : 1.0\n",
            "('knowledge', 'based')  : 1.0\n",
            "('based', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'concept')  : 0.5\n",
            "('concept', 'of')  : 1.0\n",
            "('of', 'mutual')  : 1.0\n",
            "('mutual', 'information.')  : 1.0\n",
            "('Keyfact', 'is')  : 1.0\n",
            "('is', 'an')  : 1.0\n",
            "('an', 'extended')  : 1.0\n",
            "('extended', 'concept')  : 1.0\n",
            "('concept', 'of')  : 1.0\n",
            "('of', 'keyword')  : 1.0\n",
            "('keyword', 'represented')  : 1.0\n",
            "('represented', 'by')  : 1.0\n",
            "('by', 'noun')  : 1.0\n",
            "('noun', 'and')  : 1.0\n",
            "('and', 'compound')  : 1.0\n",
            "('compound', 'noun.')  : 1.0\n",
            "('Keyfact', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'a')  : 1.0\n",
            "('a', 'verb')  : 1.0\n",
            "('verb', 'and')  : 1.0\n",
            "('and', 'an')  : 1.0\n",
            "('an', 'adjective')  : 1.0\n",
            "('adjective', 'including')  : 1.0\n",
            "('including', 'subject')  : 1.0\n",
            "('subject', 'or')  : 1.0\n",
            "('or', 'object')  : 1.0\n",
            "('object', 'term.')  : 1.0\n",
            "('We', 'first')  : 1.0\n",
            "('first', 'retrieved')  : 1.0\n",
            "('retrieved', 'relevant')  : 1.0\n",
            "('relevant', 'documents')  : 1.0\n",
            "('documents', 'with')  : 1.0\n",
            "('with', 'original')  : 1.0\n",
            "('original', 'query')  : 1.0\n",
            "('query', 'using')  : 0.5\n",
            "('using', 'tf')  : 1.0\n",
            "('tf', '*')  : 1.0\n",
            "('*', 'idf')  : 1.0\n",
            "('idf', 'weighting')  : 1.0\n",
            "('weighting', 'formula')  : 1.0\n",
            "('formula', 'and')  : 1.0\n",
            "('and', 'then')  : 0.5\n",
            "('then', 'an')  : 1.0\n",
            "('an', 'expanded')  : 1.0\n",
            "('expanded', 'query')  : 1.0\n",
            "('query', 'including')  : 0.5\n",
            "('including', 'keyfacts')  : 1.0\n",
            "('keyfacts', 'is')  : 1.0\n",
            "('is', 'used')  : 1.0\n",
            "('used', 'in')  : 1.0\n",
            "('in', 'both')  : 1.0\n",
            "('both', 'second')  : 1.0\n",
            "('second', 'document')  : 1.0\n",
            "('document', 'ranking')  : 1.0\n",
            "('ranking', 'and')  : 1.0\n",
            "('and', 'word')  : 0.5\n",
            "('word', 'sense')  : 1.0\n",
            "('sense', 'disambiguating.')  : 1.0\n",
            "('So', 'we')  : 1.0\n",
            "('we', 'made')  : 1.0\n",
            "('made', 'an')  : 1.0\n",
            "('an', 'improvement')  : 1.0\n",
            "('improvement', 'in')  : 1.0\n",
            "('in', 'precision')  : 1.0\n",
            "('precision', 'rate')  : 1.0\n",
            "('rate', 'using')  : 1.0\n",
            "('using', 'keyfact')  : 1.0\n",
            "('keyfact', 'network.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', 'this')  : 1.0\n",
            "('this', 'paper')  : 1.0\n",
            "('paper', 'we')  : 1.0\n",
            "('we', 'argue')  : 1.0\n",
            "('argue', 'that')  : 1.0\n",
            "('that', 'questionanswering')  : 0.5\n",
            "('questionanswering', '(QA)')  : 1.0\n",
            "('(QA)', 'over')  : 1.0\n",
            "('over', 'technical')  : 1.0\n",
            "('technical', 'domains')  : 1.0\n",
            "('domains', 'is')  : 1.0\n",
            "('is', 'distinctly')  : 1.0\n",
            "('distinctly', 'different')  : 1.0\n",
            "('different', 'from')  : 1.0\n",
            "('from', 'TREC-based')  : 1.0\n",
            "('TREC-based', 'QA')  : 1.0\n",
            "('QA', 'or')  : 0.5\n",
            "('or', 'Web-based')  : 1.0\n",
            "('Web-based', 'QA')  : 1.0\n",
            "('QA', 'and')  : 0.5\n",
            "('and', 'it')  : 0.5\n",
            "('it', 'cannot')  : 1.0\n",
            "('cannot', 'benefit')  : 1.0\n",
            "('benefit', 'lom')  : 1.0\n",
            "('lom', 'data-intensive')  : 1.0\n",
            "('data-intensive', 'approaches')  : 1.0\n",
            "('approaches', 'Universit&quot;at')  : 1.0\n",
            "('Universit&quot;at', 'des')  : 1.0\n",
            "('des', 'Saarlandes')  : 1.0\n",
            "('Saarlandes', 'Proceedings')  : 1.0\n",
            "('Proceedings', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'Workshop')  : 0.5\n",
            "('Workshop', 'on')  : 1.0\n",
            "('on', 'uni-hamburg.de')  : 1.0\n",
            "('uni-hamburg.de', 'Abstract')  : 1.0\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', 'Abstract')  : 0.5\n",
            "('found', 'SRI')  : 0.5\n",
            "('SRI', 'has')  : 1.0\n",
            "('has', 'developed')  : 1.0\n",
            "('developed', 'a')  : 1.0\n",
            "('a', 'new')  : 0.5\n",
            "('new', 'architecture')  : 1.0\n",
            "('architecture', 'for')  : 1.0\n",
            "('for', 'integrating')  : 1.0\n",
            "('integrating', 'speech')  : 1.0\n",
            "('speech', 'and')  : 1.0\n",
            "('and', 'natural-language')  : 0.5\n",
            "('natural-language', 'processing')  : 1.0\n",
            "('processing', 'that')  : 1.0\n",
            "('that', 'applies')  : 0.5\n",
            "('applies', 'linguistic')  : 1.0\n",
            "('linguistic', 'constraints')  : 1.0\n",
            "('constraints', 'during')  : 1.0\n",
            "('during', 'recognition')  : 1.0\n",
            "('recognition', 'by')  : 1.0\n",
            "('by', 'incrementally')  : 1.0\n",
            "('incrementally', 'expanding')  : 1.0\n",
            "('expanding', 'the')  : 1.0\n",
            "('the', 'state-transition')  : 0.5\n",
            "('state-transition', 'network')  : 1.0\n",
            "('network', 'embodied')  : 1.0\n",
            "('embodied', 'in')  : 1.0\n",
            "('in', 'a')  : 1.0\n",
            "('a', 'unification')  : 0.5\n",
            "('unification', 'grammar.')  : 1.0\n",
            "('We', 'compare')  : 1.0\n",
            "('compare', 'this')  : 1.0\n",
            "('this', 'dynamic-gralnlnar-network')  : 1.0\n",
            "('dynamic-gralnlnar-network', '(DGN)')  : 1.0\n",
            "('(DGN)', 'approach')  : 1.0\n",
            "('approach', 'This')  : 1.0\n",
            "('This', 'chapter')  : 1.0\n",
            "('chapter', 'considers')  : 1.0\n",
            "('considers', 'the')  : 1.0\n",
            "('the', 'revolution')  : 0.5\n",
            "('revolution', 'that')  : 1.0\n",
            "('that', 'has')  : 1.0\n",
            "('has', 'taken')  : 1.0\n",
            "('taken', 'place')  : 1.0\n",
            "('place', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'research')  : 1.0\n",
            "('research', 'over')  : 1.0\n",
            "('over', 'the')  : 1.0\n",
            "('the', 'last')  : 0.5\n",
            "('last', 'five')  : 1.0\n",
            "('five', 'years.')  : 1.0\n",
            "('It', 'begins')  : 1.0\n",
            "('begins', 'by')  : 1.0\n",
            "('by', 'providing')  : 1.0\n",
            "('providing', 'a')  : 1.0\n",
            "('a', 'brief')  : 0.5\n",
            "('brief', 'guide')  : 1.0\n",
            "('guide', 'to')  : 1.0\n",
            "('to', 'the')  : 0.5\n",
            "('the', 'structure')  : 0.25\n",
            "('structure', 'of')  : 1.0\n",
            "('of', 'the')  : 0.25\n",
            "('the', 'field')  : 0.25\n",
            "('field', 'and')  : 1.0\n",
            "('and', 'then')  : 0.3333333333333333\n",
            "('then', 'presents')  : 1.0\n",
            "('presents', 'a')  : 1.0\n",
            "('a', 'caricature')  : 0.5\n",
            "('caricature', 'of')  : 1.0\n",
            "('of', 'two')  : 0.25\n",
            "('two', 'competing')  : 1.0\n",
            "('competing', 'paradigms')  : 1.0\n",
            "('paradigms', 'of')  : 1.0\n",
            "('of', '1980s')  : 0.25\n",
            "('1980s', 'NLP')  : 1.0\n",
            "('NLP', 'research')  : 1.0\n",
            "('research', 'and')  : 1.0\n",
            "('and', 'indicates')  : 0.3333333333333333\n",
            "('indicates', 'the')  : 1.0\n",
            "('the', 'reasons')  : 0.25\n",
            "('reasons', '\"')  : 1.0\n",
            "('\"', 'visual')  : 1.0\n",
            "('visual', 'development')  : 0.5\n",
            "('development', 'environment')  : 1.0\n",
            "('environment', 'to')  : 1.0\n",
            "('to', 'support')  : 0.5\n",
            "('support', 'the')  : 1.0\n",
            "('the', 'visual')  : 0.25\n",
            "('visual', 'assembly,')  : 0.5\n",
            "('assembly,', 'execution')  : 1.0\n",
            "('execution', 'and')  : 1.0\n",
            "('and', 'analysis')  : 0.3333333333333333\n",
            "('analysis', 'of')  : 1.0\n",
            "('of', 'modular')  : 0.25\n",
            "('modular', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'systems.')  : 1.0\n",
            "('The', 'visual')  : 1.0\n",
            "('visual', 'model')  : 1.0\n",
            "('model', 'is')  : 1.0\n",
            "('is', 'an')  : 1.0\n",
            "('an', 'executable')  : 1.0\n",
            "('executable', 'data')  : 1.0\n",
            "('data', 'flow')  : 0.5\n",
            "('flow', 'program')  : 1.0\n",
            "('program', 'graph,')  : 1.0\n",
            "('graph,', 'automatically')  : 1.0\n",
            "('automatically', 'synthesised')  : 1.0\n",
            "('synthesised', 'from')  : 1.0\n",
            "('from', 'data')  : 1.0\n",
            "('data', 'dependency')  : 0.5\n",
            "('dependency', 'declarations')  : 1.0\n",
            "('declarations', 'of')  : 1.0\n",
            "('of', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'modules.')  : 1.0\n",
            "('The', 'graph')  : 1.0\n",
            "('graph', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'In')  : 0.5\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'Chapter')  : 1.0\n",
            "('Chapter', 'the')  : 1.0\n",
            "('the', 'basic')  : 0.25\n",
            "('basic', 'uses')  : 1.0\n",
            "('uses', 'of')  : 1.0\n",
            "('of', 'Description')  : 0.5\n",
            "('Description', 'Logics')  : 1.0\n",
            "('Logics', 'for')  : 0.5\n",
            "('for', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'will')  : 1.0\n",
            "('will', 'be')  : 1.0\n",
            "('be', 'analysed,')  : 0.5\n",
            "('analysed,', 'together')  : 1.0\n",
            "('together', 'with')  : 1.0\n",
            "('with', 'a')  : 1.0\n",
            "('a', 'little')  : 1.0\n",
            "('little', 'bit')  : 1.0\n",
            "('bit', 'of')  : 1.0\n",
            "('of', 'history,')  : 0.25\n",
            "('history,', 'and')  : 1.0\n",
            "('and', 'the')  : 1.0\n",
            "('the', 'role')  : 0.25\n",
            "('role', 'of')  : 1.0\n",
            "('Logics', 'in')  : 0.5\n",
            "('in', 'the')  : 0.5\n",
            "('the', 'current')  : 0.25\n",
            "('current', 'state')  : 1.0\n",
            "('state', 'of')  : 1.0\n",
            "('of', 'the')  : 0.25\n",
            "('the', 'art')  : 0.25\n",
            "('art', 'in')  : 1.0\n",
            "('in', 'computational')  : 0.5\n",
            "('computational', 'linguistics')  : 1.0\n",
            "('linguistics', 'will')  : 1.0\n",
            "('be', 'pointed')  : 0.5\n",
            "('pointed', 'out.')  : 1.0\n",
            "('18.1', 'Introduction')  : 1.0\n",
            "('Introduction', 'Since')  : 1.0\n",
            "('Since', 'the')  : 1.0\n",
            "('the', 'early')  : 0.25\n",
            "('early', 'days')  : 1.0\n",
            "('days', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'applied')  : 1.0\n",
            "('applied', 'a')  : 1.0\n",
            "('a', 'structure')  : 1.0\n",
            "('structure', 'learning')  : 1.0\n",
            "('learning', 'model,')  : 1.0\n",
            "('model,', 'Max-Margin')  : 1.0\n",
            "('Max-Margin', 'Structure')  : 1.0\n",
            "('Structure', '(MMS),')  : 1.0\n",
            "('(MMS),', 'to')  : 1.0\n",
            "('to', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'tasks,')  : 1.0\n",
            "('tasks,', 'where')  : 1.0\n",
            "('where', 'the')  : 1.0\n",
            "('the', 'aim')  : 0.25\n",
            "('aim', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'capture')  : 0.5\n",
            "('capture', 'the')  : 1.0\n",
            "('the', 'latent')  : 0.25\n",
            "('latent', 'relationships')  : 1.0\n",
            "('relationships', 'within')  : 1.0\n",
            "('within', 'the')  : 1.0\n",
            "('the', 'output')  : 0.25\n",
            "('output', 'language')  : 1.0\n",
            "('language', 'domain.')  : 0.5\n",
            "('We', 'formulate')  : 1.0\n",
            "('formulate', 'this')  : 1.0\n",
            "('this', 'model')  : 1.0\n",
            "('model', 'as')  : 1.0\n",
            "('as', 'an')  : 1.0\n",
            "('an', 'extension')  : 1.0\n",
            "('extension', 'of')  : 1.0\n",
            "('of', 'multi–class')  : 1.0\n",
            "('multi–class', 'Support')  : 1.0\n",
            "('Support', 'Vector')  : 1.0\n",
            "('Vector', 'Machine')  : 1.0\n",
            "('Machine', '(SVM)')  : 1.0\n",
            "('(SVM)', 'and')  : 1.0\n",
            "('and', 'present')  : 1.0\n",
            "('present', 'a')  : 1.0\n",
            "('a', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', '-mation')  : 0.5\n",
            "('-mation', 'Infrastructure,')  : 1.0\n",
            "('Infrastructure,', 'digital')  : 1.0\n",
            "('digital', 'libraries,')  : 0.5\n",
            "('libraries,', 'networked')  : 1.0\n",
            "('networked', 'services,')  : 1.0\n",
            "('services,', 'digital')  : 1.0\n",
            "('digital', 'convergence')  : 0.5\n",
            "('convergence', 'or')  : 1.0\n",
            "('or', 'intelligent')  : 1.0\n",
            "('intelligent', 'agents.')  : 1.0\n",
            "('This', 'attention')  : 1.0\n",
            "('attention', 'is')  : 1.0\n",
            "('is', 'moving')  : 1.0\n",
            "('moving', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'along')  : 1.0\n",
            "('along', 'the')  : 1.0\n",
            "('the', 'critical')  : 1.0\n",
            "('critical', 'path')  : 1.0\n",
            "('path', 'for')  : 1.0\n",
            "('for', 'all')  : 1.0\n",
            "('all', 'kinds')  : 1.0\n",
            "('kinds', 'of')  : 1.0\n",
            "('of', 'novel')  : 1.0\n",
            "('novel', 'applications.')  : 1.0\n",
            "('This', 'article')  : 1.0\n",
            "('article', 'will')  : 1.0\n",
            "('will', 'mention')  : 1.0\n",
            "('mention', 'a')  : 1.0\n",
            "('a', 'number')  : 1.0\n",
            "('number', 'of')  : 1.0\n",
            "('of', 'successful')  : 0.25\n",
            "('successful', 'applications')  : 1.0\n",
            "('applications', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', '(NLP')  : 0.5\n",
            "('(NLP', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Over')  : 0.5\n",
            "('Over', 'the')  : 1.0\n",
            "('the', 'last')  : 1.0\n",
            "('last', 'few')  : 1.0\n",
            "('few', 'years,')  : 1.0\n",
            "('years,', 'a')  : 1.0\n",
            "('of', 'areas')  : 0.25\n",
            "('areas', 'of')  : 1.0\n",
            "('processing', 'have')  : 0.5\n",
            "('have', 'begun')  : 1.0\n",
            "('begun', 'applying')  : 1.0\n",
            "('applying', 'graph-based')  : 1.0\n",
            "('graph-based', 'techniques.')  : 1.0\n",
            "('These', 'include,')  : 1.0\n",
            "('include,', 'among')  : 1.0\n",
            "('among', 'others,')  : 1.0\n",
            "('others,', 'text')  : 1.0\n",
            "('text', 'summarization,')  : 0.5\n",
            "('summarization,', 'syntactic')  : 1.0\n",
            "('syntactic', 'parsing,')  : 1.0\n",
            "('parsing,', 'word')  : 1.0\n",
            "('word', 'sense')  : 1.0\n",
            "('sense', 'disambiguation,')  : 1.0\n",
            "('disambiguation,', 'ontology')  : 1.0\n",
            "('ontology', 'construction,')  : 1.0\n",
            "('construction,', 'sentiment')  : 1.0\n",
            "('sentiment', 'and')  : 1.0\n",
            "('and', 'subjectivity')  : 0.5\n",
            "('subjectivity', 'analysis,')  : 1.0\n",
            "('analysis,', 'text')  : 1.0\n",
            "('text', 'clustering')  : 0.5\n",
            "('clustering', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.3333333333333333\n",
            "('\"', 'In')  : 0.3333333333333333\n",
            "('In', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP),')  : 1.0\n",
            "('(NLP),', 'research')  : 1.0\n",
            "('research', 'results')  : 1.0\n",
            "('results', 'from')  : 1.0\n",
            "('from', 'software')  : 1.0\n",
            "('software', 'engineering')  : 0.5\n",
            "('engineering', 'and')  : 1.0\n",
            "('and', 'software')  : 0.5\n",
            "('software', 'technology')  : 0.5\n",
            "('technology', 'have')  : 1.0\n",
            "('have', 'often')  : 1.0\n",
            "('often', 'been')  : 1.0\n",
            "('been', 'neglected.')  : 1.0\n",
            "('neglected.', '\"')  : 1.0\n",
            "('\"', 'of')  : 1.0\n",
            "('of', 'kernelized')  : 1.0\n",
            "('kernelized', 'sorting')  : 1.0\n",
            "('sorting', 'to')  : 1.0\n",
            "('to', 'increase')  : 1.0\n",
            "('increase', 'its')  : 1.0\n",
            "('its', 'robustness')  : 1.0\n",
            "('robustness', 'and')  : 1.0\n",
            "('and', 'performance')  : 0.3333333333333333\n",
            "('performance', 'on')  : 1.0\n",
            "('on', 'several')  : 1.0\n",
            "('several', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'tasks:')  : 1.0\n",
            "('tasks:', 'document')  : 1.0\n",
            "('document', 'matching')  : 1.0\n",
            "('matching', 'from')  : 1.0\n",
            "('from', 'parallel')  : 1.0\n",
            "('parallel', 'and')  : 1.0\n",
            "('and', 'comparable')  : 0.3333333333333333\n",
            "('comparable', 'corpora,')  : 1.0\n",
            "('corpora,', 'machine')  : 1.0\n",
            "('machine', 'transliteration')  : 1.0\n",
            "('transliteration', 'and')  : 1.0\n",
            "('and', 'even')  : 0.3333333333333333\n",
            "('even', 'image')  : 1.0\n",
            "('image', 'processing.')  : 1.0\n",
            "('Empirically', 'we')  : 1.0\n",
            "('we', 'show')  : 1.0\n",
            "('show', 'that,')  : 1.0\n",
            "('that,', 'on')  : 1.0\n",
            "('on', 'these')  : 1.0\n",
            "('these', 'tasks,')  : 1.0\n",
            "('tasks,', 'a')  : 1.0\n",
            "('a', 'semi-supervised')  : 1.0\n",
            "('semi-supervised', 'variant')  : 1.0\n",
            "('variant', 'of')  : 1.0\n",
            "('of', 'kernelized')  : 1.0\n",
            "('kernelized', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'will')  : 0.5\n",
            "('will', 'be')  : 1.0\n",
            "('be', 'structured.')  : 1.0\n",
            "('In', 'the')  : 1.0\n",
            "('the', 'words')  : 0.3333333333333333\n",
            "('words', 'of')  : 0.5\n",
            "('of', 'statistical')  : 0.5\n",
            "('statistical', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing,')  : 1.0\n",
            "('processing,', 'we')  : 1.0\n",
            "('we', 'need')  : 1.0\n",
            "('need', 'a')  : 1.0\n",
            "('a', 'sophisticated')  : 1.0\n",
            "('sophisticated', 'statistical')  : 1.0\n",
            "('statistical', 'model')  : 0.5\n",
            "('model', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'basic')  : 0.3333333333333333\n",
            "('basic', 'elements,')  : 1.0\n",
            "('elements,', 'such')  : 1.0\n",
            "('such', 'as')  : 1.0\n",
            "('as', 'words')  : 0.5\n",
            "('words', 'or')  : 0.5\n",
            "('or', 'phrases,')  : 0.5\n",
            "('phrases,', 'to')  : 1.0\n",
            "('to', 'be')  : 1.0\n",
            "('be', 'combined')  : 1.0\n",
            "('combined', 'with')  : 1.0\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'structural')  : 0.3333333333333333\n",
            "('structural', 'modeling')  : 1.0\n",
            "('modeling', 'such')  : 1.0\n",
            "('as', 'syntactic')  : 0.5\n",
            "('syntactic', 'parsing')  : 1.0\n",
            "('parsing', 'or')  : 1.0\n",
            "('or', 'dependency')  : 0.5\n",
            "('dependency', 'analysis.')  : 1.0\n",
            "('Since', 'the')  : 1.0\n",
            "('the', 'basic')  : 1.0\n",
            "('basic', 'property')  : 1.0\n",
            "('property', 'of')  : 1.0\n",
            "('of', 'these')  : 1.0\n",
            "('these', 'elements')  : 1.0\n",
            "('elements', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'In')  : 0.5\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'paper,')  : 1.0\n",
            "('paper,', 'we')  : 1.0\n",
            "('we', 'describe')  : 1.0\n",
            "('describe', 'a')  : 1.0\n",
            "('a', 'framework')  : 1.0\n",
            "('framework', 'for')  : 1.0\n",
            "('for', 'developing')  : 1.0\n",
            "('developing', 'probabilistic')  : 1.0\n",
            "('probabilistic', 'classifiers')  : 1.0\n",
            "('classifiers', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('Our', 'focus')  : 1.0\n",
            "('focus', 'is')  : 1.0\n",
            "('is', 'on')  : 1.0\n",
            "('on', 'formulating')  : 1.0\n",
            "('formulating', 'models')  : 1.0\n",
            "('models', 'that')  : 1.0\n",
            "('that', 'capture')  : 1.0\n",
            "('capture', 'the')  : 1.0\n",
            "('the', 'most')  : 0.3333333333333333\n",
            "('most', 'important')  : 1.0\n",
            "('important', 'interdependencies')  : 1.0\n",
            "('interdependencies', 'among')  : 1.0\n",
            "('among', 'features,')  : 1.0\n",
            "('features,', 'to')  : 1.0\n",
            "('to', 'avoid')  : 1.0\n",
            "('avoid', 'overfitting')  : 1.0\n",
            "('overfitting', 'the')  : 1.0\n",
            "('the', 'data')  : 0.6666666666666666\n",
            "('data', 'while')  : 0.5\n",
            "('while', 'also')  : 1.0\n",
            "('also', 'characterizing')  : 1.0\n",
            "('characterizing', 'the')  : 1.0\n",
            "('data', 'well.')  : 0.5\n",
            "('The', 'class')  : 1.0\n",
            "('class', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Many')  : 0.5\n",
            "('Many', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'techniques')  : 1.0\n",
            "('techniques', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', 'used')  : 1.0\n",
            "('used', 'in')  : 1.0\n",
            "('in', 'Information')  : 1.0\n",
            "('Information', 'Retrieval.')  : 1.0\n",
            "('The', 'results')  : 1.0\n",
            "('results', 'are')  : 1.0\n",
            "('are', 'not')  : 1.0\n",
            "('not', 'encouraging.')  : 1.0\n",
            "('Simple', 'methods')  : 1.0\n",
            "('methods', '(stopwording,')  : 1.0\n",
            "('(stopwording,', 'porter-style')  : 1.0\n",
            "('porter-style', 'stemming,')  : 1.0\n",
            "('stemming,', 'etc.)')  : 1.0\n",
            "('usually', 'yield')  : 1.0\n",
            "('yield', 'significant')  : 1.0\n",
            "('significant', 'improvements,')  : 1.0\n",
            "('improvements,', 'while')  : 1.0\n",
            "('while', 'higher-level')  : 1.0\n",
            "('higher-level', 'processing')  : 1.0\n",
            "('processing', '(chunking,')  : 0.5\n",
            "('(chunking,', 'parsing,')  : 1.0\n",
            "('parsing,', 'word')  : 1.0\n",
            "('word', 'sense')  : 1.0\n",
            "('sense', 'disambiguation')  : 1.0\n",
            "('disambiguation', '\"')  : 1.0\n",
            "('\"', 'Abstract-')  : 0.5\n",
            "('Abstract-', 'This')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'explains')  : 1.0\n",
            "('explains', 'the')  : 1.0\n",
            "('the', 'information')  : 0.3333333333333333\n",
            "('information', 'retrieval')  : 1.0\n",
            "('retrieval', 'using')  : 1.0\n",
            "('using', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'for')  : 0.5\n",
            "('for', 'Malayalam')  : 1.0\n",
            "('Malayalam', 'language')  : 1.0\n",
            "('language', 'in')  : 0.5\n",
            "('in', 'these')  : 0.5\n",
            "('these', 'basic')  : 1.0\n",
            "('basic', '\"')  : 1.0\n",
            "('\"', 'in')  : 0.5\n",
            "('in', 'the')  : 0.5\n",
            "('the', 'state')  : 0.3333333333333333\n",
            "('state', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'art')  : 0.3333333333333333\n",
            "('art', 'plan')  : 1.0\n",
            "('plan', 'recognition')  : 1.0\n",
            "('recognition', 'systems.')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'will')  : 1.0\n",
            "('will', 'outline')  : 1.0\n",
            "('outline', 'the')  : 1.0\n",
            "('the', 'relations')  : 0.5\n",
            "('relations', 'between')  : 1.0\n",
            "('between', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing(NLP)')  : 1.0\n",
            "('processing(NLP)', 'and')  : 1.0\n",
            "('and', 'plan')  : 0.3333333333333333\n",
            "('plan', 'recognition(PR),')  : 1.0\n",
            "('recognition(PR),', 'argue')  : 1.0\n",
            "('argue', 'that')  : 0.5\n",
            "('that', 'each')  : 1.0\n",
            "('each', 'of')  : 1.0\n",
            "('of', 'them')  : 1.0\n",
            "('them', 'can')  : 1.0\n",
            "('can', 'effectively')  : 1.0\n",
            "('effectively', 'inform')  : 1.0\n",
            "('inform', 'the')  : 1.0\n",
            "('the', 'other,')  : 0.5\n",
            "('other,', 'and')  : 1.0\n",
            "('and', 'then')  : 0.3333333333333333\n",
            "('then', 'focus')  : 1.0\n",
            "('focus', 'on')  : 1.0\n",
            "('on', 'key')  : 1.0\n",
            "('key', 'recent')  : 1.0\n",
            "('recent', 'research')  : 1.0\n",
            "('research', 'results')  : 1.0\n",
            "('results', 'in')  : 1.0\n",
            "('in', 'NLP')  : 1.0\n",
            "('NLP', 'and')  : 1.0\n",
            "('and', 'argue')  : 0.3333333333333333\n",
            "('argue', 'for')  : 0.5\n",
            "('for', 'their')  : 1.0\n",
            "('their', 'applicability')  : 1.0\n",
            "('applicability', 'to')  : 1.0\n",
            "('to', 'PR.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'in')  : 0.5\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'state')  : 0.5\n",
            "('state', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'art')  : 0.5\n",
            "('art', 'plan')  : 1.0\n",
            "('plan', 'recognition')  : 1.0\n",
            "('recognition', 'systems.')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'will')  : 1.0\n",
            "('will', 'outline')  : 1.0\n",
            "('outline', 'the')  : 1.0\n",
            "('the', 'relations')  : 0.5\n",
            "('relations', 'between')  : 1.0\n",
            "('between', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing(NLP)')  : 1.0\n",
            "('processing(NLP)', 'and')  : 1.0\n",
            "('and', 'plan')  : 0.3333333333333333\n",
            "('plan', 'recognition(PR),')  : 1.0\n",
            "('recognition(PR),', 'argue')  : 1.0\n",
            "('argue', 'that')  : 0.5\n",
            "('that', 'each')  : 1.0\n",
            "('each', 'of')  : 1.0\n",
            "('of', 'them')  : 1.0\n",
            "('them', 'can')  : 1.0\n",
            "('can', 'effectively')  : 1.0\n",
            "('effectively', 'inform')  : 1.0\n",
            "('inform', 'the')  : 1.0\n",
            "('the', 'other,')  : 0.5\n",
            "('other,', 'and')  : 1.0\n",
            "('and', 'then')  : 0.3333333333333333\n",
            "('then', 'focus')  : 1.0\n",
            "('focus', 'on')  : 1.0\n",
            "('on', 'key')  : 1.0\n",
            "('key', 'recent')  : 1.0\n",
            "('recent', 'research')  : 1.0\n",
            "('research', 'results')  : 1.0\n",
            "('results', 'in')  : 1.0\n",
            "('in', 'NLP')  : 1.0\n",
            "('NLP', 'and')  : 1.0\n",
            "('and', 'argue')  : 0.3333333333333333\n",
            "('argue', 'for')  : 0.5\n",
            "('for', 'their')  : 1.0\n",
            "('their', 'applicability')  : 1.0\n",
            "('applicability', 'to')  : 1.0\n",
            "('to', 'PR.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Information')  : 0.5\n",
            "('Information', 'retrieval')  : 1.0\n",
            "('retrieval', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'process')  : 0.25\n",
            "('process', 'of')  : 1.0\n",
            "('of', 'finding')  : 0.5\n",
            "('finding', 'the')  : 1.0\n",
            "('the', 'documents')  : 0.25\n",
            "('documents', 'in')  : 1.0\n",
            "('in', 'a')  : 1.0\n",
            "('a', 'document')  : 1.0\n",
            "('document', 'collection')  : 1.0\n",
            "('collection', 'that')  : 1.0\n",
            "('that', 'satisfies')  : 1.0\n",
            "('satisfies', 'the')  : 1.0\n",
            "('the', 'information')  : 0.25\n",
            "('information', 'need')  : 1.0\n",
            "('need', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'user.')  : 0.25\n",
            "('The', 'documents')  : 1.0\n",
            "('documents', 'are')  : 1.0\n",
            "('are', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'constructs,')  : 0.3333333333333333\n",
            "('constructs,', 'and')  : 1.0\n",
            "('and', 'the')  : 0.5\n",
            "('the', 'motivation')  : 1.0\n",
            "('motivation', 'of')  : 1.0\n",
            "('of', 'this')  : 0.3333333333333333\n",
            "('this', 'work')  : 1.0\n",
            "('work', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'investigate')  : 0.5\n",
            "('investigate', 'how')  : 1.0\n",
            "('how', 'natural')  : 1.0\n",
            "('language', 'processing')  : 0.3333333333333333\n",
            "('processing', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'used')  : 1.0\n",
            "('used', 'to')  : 1.0\n",
            "('to', 'improve')  : 0.5\n",
            "('improve', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'of')  : 0.5\n",
            "('of', 'logic')  : 0.3333333333333333\n",
            "('logic', 'programming')  : 0.5\n",
            "('programming', 'within')  : 1.0\n",
            "('within', 'both')  : 0.5\n",
            "('both', 'natural')  : 1.0\n",
            "('language', 'research')  : 0.3333333333333333\n",
            "('research', 'and')  : 1.0\n",
            "('and', 'machine')  : 0.5\n",
            "('machine', 'learning,')  : 1.0\n",
            "('learning,', 'we')  : 1.0\n",
            "('we', 'point')  : 1.0\n",
            "('point', 'out')  : 1.0\n",
            "('out', 'opportunities')  : 1.0\n",
            "('opportunities', 'for')  : 1.0\n",
            "('for', 'induction')  : 1.0\n",
            "('induction', 'of')  : 1.0\n",
            "('of', 'linguistic')  : 0.3333333333333333\n",
            "('linguistic', 'knowledge')  : 1.0\n",
            "('knowledge', 'within')  : 1.0\n",
            "('within', 'logic')  : 0.5\n",
            "('logic', '(programming).')  : 0.5\n",
            "('Keywords:', 'inductive')  : 1.0\n",
            "('inductive', 'logic')  : 1.0\n",
            "('logic', 'programming,')  : 1.0\n",
            "('programming,', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing,')  : 1.0\n",
            "('processing,', 'logic')  : 1.0\n",
            "('programming,', 'machine')  : 0.5\n",
            "('machine', 'learning.')  : 1.0\n",
            "('1', 'Introduction')  : 1.0\n",
            "('Introduction', 'There')  : 1.0\n",
            "('There', 'is')  : 1.0\n",
            "('is', 'a')  : 1.0\n",
            "('a', '\"')  : 0.5\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'What')  : 0.5\n",
            "('What', 'is')  : 1.0\n",
            "('a', 'statistical')  : 0.5\n",
            "('statistical', 'method')  : 1.0\n",
            "('method', 'and')  : 1.0\n",
            "('and', 'how')  : 1.0\n",
            "('how', 'can')  : 1.0\n",
            "('can', 'it')  : 1.0\n",
            "('it', 'be')  : 1.0\n",
            "('be', 'used')  : 1.0\n",
            "('used', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', '(NLP)?')  : 1.0\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'paper,')  : 1.0\n",
            "('paper,', 'we')  : 1.0\n",
            "('we', 'start')  : 1.0\n",
            "('start', 'from')  : 1.0\n",
            "('from', 'a')  : 1.0\n",
            "('a', 'definition')  : 1.0\n",
            "('definition', 'of')  : 1.0\n",
            "('of', 'NLP')  : 0.5\n",
            "('NLP', 'as')  : 1.0\n",
            "('as', 'concerned')  : 1.0\n",
            "('concerned', 'with')  : 1.0\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'design')  : 1.0\n",
            "('design', 'and')  : 1.0\n",
            "('and', 'implementation')  : 0.5\n",
            "('implementation', 'of')  : 1.0\n",
            "('of', 'effective')  : 0.5\n",
            "('effective', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'input')  : 1.0\n",
            "('input', 'and')  : 1.0\n",
            "('and', 'output')  : 0.5\n",
            "('output', 'components')  : 1.0\n",
            "('components', 'for')  : 1.0\n",
            "('for', 'computational')  : 1.0\n",
            "('computational', 'systems.')  : 1.0\n",
            "('We', 'distinguish')  : 1.0\n",
            "('distinguish', 'three')  : 1.0\n",
            "('three', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'In')  : 0.5\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'report,')  : 1.0\n",
            "('report,', 'some')  : 1.0\n",
            "('some', 'collaborative')  : 1.0\n",
            "('collaborative', 'work')  : 1.0\n",
            "('work', 'between')  : 1.0\n",
            "('between', 'the')  : 1.0\n",
            "('the', 'fields')  : 1.0\n",
            "('fields', 'of')  : 1.0\n",
            "('of', 'Machine')  : 1.0\n",
            "('Machine', 'Learning')  : 1.0\n",
            "('Learning', '(ML)')  : 1.0\n",
            "('(ML)', 'and')  : 1.0\n",
            "('and', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'is')  : 1.0\n",
            "('is', 'presented.')  : 1.0\n",
            "('The', 'document')  : 1.0\n",
            "('document', 'is')  : 1.0\n",
            "('is', 'structured')  : 1.0\n",
            "('structured', 'in')  : 1.0\n",
            "('in', 'two')  : 1.0\n",
            "('two', 'parts.')  : 1.0\n",
            "('The', 'first')  : 1.0\n",
            "('first', 'part')  : 1.0\n",
            "('part', 'includes')  : 1.0\n",
            "('includes', 'a')  : 1.0\n",
            "('a', 'superficial')  : 1.0\n",
            "('superficial', 'but')  : 1.0\n",
            "('but', 'comprehensive')  : 1.0\n",
            "('comprehensive', 'survey')  : 1.0\n",
            "('survey', 'covering')  : 1.0\n",
            "('covering', 'the')  : 1.0\n",
            "('the', 'state--of--the--art')  : 1.0\n",
            "('state--of--the--art', 'of')  : 1.0\n",
            "('of', 'machine')  : 1.0\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Abstract.')  : 0.5\n",
            "('This', 'thesis')  : 1.0\n",
            "('thesis', 'examines')  : 1.0\n",
            "('examines', 'the')  : 1.0\n",
            "('the', 'use')  : 0.5\n",
            "('use', 'of')  : 1.0\n",
            "('of', 'machine')  : 0.3333333333333333\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', 'techniques')  : 1.0\n",
            "('techniques', 'in')  : 1.0\n",
            "('in', 'various')  : 1.0\n",
            "('various', 'tasks')  : 1.0\n",
            "('tasks', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.3333333333333333\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing,')  : 1.0\n",
            "('processing,', 'mainly')  : 1.0\n",
            "('mainly', 'for')  : 1.0\n",
            "('for', 'the')  : 1.0\n",
            "('the', 'task')  : 0.5\n",
            "('task', 'of')  : 1.0\n",
            "('of', 'information')  : 0.3333333333333333\n",
            "('information', 'extraction')  : 1.0\n",
            "('extraction', 'from')  : 1.0\n",
            "('from', 'texts.')  : 1.0\n",
            "('The', 'objectives')  : 1.0\n",
            "('objectives', 'are')  : 1.0\n",
            "('are', 'the')  : 1.0\n",
            "('the', 'improvement')  : 0.25\n",
            "('improvement', 'of')  : 1.0\n",
            "('of', 'adaptability')  : 0.25\n",
            "('adaptability', 'of')  : 1.0\n",
            "('of', 'information')  : 0.25\n",
            "('information', 'extraction')  : 1.0\n",
            "('extraction', 'systems')  : 1.0\n",
            "('systems', 'to')  : 1.0\n",
            "('to', 'new')  : 0.5\n",
            "('new', 'thematic')  : 1.0\n",
            "('thematic', 'do-mains')  : 1.0\n",
            "('do-mains', '(or')  : 1.0\n",
            "('(or', 'even')  : 1.0\n",
            "('even', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'chapter')  : 1.0\n",
            "('chapter', 'examines')  : 1.0\n",
            "('examines', 'the')  : 1.0\n",
            "('the', 'application')  : 0.25\n",
            "('application', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.25\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'to')  : 1.0\n",
            "('to', 'computerassisted')  : 0.5\n",
            "('computerassisted', 'language')  : 1.0\n",
            "('language', 'learning')  : 0.5\n",
            "('learning', 'including')  : 1.0\n",
            "('including', 'the')  : 1.0\n",
            "('the', 'history')  : 0.25\n",
            "('history', 'of')  : 1.0\n",
            "('of', 'work')  : 0.25\n",
            "('work', 'in')  : 1.0\n",
            "('in', 'this')  : 1.0\n",
            "('this', 'field')  : 1.0\n",
            "('field', 'over')  : 1.0\n",
            "('over', 'the')  : 1.0\n",
            "('the', 'last')  : 0.25\n",
            "('last', 'thirtyfive')  : 1.0\n",
            "('thirtyfive', 'years')  : 1.0\n",
            "('years', 'but')  : 1.0\n",
            "('but', 'with')  : 1.0\n",
            "('with', 'a')  : 1.0\n",
            "('a', 'focus')  : 1.0\n",
            "('focus', 'on')  : 1.0\n",
            "('on', 'current')  : 1.0\n",
            "('current', 'developments')  : 1.0\n",
            "('developments', 'and')  : 1.0\n",
            "('and', 'opportunities.')  : 1.0\n",
            "('36.1', '\"')  : 1.0\n",
            "('\"', 'Traditional')  : 1.0\n",
            "('Traditional', 'approaches')  : 1.0\n",
            "('approaches', 'tointerpretation')  : 1.0\n",
            "('tointerpretation', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'typically')  : 1.0\n",
            "('typically', 'fall')  : 1.0\n",
            "('fall', 'into')  : 1.0\n",
            "('into', 'one')  : 1.0\n",
            "('one', 'of')  : 1.0\n",
            "('of', 'three')  : 1.0\n",
            "('three', 'classes:')  : 1.0\n",
            "('classes:', 'syntax-driven,')  : 1.0\n",
            "('syntax-driven,', 'semantics-driven,')  : 1.0\n",
            "('semantics-driven,', 'or')  : 1.0\n",
            "('or', 'frame/task')  : 1.0\n",
            "('frame/task', 'based.')  : 1.0\n",
            "('Syntax-driven', 'approaches')  : 1.0\n",
            "('approaches', 'use')  : 1.0\n",
            "('use', 'a')  : 1.0\n",
            "('a', 'domain-independent')  : 0.3333333333333333\n",
            "('domain-independent', 'grammar')  : 1.0\n",
            "('grammar', 'to')  : 1.0\n",
            "('to', 'drive')  : 1.0\n",
            "('drive', 'the')  : 1.0\n",
            "('the', 'interpretation')  : 1.0\n",
            "('interpretation', 'process')  : 1.0\n",
            "('process', 'and')  : 1.0\n",
            "('and', 'produce')  : 0.5\n",
            "('produce', 'a')  : 1.0\n",
            "('a', 'global')  : 0.3333333333333333\n",
            "('global', 'parse')  : 1.0\n",
            "('parse', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Natural')  : 0.5\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'is')  : 1.0\n",
            "('is', 'a')  : 1.0\n",
            "('a', 'very')  : 0.3333333333333333\n",
            "('very', 'large')  : 1.0\n",
            "('large', 'and')  : 1.0\n",
            "('and', 'diverse')  : 0.5\n",
            "('diverse', 'subtopic')  : 1.0\n",
            "('subtopic', 'of')  : 1.0\n",
            "('of', 'artificial')  : 1.0\n",
            "('artificial', 'intelligence.')  : 1.0\n",
            "('As', 'a')  : 1.0\n",
            "('a', 'result,')  : 1.0\n",
            "('result,', 'NLP')  : 1.0\n",
            "('NLP', 'itself')  : 1.0\n",
            "('itself', 'has')  : 1.0\n",
            "('has', 'many')  : 1.0\n",
            "('many', 'subtopics')  : 1.0\n",
            "('subtopics', 'including')  : 1.0\n",
            "('including', 'optical')  : 1.0\n",
            "('optical', 'character')  : 1.0\n",
            "('character', 'recognition,')  : 1.0\n",
            "('recognition,', 'text')  : 1.0\n",
            "('text', 'to')  : 1.0\n",
            "('to', 'speech')  : 0.5\n",
            "('speech', 'translators,')  : 0.5\n",
            "('translators,', 'foreign')  : 1.0\n",
            "('foreign', 'language')  : 1.0\n",
            "('language', 'reading')  : 0.5\n",
            "('reading', 'and')  : 1.0\n",
            "('and', 'writing')  : 0.3333333333333333\n",
            "('writing', 'aids,')  : 1.0\n",
            "('aids,', 'machine')  : 1.0\n",
            "('machine', 'translation,')  : 1.0\n",
            "('translation,', 'and')  : 1.0\n",
            "('and', 'speech')  : 0.3333333333333333\n",
            "('speech', 'recognition')  : 0.5\n",
            "('recognition', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Probabilistic')  : 0.5\n",
            "('Probabilistic', 'finite-state')  : 1.0\n",
            "('finite-state', 'string')  : 1.0\n",
            "('string', 'transducers')  : 1.0\n",
            "('transducers', '(FSTs)')  : 1.0\n",
            "('(FSTs)', 'are')  : 1.0\n",
            "('are', 'extremely')  : 1.0\n",
            "('extremely', 'popular')  : 1.0\n",
            "('popular', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing,')  : 0.5\n",
            "('processing,', 'due')  : 1.0\n",
            "('due', 'to')  : 1.0\n",
            "('to', 'powerful')  : 0.5\n",
            "('powerful', 'generic')  : 1.0\n",
            "('generic', 'methods')  : 1.0\n",
            "('methods', 'for')  : 1.0\n",
            "('for', 'applying,')  : 1.0\n",
            "('applying,', 'composing,')  : 1.0\n",
            "('composing,', 'and')  : 1.0\n",
            "('and', 'learning')  : 0.3333333333333333\n",
            "('learning', 'them.')  : 1.0\n",
            "('Unfortunately,', 'FSTs')  : 1.0\n",
            "('FSTs', 'are')  : 1.0\n",
            "('are', 'not')  : 1.0\n",
            "('not', 'a')  : 1.0\n",
            "('a', 'good')  : 1.0\n",
            "('good', 'fit')  : 1.0\n",
            "('fit', 'for')  : 1.0\n",
            "('for', 'much')  : 0.5\n",
            "('much', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'current')  : 1.0\n",
            "('current', 'work')  : 1.0\n",
            "('work', 'on')  : 1.0\n",
            "('on', 'probabilistic')  : 1.0\n",
            "('probabilistic', 'modeling')  : 1.0\n",
            "('modeling', 'for')  : 1.0\n",
            "('for', 'machine')  : 0.5\n",
            "('machine', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'ABSTRACT.')  : 0.5\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'special')  : 1.0\n",
            "('special', 'issue')  : 1.0\n",
            "('issue', 'of')  : 1.0\n",
            "('of', 'TAL,')  : 1.0\n",
            "('TAL,', 'we')  : 1.0\n",
            "('we', 'look')  : 1.0\n",
            "('look', 'at')  : 1.0\n",
            "('at', 'the')  : 1.0\n",
            "('the', 'fundamental')  : 1.0\n",
            "('fundamental', 'principles')  : 1.0\n",
            "('principles', 'underlying')  : 1.0\n",
            "('underlying', 'evaluation')  : 1.0\n",
            "('evaluation', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('We', 'adopt')  : 1.0\n",
            "('adopt', 'a')  : 1.0\n",
            "('a', 'global')  : 0.3333333333333333\n",
            "('global', 'point')  : 1.0\n",
            "('point', 'of')  : 1.0\n",
            "('of', 'view')  : 0.5\n",
            "('view', 'that')  : 1.0\n",
            "('that', 'goes')  : 1.0\n",
            "('goes', 'beyond')  : 1.0\n",
            "('beyond', 'the')  : 1.0\n",
            "('the', 'horizon')  : 1.0\n",
            "('horizon', 'of')  : 1.0\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'single')  : 0.3333333333333333\n",
            "('single', 'evaluation')  : 1.0\n",
            "('evaluation', 'campaign')  : 1.0\n",
            "('campaign', 'or')  : 1.0\n",
            "('or', 'a')  : 1.0\n",
            "('a', 'particular')  : 0.3333333333333333\n",
            "('particular', 'protocol.')  : 1.0\n",
            "('After', 'a')  : 1.0\n",
            "('a', 'brief')  : 1.0\n",
            "('brief', 'review')  : 1.0\n",
            "('review', 'of')  : 1.0\n",
            "('of', 'history')  : 1.0\n",
            "('history', 'and')  : 1.0\n",
            "('and', 'terminology')  : 0.5\n",
            "('terminology', '\"')  : 1.0\n",
            "('\"', 'Abstract')  : 0.5\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', '\"')  : 1.0\n",
            "('\"', 'Natural')  : 0.5\n",
            "('Natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'systems')  : 1.0\n",
            "('systems', '(NLP)')  : 1.0\n",
            "('(NLP)', 'that')  : 1.0\n",
            "('that', 'extract')  : 1.0\n",
            "('extract', 'clinical')  : 1.0\n",
            "('clinical', 'information')  : 1.0\n",
            "('information', 'from')  : 1.0\n",
            "('from', 'textual')  : 1.0\n",
            "('textual', 'reports')  : 1.0\n",
            "('reports', 'were')  : 1.0\n",
            "('were', 'shown')  : 1.0\n",
            "('shown', 'to')  : 1.0\n",
            "('to', 'be')  : 1.0\n",
            "('be', 'effective')  : 1.0\n",
            "('effective', 'for')  : 1.0\n",
            "('for', 'limited')  : 0.5\n",
            "('limited', 'domains')  : 1.0\n",
            "('domains', 'and')  : 1.0\n",
            "('and', 'for')  : 0.5\n",
            "('for', 'particular')  : 0.5\n",
            "('particular', 'applications.')  : 1.0\n",
            "('Because', 'an')  : 1.0\n",
            "('an', 'NLP')  : 1.0\n",
            "('NLP', 'system')  : 1.0\n",
            "('system', 'typically')  : 1.0\n",
            "('typically', 'requires')  : 1.0\n",
            "('requires', 'substantial')  : 1.0\n",
            "('substantial', 'resources')  : 1.0\n",
            "('resources', 'to')  : 1.0\n",
            "('to', 'develop,')  : 0.5\n",
            "('develop,', 'it')  : 1.0\n",
            "('it', 'is')  : 1.0\n",
            "('is', 'beneficial')  : 0.5\n",
            "('beneficial', 'if')  : 1.0\n",
            "('if', 'it')  : 1.0\n",
            "('is', 'designed')  : 0.5\n",
            "('designed', 'to')  : 1.0\n",
            "('to', 'be')  : 0.5\n",
            "('be', 'easily')  : 1.0\n",
            "('easily', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'facts')  : 0.5\n",
            "('facts', 'forms')  : 1.0\n",
            "('forms', 'a')  : 1.0\n",
            "('a', 'link')  : 0.5\n",
            "('link', 'between')  : 1.0\n",
            "('between', 'IE,')  : 1.0\n",
            "('IE,', 'a')  : 1.0\n",
            "('a', 'recent')  : 0.5\n",
            "('recent', 'development')  : 1.0\n",
            "('development', 'in')  : 1.0\n",
            "('in', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing,')  : 1.0\n",
            "('Processing,', 'and')  : 1.0\n",
            "('and', 'logic')  : 1.0\n",
            "('logic', 'programming')  : 1.0\n",
            "('programming', 'with')  : 1.0\n",
            "('with', 'Prolog.')  : 1.0\n",
            "('1', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.3333333333333333\n",
            "('\"', 'We')  : 0.6666666666666666\n",
            "('We', 'describe')  : 0.5\n",
            "('describe', 'a')  : 1.0\n",
            "('a', 'single')  : 0.25\n",
            "('single', 'convolutional')  : 1.0\n",
            "('convolutional', 'neural')  : 1.0\n",
            "('neural', 'network')  : 1.0\n",
            "('network', 'architecture')  : 1.0\n",
            "('architecture', 'that,')  : 1.0\n",
            "('that,', 'given')  : 1.0\n",
            "('given', 'a')  : 1.0\n",
            "('a', 'sentence,')  : 0.25\n",
            "('sentence,', 'outputs')  : 1.0\n",
            "('outputs', 'a')  : 1.0\n",
            "('a', 'host')  : 0.25\n",
            "('host', 'of')  : 1.0\n",
            "('of', 'language')  : 0.5\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'predictions:')  : 0.5\n",
            "('predictions:', 'part-of-speech')  : 1.0\n",
            "('part-of-speech', 'tags,')  : 1.0\n",
            "('tags,', 'chunks,')  : 0.5\n",
            "('chunks,', 'named')  : 1.0\n",
            "('named', 'entity')  : 1.0\n",
            "('entity', 'tags,')  : 1.0\n",
            "('tags,', 'semantic')  : 0.5\n",
            "('semantic', 'roles,')  : 1.0\n",
            "('roles,', 'semantically')  : 1.0\n",
            "('semantically', 'similar')  : 1.0\n",
            "('similar', 'words')  : 1.0\n",
            "('words', 'and')  : 1.0\n",
            "('and', 'the')  : 1.0\n",
            "('the', 'likelihood')  : 0.3333333333333333\n",
            "('likelihood', 'that')  : 1.0\n",
            "('that', 'the')  : 1.0\n",
            "('the', 'sentence')  : 0.3333333333333333\n",
            "('sentence', 'makes')  : 1.0\n",
            "('makes', 'sense')  : 1.0\n",
            "('sense', '(grammatically')  : 1.0\n",
            "('(grammatically', '\"')  : 1.0\n",
            "('We', 'developed')  : 0.5\n",
            "('developed', 'a')  : 1.0\n",
            "('a', 'prototype')  : 0.25\n",
            "('prototype', 'information')  : 1.0\n",
            "('information', 'retrieval')  : 1.0\n",
            "('retrieval', 'system')  : 1.0\n",
            "('system', 'which')  : 1.0\n",
            "('which', 'uses')  : 1.0\n",
            "('uses', 'advanced')  : 1.0\n",
            "('advanced', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('processing', 'techniques')  : 0.5\n",
            "('techniques', 'to')  : 1.0\n",
            "('to', 'enhance')  : 1.0\n",
            "('enhance', 'the')  : 1.0\n",
            "('the', 'effectiveness')  : 0.3333333333333333\n",
            "('effectiveness', 'of')  : 1.0\n",
            "('of', 'traditional')  : 0.5\n",
            "('traditional', 'key-word')  : 1.0\n",
            "('key-word', 'based')  : 1.0\n",
            "('based', 'document')  : 1.0\n",
            "('document', 'retrieval.')  : 1.0\n",
            "('The', 'backbone')  : 1.0\n",
            "('backbone', 'of')  : 1.0\n",
            "('of', 'our')  : 1.0\n",
            "('our', 'system')  : 1.0\n",
            "('system', 'is')  : 1.0\n",
            "('is', 'a')  : 1.0\n",
            "('a', 'statistical')  : 1.0\n",
            "('statistical', 'retrieval')  : 1.0\n",
            "('retrieval', 'engine')  : 1.0\n",
            "('engine', 'which')  : 1.0\n",
            "('which', 'performs')  : 1.0\n",
            "('performs', 'automated')  : 1.0\n",
            "('automated', 'indexing')  : 1.0\n",
            "('indexing', 'Abstract')  : 1.0\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', 'In')  : 1.0\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'paper')  : 1.0\n",
            "('paper', 'we')  : 1.0\n",
            "('we', 'will')  : 1.0\n",
            "('will', 'discuss')  : 1.0\n",
            "('discuss', 'several')  : 1.0\n",
            "('several', 'issues')  : 1.0\n",
            "('issues', 'and')  : 1.0\n",
            "('and', 'requirements')  : 1.0\n",
            "('requirements', 'for')  : 1.0\n",
            "('for', 'enabling')  : 1.0\n",
            "('enabling', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'systems')  : 1.0\n",
            "('systems', 'to')  : 1.0\n",
            "('to', 'become')  : 1.0\n",
            "('become', 'context-adaptive.')  : 1.0\n",
            "('Given', 'the')  : 1.0\n",
            "('the', 'fact')  : 1.0\n",
            "('fact', 'that')  : 1.0\n",
            "('that', 'emerging')  : 1.0\n",
            "('emerging', 'systems')  : 1.0\n",
            "('systems', 'feature')  : 1.0\n",
            "('feature', 'speaker')  : 1.0\n",
            "('speaker', 'independent')  : 1.0\n",
            "('independent', 'continuous')  : 1.0\n",
            "('continuous', 'speech')  : 1.0\n",
            "('speech', 'recognition')  : 1.0\n",
            "('recognition', 'restricted')  : 1.0\n",
            "('restricted', 'to')  : 1.0\n",
            "('to', 'individual')  : 1.0\n",
            "('individual', 'domains')  : 1.0\n",
            "('domains', 'and')  : 1.0\n",
            "('and', 'are')  : 1.0\n",
            "('are', 'equipped')  : 0.5\n",
            "('equipped', 'with')  : 1.0\n",
            "('with', 'syntactic')  : 1.0\n",
            "('syntactic', '\"')  : 1.0\n",
            "('\"', 'In')  : 0.5\n",
            "('In', 'Fall')  : 1.0\n",
            "('Fall', '2004')  : 1.0\n",
            "('2004', 'I')  : 1.0\n",
            "('I', 'introduced')  : 1.0\n",
            "('introduced', 'a')  : 1.0\n",
            "('a', 'new')  : 1.0\n",
            "('new', 'course')  : 1.0\n",
            "('course', 'called')  : 1.0\n",
            "('called', 'Applied')  : 1.0\n",
            "('Applied', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing,')  : 1.0\n",
            "('Processing,', 'in')  : 1.0\n",
            "('in', 'which')  : 1.0\n",
            "('which', 'students')  : 0.5\n",
            "('students', 'acquire')  : 1.0\n",
            "('acquire', 'an')  : 1.0\n",
            "('an', 'understanding')  : 1.0\n",
            "('understanding', 'of')  : 1.0\n",
            "('of', 'which')  : 1.0\n",
            "('which', 'text')  : 0.5\n",
            "('text', 'analysis')  : 1.0\n",
            "('analysis', 'techniques')  : 1.0\n",
            "('techniques', 'are')  : 1.0\n",
            "('are', 'currently')  : 0.5\n",
            "('currently', 'feasible')  : 1.0\n",
            "('feasible', 'for')  : 1.0\n",
            "('for', 'practical')  : 1.0\n",
            "('practical', 'applications.')  : 1.0\n",
            "('applications.', '\"')  : 1.0\n",
            "('Abstract', 'not')  : 1.0\n",
            "('not', 'found')  : 1.0\n",
            "('found', 'Abstract:')  : 1.0\n",
            "('Abstract:', 'Natural')  : 1.0\n",
            "('Natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'study')  : 0.5\n",
            "('study', 'of')  : 1.0\n",
            "('of', 'mathematical')  : 0.2\n",
            "('mathematical', 'and')  : 1.0\n",
            "('and', 'computational')  : 0.5\n",
            "('computational', 'modelling')  : 1.0\n",
            "('modelling', 'of')  : 1.0\n",
            "('of', 'various')  : 0.2\n",
            "('various', 'aspects')  : 1.0\n",
            "('aspects', 'of')  : 1.0\n",
            "('of', 'language')  : 0.2\n",
            "('language', 'and')  : 0.5\n",
            "('and', 'the')  : 0.5\n",
            "('the', 'improvement')  : 0.5\n",
            "('improvement', 'of')  : 1.0\n",
            "('of', 'a')  : 0.2\n",
            "('a', 'wide')  : 1.0\n",
            "('wide', 'range')  : 1.0\n",
            "('range', 'of')  : 1.0\n",
            "('of', 'systems.')  : 0.2\n",
            "('Natural', 'language')  : 0.5\n",
            "('language', 'is')  : 0.3333333333333333\n",
            "('is', 'any')  : 0.5\n",
            "('any', 'language')  : 1.0\n",
            "('language', 'that')  : 0.3333333333333333\n",
            "('that', 'arises')  : 1.0\n",
            "('arises', 'as')  : 1.0\n",
            "('as', 'an')  : 1.0\n",
            "('an', 'innate')  : 1.0\n",
            "('innate', 'facility')  : 1.0\n",
            "('facility', 'for')  : 1.0\n",
            "('for', 'language')  : 1.0\n",
            "('language', 'possessed')  : 0.3333333333333333\n",
            "('possessed', 'by')  : 1.0\n",
            "('by', 'the')  : 1.0\n",
            "('the', 'human')  : 1.0\n",
            "('human', 'intellect;')  : 1.0\n",
            "('intellect;', 'it')  : 1.0\n",
            "('it', 'may')  : 1.0\n",
            "('may', '\"')  : 1.0\n",
            "('\"', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 0.5\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP),')  : 1.0\n",
            "('(NLP),', 'which')  : 1.0\n",
            "('which', 'is')  : 1.0\n",
            "('is', 'a')  : 0.5\n",
            "('a', 'branch')  : 1.0\n",
            "('branch', 'of')  : 1.0\n",
            "('of', 'artificial')  : 1.0\n",
            "('artificial', 'intelligence,')  : 1.0\n",
            "('intelligence,', 'includes')  : 1.0\n",
            "('includes', 'speech')  : 1.0\n",
            "('speech', 'synthesis,')  : 1.0\n",
            "('synthesis,', 'Speech')  : 1.0\n",
            "('Speech', 'recognition,')  : 1.0\n",
            "('recognition,', 'and')  : 1.0\n",
            "('and', 'Machine')  : 1.0\n",
            "('Machine', 'translation.')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'has')  : 1.0\n",
            "('has', 'a')  : 1.0\n",
            "('a', 'wide')  : 1.0\n",
            "('wide', 'range')  : 1.0\n",
            "('range', 'of')  : 1.0\n",
            "('of', 'applications')  : 1.0\n",
            "('applications', 'in')  : 1.0\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'Indian')  : 1.0\n",
            "('Indian', 'context.')  : 1.0\n",
            "('Most', 'of')  : 1.0\n",
            "('of', 'the')  : 0.25\n",
            "('the', 'rural')  : 0.25\n",
            "('rural', 'Indian')  : 1.0\n",
            "('Indian', 'community')  : 1.0\n",
            "('community', 'is')  : 1.0\n",
            "('is', 'unable')  : 1.0\n",
            "('unable', 'to')  : 1.0\n",
            "('to', 'make')  : 0.5\n",
            "('make', 'use')  : 1.0\n",
            "('use', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'An')  : 0.5\n",
            "('An', 'Evaluation')  : 1.0\n",
            "('Evaluation', 'of')  : 1.0\n",
            "('of', 'LOLITA')  : 0.25\n",
            "('LOLITA', 'and')  : 1.0\n",
            "('and', 'related')  : 1.0\n",
            "('related', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'Systems')  : 1.0\n",
            "('Systems', 'Paul')  : 1.0\n",
            "('Paul', 'Callaghan')  : 1.0\n",
            "('Callaghan', 'Submitted')  : 1.0\n",
            "('Submitted', 'to')  : 1.0\n",
            "('to', 'the')  : 0.5\n",
            "('the', 'University')  : 0.25\n",
            "('University', 'of')  : 1.0\n",
            "('of', 'Durham')  : 0.25\n",
            "('Durham', 'for')  : 1.0\n",
            "('for', 'the')  : 1.0\n",
            "('the', 'degree')  : 0.25\n",
            "('degree', 'of')  : 1.0\n",
            "('of', 'Ph.D.,')  : 0.25\n",
            "('Ph.D.,', 'August')  : 1.0\n",
            "('August', '1997')  : 1.0\n",
            "('1997', '---------------------')  : 1.0\n",
            "('---------------------', 'This')  : 1.0\n",
            "('This', 'research')  : 1.0\n",
            "('research', 'addresses')  : 1.0\n",
            "('addresses', 'the')  : 1.0\n",
            "('the', 'question,')  : 0.25\n",
            "('question,', '\"\"how')  : 1.0\n",
            "('\"\"how', 'do')  : 1.0\n",
            "('do', 'we')  : 1.0\n",
            "('we', 'evaluate')  : 1.0\n",
            "('evaluate', 'systems')  : 1.0\n",
            "('systems', 'like')  : 1.0\n",
            "('like', 'LOLITA?\"\"')  : 1.0\n",
            "('LOLITA', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'Natural')  : 1.0\n",
            "('Natural', '\"')  : 0.5\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Previous')  : 0.5\n",
            "('Previous', 'work')  : 1.0\n",
            "('work', 'demonstrated')  : 1.0\n",
            "('demonstrated', 'that')  : 1.0\n",
            "('that', 'Web')  : 0.5\n",
            "('Web', 'counts')  : 1.0\n",
            "('counts', 'can')  : 1.0\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'used')  : 0.5\n",
            "('used', 'to')  : 1.0\n",
            "('to', 'approximate')  : 1.0\n",
            "('approximate', 'bigram')  : 1.0\n",
            "('bigram', 'counts,')  : 1.0\n",
            "('counts,', 'suggesting')  : 1.0\n",
            "('suggesting', 'that')  : 1.0\n",
            "('that', 'Web-based')  : 0.5\n",
            "('Web-based', 'frequencies')  : 1.0\n",
            "('frequencies', 'should')  : 1.0\n",
            "('should', 'be')  : 1.0\n",
            "('be', 'useful')  : 0.5\n",
            "('useful', 'for')  : 1.0\n",
            "('for', 'a')  : 1.0\n",
            "('a', 'wide')  : 1.0\n",
            "('wide', 'variety')  : 1.0\n",
            "('variety', 'of')  : 1.0\n",
            "('of', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 0.5\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'tasks.')  : 1.0\n",
            "('However,', 'only')  : 1.0\n",
            "('only', 'a')  : 1.0\n",
            "('a', 'limited')  : 0.5\n",
            "('limited', 'number')  : 1.0\n",
            "('number', 'of')  : 1.0\n",
            "('of', 'tasks')  : 0.3333333333333333\n",
            "('tasks', 'have')  : 1.0\n",
            "('have', 'so')  : 1.0\n",
            "('so', 'far')  : 1.0\n",
            "('far', 'been')  : 1.0\n",
            "('been', 'tested')  : 1.0\n",
            "('tested', 'using')  : 1.0\n",
            "('using', 'Web-scale')  : 1.0\n",
            "('Web-scale', 'data')  : 1.0\n",
            "('data', 'sets')  : 1.0\n",
            "('sets', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'chapter')  : 1.0\n",
            "('chapter', 'examines')  : 1.0\n",
            "('examines', 'the')  : 1.0\n",
            "('the', 'application')  : 0.3333333333333333\n",
            "('application', 'of')  : 1.0\n",
            "('of', 'natural')  : 0.3333333333333333\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'to')  : 1.0\n",
            "('to', 'computerassisted')  : 1.0\n",
            "('computerassisted', 'language')  : 1.0\n",
            "('language', 'learning')  : 0.5\n",
            "('learning', 'including')  : 1.0\n",
            "('including', 'the')  : 1.0\n",
            "('the', 'history')  : 0.3333333333333333\n",
            "('history', 'of')  : 1.0\n",
            "('of', 'work')  : 0.3333333333333333\n",
            "('work', 'in')  : 1.0\n",
            "('in', 'this')  : 1.0\n",
            "('this', 'field')  : 1.0\n",
            "('field', 'over')  : 1.0\n",
            "('over', 'the')  : 1.0\n",
            "('the', 'last')  : 0.3333333333333333\n",
            "('last', 'thirtyfive')  : 1.0\n",
            "('thirtyfive', 'years')  : 1.0\n",
            "('years', 'but')  : 1.0\n",
            "('but', 'with')  : 1.0\n",
            "('with', 'a')  : 1.0\n",
            "('a', 'focus')  : 0.5\n",
            "('focus', 'on')  : 1.0\n",
            "('on', 'current')  : 1.0\n",
            "('current', 'developments')  : 1.0\n",
            "('developments', 'and')  : 1.0\n",
            "('and', 'opportunities.')  : 1.0\n",
            "('16.1', 'Introduction')  : 1.0\n",
            "('Introduction', 'This')  : 1.0\n",
            "('This', 'chapter')  : 0.5\n",
            "('chapter', 'focuses')  : 1.0\n",
            "('focuses', 'on')  : 1.0\n",
            "('on', 'applications')  : 1.0\n",
            "('applications', '\"')  : 1.0\n",
            "('\"', 'This')  : 1.0\n",
            "('This', 'paper')  : 0.5\n",
            "('paper', 'describes')  : 1.0\n",
            "('describes', 'a')  : 1.0\n",
            "('a', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'system')  : 1.0\n",
            "('system', 'which')  : 1.0\n",
            "('which', 'improves')  : 1.0\n",
            "('improves', 'its')  : 1.0\n",
            "('its', 'own')  : 1.0\n",
            "('own', 'performance')  : 1.0\n",
            "('performance', 'through')  : 1.0\n",
            "('through', 'learning.')  : 1.0\n",
            "('The', 'system')  : 1.0\n",
            "('system', 'processes')  : 1.0\n",
            "('processes', 'short')  : 1.0\n",
            "('short', 'English')  : 1.0\n",
            "('English', 'narratives')  : 1.0\n",
            "('narratives', 'and')  : 1.0\n",
            "('and', 'is')  : 1.0\n",
            "('is', 'able')  : 1.0\n",
            "('able', 'to')  : 1.0\n",
            "('to', 'acquire,')  : 1.0\n",
            "('acquire,', 'from')  : 1.0\n",
            "('from', 'a')  : 1.0\n",
            "('a', 'single')  : 0.3333333333333333\n",
            "('single', 'narrative,')  : 1.0\n",
            "('narrative,', 'a')  : 1.0\n",
            "('a', 'new')  : 0.3333333333333333\n",
            "('new', 'schema')  : 1.0\n",
            "('schema', 'for')  : 1.0\n",
            "('for', 'a')  : 1.0\n",
            "('a', 'stereotypical')  : 0.3333333333333333\n",
            "('stereotypical', 'set')  : 1.0\n",
            "('set', 'of')  : 1.0\n",
            "('of', 'actions.')  : 1.0\n",
            "('During', 'the')  : 1.0\n",
            "('the', 'understanding')  : 0.5\n",
            "('understanding', 'process,')  : 1.0\n",
            "('process,', 'the')  : 1.0\n",
            "('the', 'system')  : 0.5\n",
            "('system', 'attempts')  : 1.0\n",
            "('attempts', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'classify')  : 1.0\n",
            "('classify', 'and')  : 1.0\n",
            "('and', 'review')  : 0.5\n",
            "('review', 'current')  : 1.0\n",
            "('current', 'approaches')  : 1.0\n",
            "('approaches', 'to')  : 1.0\n",
            "('to', 'software')  : 1.0\n",
            "('software', 'infrastructure')  : 1.0\n",
            "('infrastructure', 'for')  : 1.0\n",
            "('for', 'research,')  : 1.0\n",
            "('research,', 'development')  : 1.0\n",
            "('development', 'and')  : 1.0\n",
            "('and', 'delivery')  : 0.5\n",
            "('delivery', 'of')  : 1.0\n",
            "('of', 'NLP')  : 1.0\n",
            "('NLP', 'systems.')  : 1.0\n",
            "('The', 'task')  : 1.0\n",
            "('task', '\"')  : 1.0\n",
            "('\"', 'Confidence')  : 1.0\n",
            "('Confidence', 'measures')  : 1.0\n",
            "('measures', 'are')  : 1.0\n",
            "('are', 'a')  : 1.0\n",
            "('a', 'practical')  : 1.0\n",
            "('practical', 'solution')  : 1.0\n",
            "('solution', 'for')  : 1.0\n",
            "('for', 'improving')  : 1.0\n",
            "('improving', 'the')  : 1.0\n",
            "('the', 'usefulness')  : 1.0\n",
            "('usefulness', 'of')  : 1.0\n",
            "('of', 'Natural')  : 1.0\n",
            "('Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', 'applications.')  : 1.0\n",
            "('Confidence', 'estimation')  : 1.0\n",
            "('estimation', 'is')  : 1.0\n",
            "('is', 'a')  : 1.0\n",
            "('a', 'generic')  : 1.0\n",
            "('generic', 'machine')  : 1.0\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', 'approach')  : 1.0\n",
            "('approach', 'for')  : 1.0\n",
            "('for', 'deriving')  : 1.0\n",
            "('deriving', 'confidence')  : 1.0\n",
            "('confidence', 'measures.')  : 1.0\n",
            "('We', 'give')  : 1.0\n",
            "('give', 'an')  : 1.0\n",
            "('an', 'overview')  : 1.0\n",
            "('overview', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'application')  : 1.0\n",
            "('application', 'of')  : 1.0\n",
            "('of', 'confidence')  : 0.5\n",
            "('confidence', 'estimation')  : 1.0\n",
            "('estimation', 'in')  : 1.0\n",
            "('in', 'various')  : 1.0\n",
            "('various', 'fields')  : 1.0\n",
            "('fields', '\"')  : 1.0\n",
            "('\"', '!')  : 1.0\n",
            "('lex-sign', 'sense-id')  : 1.0\n",
            "('sense-id', ':')  : 0.5\n",
            "(':', 'sense-id')  : 1.0\n",
            "('sense-id', 'dictionary')  : 0.5\n",
            "('dictionary', '?')  : 1.0\n",
            "('=', '\"\"LDOCE\"\"')  : 1.0\n",
            "('\"\"LDOCE\"\"', '!')  : 1.0\n",
            "('lex-sign', 'sense-id')  : 1.0\n",
            "('sense-id', ':')  : 0.5\n",
            "(':', 'sense-id')  : 1.0\n",
            "('sense-id', 'ldb-entry-no')  : 0.5\n",
            "('ldb-entry-no', '?')  : 1.0\n",
            "('=', '\"\"12364\"\"')  : 1.0\n",
            "('\"\"12364\"\"', '!')  : 1.0\n",
            "('lex-sign', 'sense-id')  : 1.0\n",
            "('sense-id', ':')  : 0.5\n",
            "(':', 'sense-id')  : 1.0\n",
            "('sense-id', 'sense-no')  : 0.5\n",
            "('sense-no', '?')  : 1.0\n",
            "('=', '\"\"0\"\".')  : 1.0\n",
            "('When', 'loaded')  : 1.0\n",
            "('loaded', 'into')  : 1.0\n",
            "('into', 'the')  : 0.5\n",
            "('the', 'LKB,')  : 0.25\n",
            "('LKB,', '(9)')  : 1.0\n",
            "('(9)', 'will')  : 0.5\n",
            "('will', 'be')  : 1.0\n",
            "('be', 'expanded')  : 1.0\n",
            "('expanded', 'into')  : 1.0\n",
            "('into', 'a')  : 0.5\n",
            "('a', 'fully-fledged')  : 1.0\n",
            "('fully-fledged', 'representation')  : 1.0\n",
            "('representation', 'for')  : 1.0\n",
            "('for', 'the')  : 1.0\n",
            "('the', 'transitive')  : 0.25\n",
            "('transitive', 'use')  : 1.0\n",
            "('use', 'of')  : 1.0\n",
            "('of', 'experience;')  : 1.0\n",
            "('experience;', 'by')  : 1.0\n",
            "('by', 'integrating')  : 0.3333333333333333\n",
            "('integrating', 'word-specific')  : 1.0\n",
            "('word-specific', 'information')  : 1.0\n",
            "('information', 'provided')  : 0.5\n",
            "('provided', 'by')  : 1.0\n",
            "('by', '(9)')  : 0.3333333333333333\n",
            "('(9)', 'with')  : 0.5\n",
            "('with', 'the')  : 1.0\n",
            "('the', 'information')  : 0.25\n",
            "('information', 'encoded')  : 0.5\n",
            "('encoded', 'by')  : 1.0\n",
            "('by', 'the')  : 0.3333333333333333\n",
            "('the', 'LKB')  : 0.25\n",
            "('LKB', 'type')  : 1.0\n",
            "('type', 'strict-trans-sign.')  : 1.0\n",
            "('Thus,', 'although')  : 1.0\n",
            "('although', 'neither')  : 1.0\n",
            "('neither', 'LDOCE,')  : 1.0\n",
            "('LDOCE,', 'LLCE')  : 1.0\n",
            "('LLCE', 'or')  : 1.0\n",
            "('or', 'the')  : 1.0\n",
            "('the', 'earlier')  : 0.25\n",
            "('earlier', 'subcategorised')  : 1.0\n",
            "('subcategorised', 'lexicon')  : 1.0\n",
            "('lexicon', 'contain')  : 1.0\n",
            "('contain', 'all')  : 1.0\n",
            "('all', 'the')  : 0.5\n",
            "('the', 'information')  : 0.25\n",
            "('information', 'about')  : 0.3333333333333333\n",
            "('about', 'psychological')  : 1.0\n",
            "('psychological', 'verbs')  : 1.0\n",
            "('verbs', 'defined')  : 1.0\n",
            "('defined', 'in')  : 1.0\n",
            "('in', 'Sanfilippo&aposs')  : 1.0\n",
            "('Sanfilippo&aposs', 'type')  : 1.0\n",
            "('type', 'system,')  : 1.0\n",
            "('system,', 'by')  : 1.0\n",
            "('by', 'using')  : 1.0\n",
            "('using', 'the')  : 1.0\n",
            "('the', 'conjunction')  : 0.25\n",
            "('conjunction', 'of')  : 1.0\n",
            "('of', 'information')  : 1.0\n",
            "('information', 'available')  : 0.3333333333333333\n",
            "('available', 'from')  : 1.0\n",
            "('from', 'all')  : 1.0\n",
            "('all', 'three,')  : 0.5\n",
            "('three,', 'it')  : 1.0\n",
            "('it', 'proved')  : 0.5\n",
            "('proved', 'possible')  : 1.0\n",
            "('possible', 'to')  : 1.0\n",
            "('to', 'effectively')  : 1.0\n",
            "('effectively', 'enrich')  : 1.0\n",
            "('enrich', 'this')  : 1.0\n",
            "('this', 'information')  : 1.0\n",
            "('information', 'at')  : 0.3333333333333333\n",
            "('at', 'the')  : 1.0\n",
            "('the', 'same')  : 0.25\n",
            "('same', 'time')  : 1.0\n",
            "('time', 'as')  : 1.0\n",
            "('as', 'mapping')  : 1.0\n",
            "('mapping', 'it')  : 1.0\n",
            "('it', 'into')  : 0.5\n",
            "('into', 'a')  : 1.0\n",
            "('a', 'formal')  : 1.0\n",
            "('formal', 'representation.')  : 1.0\n",
            "('4.2.5', 'Towards')  : 1.0\n",
            "('Towards', 'a')  : 1.0\n",
            "('a', 'Multilingual')  : 1.0\n",
            "('Multilingual', 'LKB')  : 1.0\n",
            "('LKB', 'A')  : 0.5\n",
            "('A', 'goal')  : 1.0\n",
            "('goal', 'of')  : 1.0\n",
            "('of', 'ACQUILEX')  : 1.0\n",
            "('ACQUILEX', 'is')  : 1.0\n",
            "('is', 'to')  : 1.0\n",
            "('to', 'demonstrate')  : 1.0\n",
            "('demonstrate', 'that')  : 1.0\n",
            "('that', 'an')  : 0.5\n",
            "('an', 'LKB')  : 1.0\n",
            "('LKB', 'can')  : 0.5\n",
            "('can', 'be')  : 1.0\n",
            "('be', 'produced')  : 1.0\n",
            "('produced', 'that')  : 1.0\n",
            "('that', 'usefully')  : 0.5\n",
            "('usefully', 'exploits')  : 1.0\n",
            "('exploits', 'various')  : 1.0\n",
            "('various', 'MRD')  : 1.0\n",
            "('MRD', 'sources')  : 1.0\n",
            "('sources', 'and')  : 1.0\n",
            "('and', 'integrates')  : 1.0\n",
            "('integrates', 'multilingual')  : 1.0\n",
            "('multilingual', 'information.')  : 1.0\n",
            "('The', 'use')  : 1.0\n",
            "('use', 'of')  : 1.0\n",
            "('of', 'a')  : 0.5\n",
            "('a', 'common')  : 1.0\n",
            "('common', 'LRL')  : 0.5\n",
            "('LRL', 'with')  : 1.0\n",
            "('with', 'a')  : 1.0\n",
            "('common', 'type')  : 0.5\n",
            "('type', 'system,')  : 1.0\n",
            "('system,', 'makes')  : 1.0\n",
            "('makes', 'it')  : 1.0\n",
            "('it', 'possi...')  : 1.0\n",
            "('possi...', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'describe')  : 1.0\n",
            "('describe', 'the')  : 1.0\n",
            "('the', 'design')  : 0.5\n",
            "('design', 'and')  : 1.0\n",
            "('and', 'use')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'Stanford')  : 0.5\n",
            "('Stanford', 'CoreNLP')  : 1.0\n",
            "('CoreNLP', 'toolkit,')  : 1.0\n",
            "('toolkit,', 'an')  : 1.0\n",
            "('an', 'extensible')  : 1.0\n",
            "('extensible', 'pipeline')  : 1.0\n",
            "('pipeline', 'that')  : 1.0\n",
            "('that', 'provides')  : 1.0\n",
            "('provides', 'core')  : 1.0\n",
            "('core', 'natural')  : 1.0\n",
            "('natural', 'lan-guage')  : 1.0\n",
            "('lan-guage', 'analysis.')  : 1.0\n",
            "('This', 'toolkit')  : 1.0\n",
            "('toolkit', 'is')  : 1.0\n",
            "('is', 'quite')  : 1.0\n",
            "('quite', 'widely')  : 1.0\n",
            "('widely', 'used,')  : 1.0\n",
            "('used,', 'both')  : 1.0\n",
            "('both', 'in')  : 1.0\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'research')  : 1.0\n",
            "('research', 'NLP')  : 1.0\n",
            "('NLP', 'community')  : 0.5\n",
            "('community', 'and')  : 1.0\n",
            "('and', 'also')  : 0.5\n",
            "('also', 'among')  : 1.0\n",
            "('among', 'commercial')  : 1.0\n",
            "('commercial', 'and')  : 1.0\n",
            "('and', 'govern-ment')  : 0.5\n",
            "('govern-ment', 'users')  : 1.0\n",
            "('users', 'of')  : 1.0\n",
            "('of', 'open')  : 1.0\n",
            "('open', 'source')  : 1.0\n",
            "('source', 'NLP')  : 1.0\n",
            "('NLP', 'technol-ogy.')  : 0.5\n",
            "('We', 'suggest')  : 1.0\n",
            "('suggest', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.3333333333333333\n",
            "('\"', 'Gaussian')  : 0.3333333333333333\n",
            "('Gaussian', 'Processes')  : 1.0\n",
            "('Processes', '(GPs)')  : 1.0\n",
            "('(GPs)', 'are')  : 1.0\n",
            "('are', 'a')  : 0.5\n",
            "('a', 'powerful')  : 1.0\n",
            "('powerful', 'mod-elling')  : 1.0\n",
            "('mod-elling', 'framework')  : 1.0\n",
            "('framework', 'incorporating')  : 1.0\n",
            "('incorporating', 'kernels')  : 1.0\n",
            "('kernels', 'and')  : 1.0\n",
            "('and', 'Bayesian')  : 0.5\n",
            "('Bayesian', 'inference,')  : 1.0\n",
            "('inference,', 'and')  : 1.0\n",
            "('and', 'are')  : 0.5\n",
            "('are', 'recognised')  : 0.5\n",
            "('recognised', 'as')  : 1.0\n",
            "('as', 'state-of-the-art')  : 1.0\n",
            "('state-of-the-art', 'for')  : 1.0\n",
            "('for', 'many')  : 1.0\n",
            "('many', 'machine')  : 1.0\n",
            "('machine', 'learning')  : 1.0\n",
            "('learning', 'tasks.')  : 1.0\n",
            "('tasks.', '\"')  : 1.0\n",
            "(':', 'A')  : 1.0\n",
            "('A', 'fundamental')  : 1.0\n",
            "('fundamental', 'issue')  : 1.0\n",
            "('issue', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 0.5\n",
            "('processing', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'prerequisite')  : 0.3333333333333333\n",
            "('prerequisite', 'of')  : 1.0\n",
            "('of', 'an')  : 0.5\n",
            "('an', 'enormous')  : 1.0\n",
            "('enormous', 'quantity')  : 1.0\n",
            "('quantity', 'of')  : 1.0\n",
            "('of', 'preprogrammed')  : 0.5\n",
            "('preprogrammed', 'knowledge')  : 1.0\n",
            "('knowledge', 'concerning')  : 1.0\n",
            "('concerning', 'both')  : 1.0\n",
            "('both', 'the')  : 1.0\n",
            "('the', 'language')  : 0.3333333333333333\n",
            "('language', 'and')  : 0.5\n",
            "('and', 'the')  : 1.0\n",
            "('the', 'domain')  : 0.3333333333333333\n",
            "('domain', 'under')  : 1.0\n",
            "('under', 'examination.')  : 1.0\n",
            "('Manual', 'acquisition')  : 1.0\n",
            "('acquisition', 'of')  : 1.0\n",
            "('of', 'this')  : 1.0\n",
            "('this', 'knowledge')  : 1.0\n",
            "('knowledge', 'is')  : 1.0\n",
            "('is', 'tedious')  : 1.0\n",
            "('tedious', 'and')  : 1.0\n",
            "('and', 'error')  : 1.0\n",
            "('error', 'prone.')  : 1.0\n",
            "('Development', 'of')  : 1.0\n",
            "('of', 'an')  : 1.0\n",
            "('an', 'automated')  : 1.0\n",
            "('automated', 'acquisition')  : 1.0\n",
            "('acquisition', '\"')  : 1.0\n",
            "('\"', '\"\"')  : 1.0\n",
            "('\"\"', 'that')  : 1.0\n",
            "('that', 'supports')  : 1.0\n",
            "('supports', 'sophisticated')  : 1.0\n",
            "('sophisticated', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'while')  : 1.0\n",
            "('while', 'significantly')  : 1.0\n",
            "('significantly', 'simplifying')  : 1.0\n",
            "('simplifying', 'the')  : 1.0\n",
            "('the', 'interface')  : 1.0\n",
            "('interface', 'between')  : 1.0\n",
            "('between', 'domain-specific')  : 1.0\n",
            "('domain-specific', 'knowledge')  : 1.0\n",
            "('knowledge', 'and')  : 1.0\n",
            "('and', 'general')  : 1.0\n",
            "('general', 'linguis-')  : 1.0\n",
            "('linguis-', 'tic')  : 1.0\n",
            "('tic', 'resources.')  : 1.0\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'presents')  : 1.0\n",
            "('presents', 'the')  : 1.0\n",
            "('the', 'results')  : 0.25\n",
            "('results', 'of')  : 1.0\n",
            "('of', 'our')  : 0.5\n",
            "('our', 'experiences')  : 1.0\n",
            "('experiences', 'in')  : 1.0\n",
            "('in', 'designing')  : 0.5\n",
            "('designing', 'and')  : 1.0\n",
            "('and', 'using')  : 1.0\n",
            "('using', 'the')  : 1.0\n",
            "('the', 'upper')  : 0.25\n",
            "('upper', 'model')  : 1.0\n",
            "('model', 'in')  : 1.0\n",
            "('in', 'a')  : 0.5\n",
            "('a', 'variety')  : 1.0\n",
            "('variety', 'of')  : 1.0\n",
            "('of', 'applications')  : 0.5\n",
            "('applications', 'over')  : 1.0\n",
            "('over', 'the')  : 1.0\n",
            "('the', 'past')  : 0.25\n",
            "('past', '5')  : 1.0\n",
            "('5', 'years')  : 1.0\n",
            "('years', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'into')  : 0.5\n",
            "('into', 'the')  : 1.0\n",
            "('the', 'same')  : 0.25\n",
            "('same', 'or')  : 1.0\n",
            "('or', 'neighboring')  : 1.0\n",
            "('neighboring', 'map')  : 1.0\n",
            "('map', 'nodes.')  : 1.0\n",
            "('Nodes', 'may')  : 1.0\n",
            "('may', 'thus')  : 1.0\n",
            "('thus', 'be')  : 1.0\n",
            "('be', 'viewed')  : 1.0\n",
            "('viewed', 'as')  : 1.0\n",
            "('as', 'word')  : 1.0\n",
            "('word', 'categories.')  : 1.0\n",
            "('Although', 'no')  : 1.0\n",
            "('no', 'a')  : 1.0\n",
            "('a', 'priori')  : 0.5\n",
            "('priori', 'information')  : 1.0\n",
            "('information', 'about')  : 1.0\n",
            "('about', 'classes')  : 1.0\n",
            "('classes', 'is')  : 0.5\n",
            "('is', 'given,')  : 1.0\n",
            "('given,', 'during')  : 1.0\n",
            "('during', 'the')  : 1.0\n",
            "('the', 'self-organizing')  : 0.5\n",
            "('self-organizing', 'process')  : 1.0\n",
            "('process', 'a')  : 1.0\n",
            "('a', 'model')  : 0.5\n",
            "('model', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'word')  : 0.5\n",
            "('word', 'classes')  : 1.0\n",
            "('classes', 'emerges.')  : 0.5\n",
            "('The', 'central')  : 1.0\n",
            "('central', 'topic')  : 1.0\n",
            "('topic', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'thesis')  : 0.3333333333333333\n",
            "('thesis', 'is')  : 1.0\n",
            "('is', 'the')  : 1.0\n",
            "('the', 'use')  : 0.3333333333333333\n",
            "('use', 'of')  : 1.0\n",
            "('the', 'SOM')  : 0.3333333333333333\n",
            "('SOM', 'in')  : 1.0\n",
            "('in', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('The', 'approach')  : 1.0\n",
            "('approach', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'This')  : 0.5\n",
            "('This', 'paper')  : 1.0\n",
            "('paper', 'presents')  : 1.0\n",
            "('presents', 'a')  : 1.0\n",
            "('a', 'workbench')  : 1.0\n",
            "('workbench', 'built')  : 1.0\n",
            "('built', 'by')  : 1.0\n",
            "('by', 'Priberam')  : 1.0\n",
            "('Priberam', 'Informática')  : 1.0\n",
            "('Informática', 'for')  : 1.0\n",
            "('for', 'the')  : 1.0\n",
            "('the', 'development')  : 0.5\n",
            "('development', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'company’s')  : 0.5\n",
            "('company’s', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', 'technology.')  : 1.0\n",
            "('This', 'workbench')  : 1.0\n",
            "('workbench', 'includes')  : 1.0\n",
            "('includes', 'a')  : 1.0\n",
            "('a', 'set')  : 0.5\n",
            "('set', 'of')  : 1.0\n",
            "('of', 'linguistic')  : 0.5\n",
            "('linguistic', 'resources')  : 1.0\n",
            "('resources', 'and')  : 1.0\n",
            "('and', 'software')  : 1.0\n",
            "('software', 'tools')  : 1.0\n",
            "('tools', 'that')  : 1.0\n",
            "('that', 'have')  : 1.0\n",
            "('have', 'been')  : 1.0\n",
            "('been', 'applied')  : 1.0\n",
            "('applied', 'in')  : 1.0\n",
            "('in', 'a')  : 0.5\n",
            "('a', 'considerable')  : 0.5\n",
            "('considerable', 'number')  : 1.0\n",
            "('number', 'of')  : 1.0\n",
            "('of', 'practical')  : 0.5\n",
            "('practical', 'purposes,')  : 1.0\n",
            "('purposes,', 'covering')  : 1.0\n",
            "('covering', '\"')  : 1.0\n",
            "('\"', 'Abstract—Natural')  : 1.0\n",
            "('Abstract—Natural', 'Language')  : 1.0\n",
            "('Language', 'Processing')  : 1.0\n",
            "('Processing', '(NLP)')  : 1.0\n",
            "('(NLP)', 'is')  : 1.0\n",
            "('is', 'an')  : 1.0\n",
            "('an', 'effective')  : 1.0\n",
            "('effective', 'approach')  : 1.0\n",
            "('approach', 'for')  : 1.0\n",
            "('for', 'bringing')  : 1.0\n",
            "('bringing', 'improvement')  : 1.0\n",
            "('improvement', 'in')  : 1.0\n",
            "('in', 'educational')  : 0.5\n",
            "('educational', 'setting.')  : 1.0\n",
            "('Implementing', 'NLP')  : 1.0\n",
            "('NLP', 'involves')  : 1.0\n",
            "('involves', 'initiating')  : 1.0\n",
            "('initiating', 'the')  : 1.0\n",
            "('the', 'process')  : 0.3333333333333333\n",
            "('process', 'of')  : 1.0\n",
            "('of', 'learning')  : 1.0\n",
            "('learning', 'through')  : 1.0\n",
            "('through', 'the')  : 1.0\n",
            "('the', 'natural')  : 0.3333333333333333\n",
            "('natural', 'acquisition')  : 1.0\n",
            "('acquisition', 'in')  : 1.0\n",
            "('in', 'the')  : 1.0\n",
            "('the', 'educational')  : 0.3333333333333333\n",
            "('educational', 'systems.')  : 1.0\n",
            "('It', 'is')  : 1.0\n",
            "('is', 'based')  : 1.0\n",
            "('based', 'on')  : 1.0\n",
            "('on', 'effective')  : 1.0\n",
            "('effective', 'approaches')  : 1.0\n",
            "('approaches', 'for')  : 1.0\n",
            "('for', 'providing')  : 1.0\n",
            "('providing', 'a')  : 1.0\n",
            "('a', 'solution')  : 0.5\n",
            "('solution', '\"')  : 1.0\n",
            "('\"', 'ABSTRACT:')  : 1.0\n",
            "('ABSTRACT:', 'After')  : 1.0\n",
            "('After', 'twenty')  : 1.0\n",
            "('twenty', 'years')  : 1.0\n",
            "('years', 'of')  : 1.0\n",
            "('of', 'disfavor,')  : 0.5\n",
            "('disfavor,', 'a')  : 1.0\n",
            "('a', 'technology')  : 0.5\n",
            "('technology', 'has')  : 1.0\n",
            "('has', 'returned')  : 1.0\n",
            "('returned', 'which')  : 1.0\n",
            "('which', 'imitates')  : 1.0\n",
            "('imitates', 'the')  : 1.0\n",
            "('the', 'processes')  : 0.5\n",
            "('processes', 'of')  : 1.0\n",
            "('of', 'the')  : 0.5\n",
            "('the', 'brain.')  : 0.5\n",
            "('Natural', 'language')  : 1.0\n",
            "('language', 'experiments')  : 1.0\n",
            "('experiments', '(Sejnowski')  : 1.0\n",
            "('(Sejnowski', '&')  : 1.0\n",
            "('&', 'Rosenberg:')  : 1.0\n",
            "('Rosenberg:', '1986)')  : 1.0\n",
            "('1986)', 'demonstrate')  : 1.0\n",
            "('demonstrate', 'that')  : 1.0\n",
            "('that', 'neural')  : 1.0\n",
            "('neural', 'network')  : 1.0\n",
            "('network', 'computing')  : 1.0\n",
            "('computing', 'architecture')  : 1.0\n",
            "('architecture', 'can')  : 1.0\n",
            "('can', 'learn')  : 1.0\n",
            "('learn', 'from')  : 1.0\n",
            "('from', 'actual')  : 1.0\n",
            "('actual', 'spoken')  : 1.0\n",
            "('spoken', 'language,')  : 1.0\n",
            "('language,', 'observe')  : 1.0\n",
            "('observe', 'rules')  : 1.0\n",
            "('rules', 'of')  : 1.0\n",
            "('of', 'pronunciation')  : 1.0\n",
            "('pronunciation', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'Text')  : 0.5\n",
            "('Text', 'statistics')  : 1.0\n",
            "('statistics', 'are')  : 1.0\n",
            "('are', 'frequently')  : 1.0\n",
            "('frequently', 'used')  : 1.0\n",
            "('used', 'in')  : 1.0\n",
            "('in', 'stylometry')  : 1.0\n",
            "('stylometry', 'and')  : 1.0\n",
            "('and', 'cryptography')  : 1.0\n",
            "('cryptography', 'studies.')  : 1.0\n",
            "('In', 'this')  : 1.0\n",
            "('this', 'paper,')  : 1.0\n",
            "('paper,', 'some')  : 1.0\n",
            "('some', 'text')  : 1.0\n",
            "('text', 'statistics')  : 1.0\n",
            "('statistics', 'tools')  : 1.0\n",
            "('tools', 'are')  : 1.0\n",
            "('are', 'developed')  : 1.0\n",
            "('developed', 'in')  : 1.0\n",
            "('in', 'ISO')  : 1.0\n",
            "('ISO', 'Prolog')  : 1.0\n",
            "('Prolog', 'for')  : 1.0\n",
            "('for', 'natural')  : 1.0\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing.')  : 1.0\n",
            "('Details', 'are')  : 1.0\n",
            "('are', 'given')  : 1.0\n",
            "('given', 'on')  : 1.0\n",
            "('on', 'the')  : 1.0\n",
            "('the', 'usage')  : 1.0\n",
            "('usage', 'of')  : 1.0\n",
            "('of', '21')  : 1.0\n",
            "('21', 'user-callable')  : 1.0\n",
            "('user-callable', 'predicates.')  : 1.0\n",
            "('Logic', 'and')  : 1.0\n",
            "('and', 'limitations')  : 1.0\n",
            "('limitations', 'of')  : 1.0\n",
            "('of', 'the')  : 1.0\n",
            "('the', 'program')  : 1.0\n",
            "('program', 'are')  : 1.0\n",
            "('are', 'also')  : 1.0\n",
            "('also', 'discussed')  : 1.0\n",
            "('discussed', '\"')  : 1.0\n",
            "('\"', '\"')  : 0.5\n",
            "('\"', 'We')  : 0.5\n",
            "('We', 'summarize')  : 1.0\n",
            "('summarize', 'our')  : 1.0\n",
            "('our', 'experience')  : 1.0\n",
            "('experience', 'using')  : 1.0\n",
            "('using', 'FrameNet')  : 1.0\n",
            "('FrameNet', 'in')  : 1.0\n",
            "('in', 'two')  : 0.5\n",
            "('two', 'rather')  : 1.0\n",
            "('rather', 'different')  : 1.0\n",
            "('different', 'projects')  : 1.0\n",
            "('projects', 'in')  : 1.0\n",
            "('in', 'natural')  : 0.5\n",
            "('natural', 'language')  : 1.0\n",
            "('language', 'processing')  : 1.0\n",
            "('processing', '(NLP).')  : 1.0\n",
            "('We', 'conclude')  : 1.0\n",
            "('conclude', 'that')  : 1.0\n",
            "('that', 'NLP')  : 0.5\n",
            "('NLP', 'can')  : 1.0\n",
            "('can', 'benefit')  : 1.0\n",
            "('benefit', 'from')  : 1.0\n",
            "('from', 'FrameNet')  : 1.0\n",
            "('FrameNet', 'in')  : 1.0\n",
            "('in', 'different')  : 1.0\n",
            "('different', 'ways,')  : 1.0\n",
            "('ways,', 'but')  : 1.0\n",
            "('but', 'we')  : 1.0\n",
            "('we', 'sketch')  : 1.0\n",
            "('sketch', 'some')  : 1.0\n",
            "('some', 'problems')  : 1.0\n",
            "('problems', 'that')  : 1.0\n",
            "('that', 'need')  : 0.5\n",
            "('need', 'to')  : 1.0\n",
            "('to', 'be')  : 1.0\n",
            "('be', 'overcome.')  : 1.0\n",
            "('1', '\"')  : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "2J20rXSpHIbQ",
        "outputId": "cb71bb17-c1c7-49d8-d3f9-16f27da91907"
      },
      "source": [
        "#NOUN FREQUENCIES \r\n",
        "import spacy\r\n",
        "Ndata = spacy.load(\"en\")\r\n",
        "filename = open(\"Abstract1.csv\",\"r\")\r\n",
        "File = Ndata(filename.read())\r\n",
        "\r\n",
        "\r\n",
        "n = []\r\n",
        "\r\n",
        "for i in File.noun_chunks:\r\n",
        "  n.append(i.text)\r\n",
        "df = pd.DataFrame(n, columns=['NOUNPHRASES'])\r\n",
        "word_vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='word')\r\n",
        "sparse_matrix = word_vectorizer.fit_transform(df['NOUNPHRASES'].values.astype('U'))\r\n",
        "frequency = sum(sparse_matrix).toarray()[0]\r\n",
        "df1 = pd.DataFrame(frequency, index=word_vectorizer.get_feature_names(),columns=['Frequency'])\r\n",
        "df1['NounProbabilities'] = df1/df1.max()\r\n",
        "print(n)\r\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abstract\\n                     Abstract', 'a method', 'statistical modeling', 'maximum entropy', 'We', 'a maximum-likelihood approach', 'maximum entropy models', 'this approach', 'examples', 'several problems', 'natural language processing', 'conditional random fields', 'natural language processing Terms', 'Conditions', 'Terms', 'Conditions', 'Copyright', 'works', 'Minerva Access', 'The paper', 'the issue', 'cooperation', 'linguistics', 'natural language processing', 'NLP', 'linguistics', 'machine translation', '(MT', 'It', 'just one direction', 'such cooperation', 'namely applications', 'linguistics', 'NLP', 'most natural language processing applications', 'Description Logics', 'a knowledge base', 'some syntactic, semantic, and pragmatic elements', 'the semantic interpretation', 'the natural language generation', 'Description Logics', 'We', 'a unified neural network architecture', 'learning algorithm', 'various natural language processing tasks', 'speech', 'semantic role labeling', 'This versatility', 'task', 'The subject', 'Natural Language Processing', 'both broad and narrow senses', 'the broad sense', 'it', 'processing issues', 'all levels', 'natural language understanding', 'speech recognition', 'syntactic and semantic analysis', 'sentences                   \"\\n                     Robots', 'humans', 'face', 'natural language', 'the way', 'humans', 'language', 'those situations', 'We', 'a psychologicallyinspired natural language processing system', 'robots', 'incremental semantic interpretation', 'spoken utterances', 'Natural languages', 'languages', 'humans', 'we', 'the point', 'these languages', 'their unprocessed forms', 'computers', 'Natural language processing', 'the collection', 'techniques', 'that goal', 'The field', 'natural \\n\"                      ABSTRACT', 'Ambiguity', 'the ability', 'more than one meaning', 'more than one way', 'Natural languages', 'computers', 'language', 'people', 'Natural Language Processing', 'NLP', 'the development                   \"\\n                     Introduction  Statistical natural language processing', 'SNLP', 'a field', 'the intersection', 'natural language processing', 'machine learning', 'SNLP di#ers', 'traditional natural language processing', 'some model', '\"                      text', 'e.g. titles', 'abstracts', 'appropriate approaches', 'a focus', 'the role', 'natural language processing', 'The paper', 'possible connections', 'data and knowledge retrieval', 'the importance', '\"                     ABSTRACT', 'Language', 'way', 'your words', 'Language', 'the world', 'we', 'a better insight', 'the world', 'Language', 'speakers', 'they', 'NLP', 'natural language processing', 'Natural languages', 'those languages', 'We', 'experiments', 'the use', 'standard natural language processing (NLP) tools', 'the analysis', 'music lyrics', 'A significant amount', 'music audio', 'lyrics', 'Lyrics', 'an important part', 'the semantics', 'a song', 'their analysis', 'acoustic and cultural                   \"\\n\"                     this paper', 'we', 'a simple rule-based approach', 'automated learning', 'linguistic knowledge', 'This approach', 'a number', 'tasks', 'information', 'a clearer and more direct fashion', 'a compromise', 'performance', 'We', 'a detailed case study', 'this learning method', 'part', 'speech', 'This paper', 'connectionist models', 'natural language processing', 'We', 'several aspects', 'high level tasks', 'connectionism', 'localist or parallel distributed processing models', 'Several interesting architectures                   \"\\n process', 'language understanding', 'a new approach', 'natural language processing', 'the deterministic chaotic behavior', 'dynamical systems', 'a theoretical discussion', '[Kass', '[Leake', 'Owens', 'brief discussions', 'a program', 'the goal', 'our interest', 'natural language processing', 'us', '\"\\n                     Objectives', 'an overview', 'tutorial', 'natural language processing', 'NLP', 'modern NLP-system design', 'Target audience', 'This tutorial', 'the medical informatics generalist', 'who', 'acquaintance', 'the principles', 'NLP', 'the current state', 'This paper', 'the current implementation status', 'an intelligent information retrieval system', 'MARIE', 'natural language processing techniques', 'Descriptive captions', 'photographic images', 'various military projects', 'The captions', '\"\\n                      based and literature resources', 'We', 'a system', 'agent directed natural language processing', 'information', 'journal articles', 'An interface', 'curation', 'the NLP results', 'deposition', 'accepted results', 'a knowledge base', 'Motivation', 'The advent', 'speech processing', 'Part 2 surveys significant evaluation work', 'instance', 'machine translation', 'the particular problems', 'generic system evaluation', 'The conclusion', 'evaluation strategies', 'techniques', 'NLP', 'much more development', 'the way', 'humans', 'order', 'noisy content', 'this paper', 'we', 'a combination', 'HTML DOM analysis', 'Natural Language Processing (NLP) techniques', 'automated extractions', 'main article', 'associated images', 'web pages', 'Abstract-- Natural Language Processing', 'a theoretically motivated range', 'computational techniques', 'texts', 'one or more levels', 'linguistic analysis', 'the purpose', 'human-like language processing', 'a range', 'tasks', 'This paper', 'the processes', 'Natural Language Processing', 'NLP', 'It', 'the various kinds', 'choices', 'the execution', 'the word morphology', 'the syntactic text analysis', 'text generation components', 'It', 'the time', 'This article', 'the derivation', 'large lexicons', 'natural language processing', 'We', 'the  development', 'a dictionary support environment', 'a restructured version', 'the Longman  Dictionary', 'Contemporary English', 'natural language processing systems', 'The process', 'We', 'a method', 'the complexity', 'natural language processing tasks', 'the difficulty', 'new NLP tasks', 'Our complexity measures', 'the Kolmogorov complexity', 'a class', 'automata', 'automata', 'whose purpose', 'relevant pieces', 'text', 'motion', 'The techniques', 'deep learning research', 'the research', 'natural language process', 'This paper', 'the recent research', 'deep learning', 'its applications', 'recent development', 'natural language processing', 'an author-produced version', 'a paper', 'Abstract', 'Natural language processing', 'NLP', 'the application', 'automated parsing and machine learning techniques', 'standard text', 'Applications', 'NLP', 'extraction', 'ontologies', 'a requirements specification', 'use', 'NLP', 'the consistency', 'statistical  baseline', 'the forgiving nature', 'broad coverage', 'the  typical retrieval task', 'the lack', 'good weighting schemes', 'compound  index terms', 'the statistical  methods', 'Natural language processing techniques', 'Work', 'computational linguistics', 'the development', 'the first computers', 'Booth', 'Brandwood', 'Cleave', 'the intervening four decades', 'a pervasive feeling', 'progress', 'computer understanding', 'natural language', 'the voice recognition', 'a natural language', 'Tamil', 'the digital and mathematical knowledge', 'MFCC', 'DTW', 'the features', 'the accuracy', 'better performance', 'Abstract', 'natural language requirements', 'the standard approach', 'system', 'acceptance testing', 'This test', 'an independent test organization', 'the application area', 'The only things', 'the testers', 'the written requirements', 'Abstract', 'conversational partners', 'it', 'us', 'information', 'associations', 'storytelling', 'language use', 'Many more subtleties', 'face', 'humor', 'a face threatening act', 'Abstract', 'recent years', 'machine learning', 'ML', 'complex tasks', 'different disciplines', 'Data Mining', 'Information', 'We', 'manual and automatic thesauruses', 'alternative resources', 'the same NLP tasks', 'the radical step', 'manual thesauruses', 'classifications', 'words', 'word senses', 'the case', 'The range', 'roles', 'thesauruses', 'NLP', 'the WASPS thesaurus', 'Thesaurus evaluation', 'A range', 'evaluation strategies', 'NLP tasks', 'Introduction  Patterns', 'music', 'the object', 'intensive studies', 'the past years', 'the purposes', 'musical structure', 'form', 'the patterns', 'musical works', '\" Simon', 'Patterns', 'periodicity', 'use', 'alphabets', 'can be compound', 'subpatterns', 'phrase structure', 'various forms', 'punctuation', 'composers', 'pattern propagation', 'algorithmic composition techniques', 'the pattern propagation', 'a high level', 'composition', 'all the musical patterns', 'the rules', 'constraints', 'the design stage', 'jazz improvisation', 'the musician', 'a solo', 'a progression', 'chords', 'the changes', 'One approach', 'to memorize patterns', 'short chunks', 'music', 't sub-progressions', 'them', 'a whole solo', 'a whole progression', '\"                     Abstract Many information retrieval(IR) systems', 'relevant documents', 'exact matching', 'keywords', 'a query', 'documents', 'This method', 'precision rate', 'order', 'the problem', 'we', 'semantically related words', 'assigned semantic relationships', 'general thesaurus', 'a special relationship', 'addition', 'the semantic knowledge', 'we', 'statistic knowledge', 'the concept', 'mutual information', 'Keyfact', 'an extended concept', 'keyword', 'compound noun', 'Keyfact', 'an adjective', 'subject or object term', 'We', 'relevant documents', 'original query', 'tf * idf weighting formula', 'an expanded query', 'keyfacts', 'both second document ranking', 'word sense disambiguating', 'we', 'an improvement', 'precision rate', 'keyfact network', 'we', 'technical domains', 'TREC-based  QA', 'Web-based QA', 'it', 'lom data-intensive approaches', 'des Saarlandes', 'Proceedings', 'the Workshop', 'Abstract', 'Abstract', 'SRI', 'a new architecture', 'speech', 'natural-language processing', 'linguistic constraints', 'recognition', 'the state-transition network', 'a unification grammar', 'We', '(DGN', 'This chapter', 'the revolution', 'place', 'natural language processing research', 'the last five years', 'It', 'a brief guide', 'the structure', 'the field', 'a caricature', 'two competing paradigms', '1980s NLP research', 'the reasons', 'visual development environment', 'the visual assembly', 'execution', 'analysis', 'modular natural language processing systems', 'The visual model', 'an executable data flow program graph', 'data dependency declarations', 'language processing modules', 'The graph', 'this Chapter', 'Description Logics', 'Natural Language Processing', 'a little bit', 'history', 'the role', 'Description Logics', 'the current state', 'the art', 'computational linguistics', '18.1 Introduction', 'the early days', 'We', 'a structure learning model', 'Max-Margin Structure', 'MMS', 'natural language processing (NLP) tasks', 'the aim', 'the latent relationships', 'the output language domain', 'We', 'this model', 'an extension', 'class Support Vector Machine', '(SVM', 'a                   \"\\n\"                     -mation Infrastructure', 'digital libraries', 'networked services', 'digital convergence', 'intelligent agents', 'This attention', 'natural language processing', 'the critical path', 'all kinds', 'novel applications', 'This article', 'a number', 'successful applications', 'natural language processing', 'NLP', 'the last few years', 'a number', 'areas', 'natural language processing', 'graph-based techniques', 'others', 'Natural Language Processing', 'research results', 'software engineering and software technology', 'its robustness', 'performance', 'several Natural Language Processing (NLP) tasks', 'document', 'comparable corpora', 'machine transliteration', 'even image processing', 'we', 'these tasks', 'a semi-supervised variant', 'the words', 'statistical natural language processing', 'we', 'a sophisticated statistical model', 'the basic elements', 'words', 'phrases', 'the structural modeling', 'syntactic parsing', 'dependency analysis', 'the basic property', 'these elements', 'this paper', 'we', 'a framework', 'probabilistic classifiers', 'natural language processing', 'Our focus', 'models', 'the most important interdependencies', 'features', 'the data', 'the data', 'The class', '\"                     Many Natural Language Processing (NLP) techniques', 'Information Retrieval', 'The results', 'Simple methods', 'significant improvements', 'higher-level processing', 'chunking', 'parsing', 'word sense disambiguation', 'Abstract-', 'This paper', 'the information retrieval', 'natural language processing', 'Malayalam language', 'the state', 'the art plan recognition systems', 'This paper', 'the relations', 'natural language processing(NLP', 'them', 'key recent research results', 'NLP', 'their applicability', 'the state', 'the art plan recognition systems', 'This paper', 'the relations', 'natural language processing(NLP', 'them', 'key recent research results', 'NLP', 'their applicability', 'PR.', '\"                     Information retrieval', 'the process', 'the documents', 'a document collection', 'the information', 'the user', 'The documents', 'natural language constructs', 'the motivation', 'this work', 'natural language processing', 'logic programming', 'both natural language research and machine learning', 'we', 'opportunities', 'induction', 'linguistic knowledge', 'logic', 'programming', 'Keywords', 'inductive logic programming', 'natural language processing', 'logic programming', 'machine learning', '1 Introduction', 'What', 'a statistical method', 'it', 'natural language processing', 'NLP', 'this paper', 'we', 'a definition', 'NLP', 'the design', 'implementation', 'effective natural language input and output components', 'computational systems', 'We', 'this report', 'some collaborative work', 'the fields', 'Machine Learning', 'ML', 'Natural Language Processing', 'NLP', 'The document', 'two parts', 'The first part', 'a superficial but comprehensive survey', 'the state', 'the--art', 'Abstract', 'This thesis', 'the use', 'techniques', 'various tasks', 'natural language processing', 'the task', 'information extraction', 'texts', 'The objectives', 'the improvement', 'adaptability', 'information extraction systems', 'new thematic do-mains', 'This chapter', 'the application', 'natural language processing', 'language learning', 'the history', 'work', 'this field', 'the last thirtyfive years', 'a focus', 'current developments', 'opportunities', '36.1                    \\n\"                     Traditional approaches tointerpretation', 'natural language processing', 'three classes', 'Syntax-driven approaches', 'a domain-independent grammar', 'the interpretation process', 'a global parse', '\" Natural Language Processing (NLP', 'a very large and diverse subtopic', 'artificial intelligence', 'a result', 'NLP', 'itself', 'many subtopics', 'optical character recognition', 'text', 'translators', 'foreign language reading and writing aids', 'machine translation', 'speech recognition', '\"\\n\"                       Probabilistic finite-state string transducers', 'FSTs', 'natural language processing', 'powerful generic methods', 'composing', 'them', 'FSTs', 'a good fit', 'the current work', 'probabilistic modeling', 'machine', '\"\\n\"                     ABSTRACT', 'this special issue', 'TAL', 'we', 'the fundamental principles', 'underlying evaluation', 'natural language processing', 'We', 'a global point', 'view', 'the horizon', 'a single evaluation campaign', 'a particular protocol', 'a brief review', 'history', 'Abstract', '(NLP', 'clinical information', 'textual reports', 'limited domains', 'particular applications', 'an NLP system', 'substantial resources', 'it', 'it', 'a link', 'IE', 'a recent development', 'Natural Language Processing', 'logic programming', 'We', 'a single convolutional neural network architecture', 'a sentence', 'a host', 'language processing predictions', 'speech', 'chunks', 'the sentence', 'sense', 'We', 'a prototype information retrieval system', 'advanced natural language', 'techniques', 'the effectiveness', 'traditional  key-word based document retrieval', 'The backbone', 'our system', 'a statistical retrieval engine', 'automated indexing', 'Abstract', 'this paper', 'we', 'several issues', 'requirements', 'natural language processing systems', 'the fact', 'emerging systems', 'speaker independent continuous speech recognition', 'individual domains', 'Fall', 'I', 'a new course', 'students', 'an understanding', 'analysis techniques', 'practical applications', 'Abstract', 'Abstract: Natural language processing', 'the study', 'mathematical and computational modelling', 'various aspects', 'language', 'the improvement', 'a wide range', 'systems', 'Natural language', 'any language', 'an innate facility', 'language', 'the human intellect', 'it', 'Natural Language Processing', '(NLP', 'a branch', 'artificial intelligence', 'speech synthesis', 'Speech recognition', 'Machine translation', 'Natural Language Processing', 'a wide range', 'applications', 'the Indian context', 'the rural Indian community', 'use', '\"                     An Evaluation', 'LOLITA', 'Natural Language Processing Systems', 'Paul Callaghan', 'the University', 'Durham', 'the degree', 'Ph.D.', 'August', 'This research', 'the question', 'we', 'systems', 'LOLITA', 'LOLITA', 'the Natural', 'Previous work', 'Web counts', 'bigram counts', 'Web-based frequencies', 'a wide variety', 'Natural Language Processing (NLP) tasks', 'only a limited number', 'tasks', 'Web-scale data sets', 'This chapter', 'the application', 'natural language processing', 'language learning', 'the history', 'work', 'this field', 'the last thirtyfive years', 'a focus', 'current developments', 'opportunities', '16.1 Introduction', 'This chapter', 'applications', 'This paper', 'a natural language system', 'its own performance', 'learning', 'The system', 'short English narratives', 'a single narrative', 'a new schema', 'a stereotypical set', 'actions', 'the understanding process', 'the system', 'We', 'current approaches', 'infrastructure', 'research', 'development', 'delivery', 'NLP systems', 'The task                   \"\\n                     Confidence measures', 'a practical solution', 'the usefulness', 'Natural Language Processing applications', 'Confidence estimation', 'a generic machine learning approach', 'deriving confidence measures', 'We', 'an overview', 'the application', 'confidence estimation', 'various fields', 'lex-sign sense', '-id', 'sense-id', '\"\"LDOCE', 'lex-sign sense-id', 'sense-id ldb-entry', '-no', 'lex-sign sense-id', 'sense-id sense', 'the LKB', 'a fully-fledged representation', 'the transitive use', 'experience', 'word-specific information', 'the information', 'the LKB type', 'strict-trans-sign', 'neither LDOCE', 'LLCE', 'the earlier subcategorised lexicon', 'all the information', 'psychological verbs', 'Sanfilippo&aposs type system', 'the conjunction', 'information', 'it', 'this information', 'the same time', 'it', 'a formal representation', 'a Multilingual LKB', 'A goal', 'ACQUILEX', 'an LKB', 'various MRD sources', 'multilingual information', 'The use', 'a common LRL', 'a common type system', 'it', 'We', 'the design', 'use', 'the Stanford CoreNLP toolkit', 'an extensible pipeline', 'core natural lan-guage analysis', 'This toolkit', 'the research NLP community', 'commercial and govern-ment users', 'open source NLP technol-ogy', 'We', 'Gaussian Processes', 'GPs', 'a powerful mod-elling framework', 'kernels', 'Bayesian inference', 'state', 'the-art', 'many machine learning tasks', 'A fundamental issue', 'natural language processing', 'the prerequisite', 'an enormous quantity', 'preprogrammed knowledge', 'both the language', 'the domain', 'examination', 'Manual acquisition', 'this knowledge', 'Development', 'an automated acquisition', 'sophisticated natural language processing', 'the interface', 'domain-specific knowledge', 'general linguis- tic resources', 'This paper', 'the results', 'our experiences', 'the upper model', 'a variety', 'applications', 'the past 5 years', 'the same or neighboring map nodes', 'Nodes', 'word categories', 'no a priori information', 'classes', 'the self-organizing process', 'a model', 'the word classes', 'The central topic', 'the thesis', 'the use', 'the SOM', 'natural language processing', 'The approach', 'This paper', 'a workbench', 'Priberam Informática', 'the development', 'the company’s natural language processing technology', 'This workbench', 'a set', 'linguistic resources', 'software tools', 'a considerable number', 'practical purposes', 'Abstract', 'Natural Language Processing', 'NLP', 'an effective approach', 'improvement', 'educational setting', 'Implementing NLP', 'the process', 'the natural acquisition', 'the educational systems', 'It', 'effective approaches', 'a solution', 'ABSTRACT', 'twenty years', 'disfavor', 'a technology', 'the processes', 'the brain', 'Natural language experiments', 'Sejnowski', 'Rosenberg', 'neural network computing architecture', 'actual spoken language', 'rules', 'pronunciation', 'Text statistics', 'stylometry', 'cryptography studies', 'this paper', 'some text statistics tools', 'ISO Prolog', 'natural language processing', 'Details', 'the usage', '21 user-callable predicates', 'Logic', 'limitations', 'the program', 'We', 'our experience', 'FrameNet', 'two rather different projects', 'natural language processing', '(NLP', 'We', 'NLP', 'FrameNet', 'different ways', 'we', 'some problems']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frequency</th>\n",
              "      <th>NounProbabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1980s nlp research</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21 user callable</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36 traditional approaches</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abstract many information</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abstract natural language</th>\n",
              "      <td>2</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>web scale data</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word based document</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word sense disambiguating</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word sense disambiguation</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word specific information</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>367 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Frequency  NounProbabilities\n",
              "1980s nlp research                 1           0.013889\n",
              "21 user callable                   1           0.013889\n",
              "36 traditional approaches          1           0.013889\n",
              "abstract many information          1           0.013889\n",
              "abstract natural language          2           0.027778\n",
              "...                              ...                ...\n",
              "web scale data                     1           0.013889\n",
              "word based document                1           0.013889\n",
              "word sense disambiguating          1           0.013889\n",
              "word sense disambiguation          1           0.013889\n",
              "word specific information          1           0.013889\n",
              "\n",
              "[367 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadd9019-4c2f-4636-d7dd-0126afb7d564"
      },
      "source": [
        "\n",
        "#**********************************************tf-idf\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "posdata = []\n",
        "with open('/content/Abstract1.csv' , 'r') as input:\n",
        "  reader = csv.reader(input)\n",
        "  for row in reader:\n",
        "    posdata.extend(row)\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
        "for i , tvar  in zip(range(500), posdata):\n",
        "\n",
        "  #new = input[tvar]\n",
        "  #print(tvar)\n",
        "  tfIdf = tfIdfVectorizer.fit_transform([tvar])\n",
        "  df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "  df = df.sort_values('TF-IDF', ascending=False)\n",
        "  print(df)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          TF-IDF\n",
            "abstract     1.0\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                 TF-IDF\n",
            "maximum        0.420084\n",
            "for            0.280056\n",
            "approach       0.280056\n",
            "describe       0.280056\n",
            "entropy        0.280056\n",
            "and            0.140028\n",
            "natural        0.140028\n",
            "on             0.140028\n",
            "present        0.140028\n",
            "problems       0.140028\n",
            "processing     0.140028\n",
            "modeling       0.140028\n",
            "several        0.140028\n",
            "statistical    0.140028\n",
            "this           0.140028\n",
            "to             0.140028\n",
            "using          0.140028\n",
            "models         0.140028\n",
            "likelihood     0.140028\n",
            "method         0.140028\n",
            "language       0.140028\n",
            "in             0.140028\n",
            "implement      0.140028\n",
            "how            0.140028\n",
            "examples       0.140028\n",
            "efficiently    0.140028\n",
            "constructing   0.140028\n",
            "based          0.140028\n",
            "automatically  0.140028\n",
            "as             0.140028\n",
            "we             0.140028\n",
            "               TF-IDF\n",
            "terms        0.348155\n",
            "conditions   0.348155\n",
            "in           0.348155\n",
            "and          0.348155\n",
            "access       0.174078\n",
            "minerva      0.174078\n",
            "the          0.174078\n",
            "scaling      0.174078\n",
            "retained     0.174078\n",
            "random       0.174078\n",
            "processing   0.174078\n",
            "natural      0.174078\n",
            "is           0.174078\n",
            "language     0.174078\n",
            "for          0.174078\n",
            "fields       0.174078\n",
            "deposited    0.174078\n",
            "copyright    0.174078\n",
            "conditional  0.174078\n",
            "by           0.174078\n",
            "works        0.174078\n",
            "                TF-IDF\n",
            "of            0.361158\n",
            "and           0.361158\n",
            "linguistics   0.361158\n",
            "the           0.240772\n",
            "nlp           0.240772\n",
            "in            0.240772\n",
            "cooperation   0.240772\n",
            "between       0.240772\n",
            "to            0.120386\n",
            "such          0.120386\n",
            "processing    0.120386\n",
            "particular    0.120386\n",
            "paper         0.120386\n",
            "one           0.120386\n",
            "on            0.120386\n",
            "translation   0.120386\n",
            "addresses     0.120386\n",
            "mt            0.120386\n",
            "natural       0.120386\n",
            "namely        0.120386\n",
            "machine       0.120386\n",
            "language      0.120386\n",
            "just          0.120386\n",
            "it            0.120386\n",
            "issue         0.120386\n",
            "general       0.120386\n",
            "focuses       0.120386\n",
            "direction     0.120386\n",
            "applications  0.120386\n",
            "virtually     0.120386\n",
            "                TF-IDF\n",
            "and              0.254\n",
            "have             0.254\n",
            "to               0.254\n",
            "the              0.254\n",
            "semantic         0.254\n",
            "natural          0.254\n",
            "language         0.254\n",
            "in               0.254\n",
            "logics           0.254\n",
            "been             0.254\n",
            "description      0.254\n",
            "generation       0.127\n",
            "encode           0.127\n",
            "base             0.127\n",
            "syntactic        0.127\n",
            "some             0.127\n",
            "recently         0.127\n",
            "processing       0.127\n",
            "processes        0.127\n",
            "pragmatic        0.127\n",
            "needed           0.127\n",
            "drive            0.127\n",
            "most             0.127\n",
            "more             0.127\n",
            "applications     0.127\n",
            "elements         0.127\n",
            "knowledge        0.127\n",
            "interpretation   0.127\n",
            "used             0.127\n",
            "                TF-IDF\n",
            "and           0.298142\n",
            "to            0.298142\n",
            "achieved      0.149071\n",
            "task          0.149071\n",
            "processing    0.149071\n",
            "propose       0.149071\n",
            "recognition   0.149071\n",
            "role          0.149071\n",
            "semantic      0.149071\n",
            "speech        0.149071\n",
            "tagging       0.149071\n",
            "tasks         0.149071\n",
            "of            0.149071\n",
            "that          0.149071\n",
            "this          0.149071\n",
            "trying        0.149071\n",
            "unified       0.149071\n",
            "various       0.149071\n",
            "versatility   0.149071\n",
            "part          0.149071\n",
            "neural        0.149071\n",
            "algorithm     0.149071\n",
            "network       0.149071\n",
            "applied       0.149071\n",
            "architecture  0.149071\n",
            "avoid         0.149071\n",
            "be            0.149071\n",
            "by            0.149071\n",
            "can           0.149071\n",
            "chunking      0.149071\n",
            "entity        0.149071\n",
            "including     0.149071\n",
            "is            0.149071\n",
            "labeling      0.149071\n",
            "language      0.149071\n",
            "learning      0.149071\n",
            "named         0.149071\n",
            "natural       0.149071\n",
            "we            0.149071\n",
            "                 TF-IDF\n",
            "of             0.348743\n",
            "processing     0.348743\n",
            "language       0.348743\n",
            "natural        0.348743\n",
            "and            0.232495\n",
            "the            0.232495\n",
            "broad          0.232495\n",
            "in             0.232495\n",
            "sense          0.116248\n",
            "recognition    0.116248\n",
            "semantic       0.116248\n",
            "all            0.116248\n",
            "senses         0.116248\n",
            "speech         0.116248\n",
            "subject        0.116248\n",
            "syntactic      0.116248\n",
            "sentences      0.116248\n",
            "levels         0.116248\n",
            "narrow         0.116248\n",
            "analysis       0.116248\n",
            "it             0.116248\n",
            "issues         0.116248\n",
            "including      0.116248\n",
            "covers         0.116248\n",
            "considered     0.116248\n",
            "can            0.116248\n",
            "both           0.116248\n",
            "be             0.116248\n",
            "at             0.116248\n",
            "understanding  0.116248\n",
            "                           TF-IDF\n",
            "to                       0.384111\n",
            "language                 0.384111\n",
            "natural                  0.256074\n",
            "robots                   0.256074\n",
            "humans                   0.256074\n",
            "face                     0.256074\n",
            "system                   0.128037\n",
            "that                     0.128037\n",
            "the                      0.128037\n",
            "those                    0.128037\n",
            "be                       0.128037\n",
            "use                      0.128037\n",
            "situations               0.128037\n",
            "using                    0.128037\n",
            "utterances               0.128037\n",
            "way                      0.128037\n",
            "we                       0.128037\n",
            "which                    0.128037\n",
            "spoken                   0.128037\n",
            "responsive               0.128037\n",
            "semantic                 0.128037\n",
            "psychologicallyinspired  0.128037\n",
            "propose                  0.128037\n",
            "processing               0.128037\n",
            "performs                 0.128037\n",
            "of                       0.128037\n",
            "need                     0.128037\n",
            "interpretation           0.128037\n",
            "interact                 0.128037\n",
            "incremental              0.128037\n",
            "in                       0.128037\n",
            "for                      0.128037\n",
            "with                     0.128037\n",
            "               TF-IDF\n",
            "languages    0.344124\n",
            "the          0.344124\n",
            "of           0.344124\n",
            "natural      0.344124\n",
            "are          0.229416\n",
            "by           0.229416\n",
            "point        0.114708\n",
            "processing   0.114708\n",
            "spoken       0.114708\n",
            "techniques   0.114708\n",
            "that         0.114708\n",
            "these        0.114708\n",
            "their        0.114708\n",
            "to           0.114708\n",
            "try          0.114708\n",
            "understood   0.114708\n",
            "unprocessed  0.114708\n",
            "we           0.114708\n",
            "where        0.114708\n",
            "not          0.114708\n",
            "accomplish   0.114708\n",
            "all          0.114708\n",
            "currently    0.114708\n",
            "and          0.114708\n",
            "at           0.114708\n",
            "be           0.114708\n",
            "can          0.114708\n",
            "collection   0.114708\n",
            "computers    0.114708\n",
            "employed     0.114708\n",
            "language     0.114708\n",
            "field        0.114708\n",
            "forms        0.114708\n",
            "goal         0.114708\n",
            "humans       0.114708\n",
            "in           0.114708\n",
            "is           0.114708\n",
            "yet          0.114708\n",
            "               TF-IDF\n",
            "the          0.366508\n",
            "natural      0.244339\n",
            "way          0.244339\n",
            "language     0.244339\n",
            "are          0.244339\n",
            "than         0.244339\n",
            "more         0.244339\n",
            "one          0.244339\n",
            "or           0.122169\n",
            "nlp          0.122169\n",
            "not          0.122169\n",
            "of           0.122169\n",
            "ability      0.122169\n",
            "people       0.122169\n",
            "processing   0.122169\n",
            "so           0.122169\n",
            "to           0.122169\n",
            "understand   0.122169\n",
            "understood   0.122169\n",
            "referred     0.122169\n",
            "meaning      0.122169\n",
            "able         0.122169\n",
            "can          0.122169\n",
            "abstract     0.122169\n",
            "ambiguity    0.122169\n",
            "ambiguous    0.122169\n",
            "as           0.122169\n",
            "be           0.122169\n",
            "being        0.122169\n",
            "computers    0.122169\n",
            "languages    0.122169\n",
            "concerned    0.122169\n",
            "development  0.122169\n",
            "do           0.122169\n",
            "having       0.122169\n",
            "in           0.122169\n",
            "is           0.122169\n",
            "with         0.122169\n",
            "                TF-IDF\n",
            "processing    0.363803\n",
            "of            0.363803\n",
            "natural       0.363803\n",
            "language      0.363803\n",
            "snlp          0.242536\n",
            "in            0.242536\n",
            "and           0.121268\n",
            "linguistic    0.121268\n",
            "the           0.121268\n",
            "that          0.121268\n",
            "statistical   0.121268\n",
            "some          0.121268\n",
            "model         0.121268\n",
            "manually      0.121268\n",
            "machine       0.121268\n",
            "lying         0.121268\n",
            "linguist      0.121268\n",
            "construct     0.121268\n",
            "learning      0.121268\n",
            "is            0.121268\n",
            "introduction  0.121268\n",
            "intersection  0.121268\n",
            "instead       0.121268\n",
            "having        0.121268\n",
            "given         0.121268\n",
            "from          0.121268\n",
            "field         0.121268\n",
            "ers           0.121268\n",
            "di            0.121268\n",
            "traditional   0.121268\n",
            "               TF-IDF\n",
            "and          0.488678\n",
            "the          0.366508\n",
            "with         0.244339\n",
            "of           0.244339\n",
            "on           0.244339\n",
            "this         0.122169\n",
            "titles       0.122169\n",
            "than         0.122169\n",
            "text         0.122169\n",
            "to           0.122169\n",
            "role         0.122169\n",
            "rigorous     0.122169\n",
            "retrieval    0.122169\n",
            "rather       0.122169\n",
            "processing   0.122169\n",
            "possible     0.122169\n",
            "paper        0.122169\n",
            "suggests     0.122169\n",
            "abstracts    0.122169\n",
            "also         0.122169\n",
            "language     0.122169\n",
            "knowledge    0.122169\n",
            "importance   0.122169\n",
            "focus        0.122169\n",
            "emphasizing  0.122169\n",
            "doing        0.122169\n",
            "directly     0.122169\n",
            "data         0.122169\n",
            "connections  0.122169\n",
            "concludes    0.122169\n",
            "comments     0.122169\n",
            "by           0.122169\n",
            "appropriate  0.122169\n",
            "approaches   0.122169\n",
            "natural      0.122169\n",
            "                 TF-IDF\n",
            "language       0.447214\n",
            "as             0.335410\n",
            "world          0.223607\n",
            "are            0.223607\n",
            "of             0.223607\n",
            "the            0.223607\n",
            "helps          0.223607\n",
            "natural        0.223607\n",
            "languages      0.223607\n",
            "abstract       0.111803\n",
            "that           0.111803\n",
            "they           0.111803\n",
            "to             0.111803\n",
            "those          0.111803\n",
            "spoken         0.111803\n",
            "understanding  0.111803\n",
            "vague          0.111803\n",
            "way            0.111803\n",
            "we             0.111803\n",
            "words          0.111803\n",
            "stands         0.111803\n",
            "or             0.111803\n",
            "speakers       0.111803\n",
            "processing     0.111803\n",
            "precise        0.111803\n",
            "nlp            0.111803\n",
            "like           0.111803\n",
            "is             0.111803\n",
            "insight        0.111803\n",
            "in             0.111803\n",
            "get            0.111803\n",
            "for            0.111803\n",
            "communicating  0.111803\n",
            "better         0.111803\n",
            "be             0.111803\n",
            "your           0.111803\n",
            "               TF-IDF\n",
            "of           0.628971\n",
            "lyrics       0.314485\n",
            "the          0.314485\n",
            "analysis     0.209657\n",
            "music        0.209657\n",
            "significant  0.104828\n",
            "part         0.104828\n",
            "processing   0.104828\n",
            "report       0.104828\n",
            "semantics    0.104828\n",
            "acoustic     0.104828\n",
            "song         0.104828\n",
            "on           0.104828\n",
            "that         0.104828\n",
            "their        0.104828\n",
            "therefore    0.104828\n",
            "tools        0.104828\n",
            "use          0.104828\n",
            "standard     0.104828\n",
            "nlp          0.104828\n",
            "amount       0.104828\n",
            "natural      0.104828\n",
            "language     0.104828\n",
            "important    0.104828\n",
            "has          0.104828\n",
            "for          0.104828\n",
            "experiments  0.104828\n",
            "encode       0.104828\n",
            "cultural     0.104828\n",
            "complements  0.104828\n",
            "audio        0.104828\n",
            "and          0.104828\n",
            "an           0.104828\n",
            "we           0.104828\n",
            "               TF-IDF\n",
            "of           0.436436\n",
            "to           0.327327\n",
            "this         0.327327\n",
            "approach     0.218218\n",
            "we           0.218218\n",
            "learning     0.218218\n",
            "in           0.218218\n",
            "and          0.109109\n",
            "rule         0.109109\n",
            "paper        0.109109\n",
            "part         0.109109\n",
            "performance  0.109109\n",
            "present      0.109109\n",
            "simple       0.109109\n",
            "shown        0.109109\n",
            "more         0.109109\n",
            "speech       0.109109\n",
            "study        0.109109\n",
            "tagging      0.109109\n",
            "tasks        0.109109\n",
            "will         0.109109\n",
            "number       0.109109\n",
            "linguistic   0.109109\n",
            "method       0.109109\n",
            "applied      0.109109\n",
            "automated    0.109109\n",
            "based        0.109109\n",
            "been         0.109109\n",
            "capture      0.109109\n",
            "case         0.109109\n",
            "clearer      0.109109\n",
            "compromise   0.109109\n",
            "describe     0.109109\n",
            "detailed     0.109109\n",
            "direct       0.109109\n",
            "fashion      0.109109\n",
            "for          0.109109\n",
            "has          0.109109\n",
            "information  0.109109\n",
            "knowledge    0.109109\n",
            "without      0.109109\n",
            "                 TF-IDF\n",
            "with           0.291730\n",
            "several        0.291730\n",
            "processing     0.291730\n",
            "models         0.291730\n",
            "we             0.145865\n",
            "this           0.145865\n",
            "tasks          0.145865\n",
            "which          0.145865\n",
            "recently       0.145865\n",
            "localist       0.145865\n",
            "present        0.145865\n",
            "parallel       0.145865\n",
            "paper          0.145865\n",
            "or             0.145865\n",
            "on             0.145865\n",
            "of             0.145865\n",
            "natural        0.145865\n",
            "and            0.145865\n",
            "approached     0.145865\n",
            "discuss        0.145865\n",
            "architectures  0.145865\n",
            "aspects        0.145865\n",
            "been           0.145865\n",
            "briefly        0.145865\n",
            "connectionism  0.145865\n",
            "connectionist  0.145865\n",
            "distributed    0.145865\n",
            "language       0.145865\n",
            "either         0.145865\n",
            "focuses        0.145865\n",
            "have           0.145865\n",
            "high           0.145865\n",
            "in             0.145865\n",
            "interesting    0.145865\n",
            "level          0.145865\n",
            "               TF-IDF\n",
            "language          0.4\n",
            "of                0.4\n",
            "approach          0.2\n",
            "new               0.2\n",
            "this              0.2\n",
            "the               0.2\n",
            "systems           0.2\n",
            "processing        0.2\n",
            "process           0.2\n",
            "on                0.2\n",
            "natural           0.2\n",
            "based             0.2\n",
            "is                0.2\n",
            "in                0.2\n",
            "dynamical         0.2\n",
            "deterministic     0.2\n",
            "chaotic           0.2\n",
            "behavior          0.2\n",
            "understanding     0.2\n",
            "               TF-IDF\n",
            "and          0.488678\n",
            "86           0.366508\n",
            "for          0.244339\n",
            "to           0.122169\n",
            "processing   0.122169\n",
            "of           0.122169\n",
            "our          0.122169\n",
            "out          0.122169\n",
            "owens        0.122169\n",
            "paper        0.122169\n",
            "point        0.122169\n",
            "principles   0.122169\n",
            "program      0.122169\n",
            "this         0.122169\n",
            "naturally    0.122169\n",
            "see          0.122169\n",
            "simply       0.122169\n",
            "the          0.122169\n",
            "theoretical  0.122169\n",
            "these        0.122169\n",
            "schank       0.122169\n",
            "led          0.122169\n",
            "natural      0.122169\n",
            "here         0.122169\n",
            "around       0.122169\n",
            "brief        0.122169\n",
            "built        0.122169\n",
            "discussion   0.122169\n",
            "discussions  0.122169\n",
            "goal         0.122169\n",
            "has          0.122169\n",
            "how          0.122169\n",
            "leake        0.122169\n",
            "in           0.122169\n",
            "indeed       0.122169\n",
            "inevitably   0.122169\n",
            "interest     0.122169\n",
            "is           0.122169\n",
            "kass         0.122169\n",
            "language     0.122169\n",
            "us           0.122169\n",
            "                TF-IDF\n",
            "and           0.366508\n",
            "nlp           0.366508\n",
            "the           0.366508\n",
            "of            0.244339\n",
            "tutorial      0.244339\n",
            "limited       0.244339\n",
            "state         0.122169\n",
            "overview      0.122169\n",
            "principles    0.122169\n",
            "processing    0.122169\n",
            "provide       0.122169\n",
            "acquaintance  0.122169\n",
            "system        0.122169\n",
            "or            0.122169\n",
            "targets       0.122169\n",
            "this          0.122169\n",
            "to            0.122169\n",
            "who           0.122169\n",
            "target        0.122169\n",
            "objectives    0.122169\n",
            "an            0.122169\n",
            "natural       0.122169\n",
            "modern        0.122169\n",
            "medical       0.122169\n",
            "language      0.122169\n",
            "knowledge     0.122169\n",
            "informatics   0.122169\n",
            "has           0.122169\n",
            "generalist    0.122169\n",
            "design        0.122169\n",
            "current       0.122169\n",
            "behind        0.122169\n",
            "audience      0.122169\n",
            "with          0.122169\n",
            "                  TF-IDF\n",
            "are             0.301511\n",
            "captions        0.301511\n",
            "the             0.301511\n",
            "system          0.150756\n",
            "parsed          0.150756\n",
            "photographic    0.150756\n",
            "processing      0.150756\n",
            "projects        0.150756\n",
            "retrieval       0.150756\n",
            "status          0.150756\n",
            "an              0.150756\n",
            "paper           0.150756\n",
            "that            0.150756\n",
            "this            0.150756\n",
            "tify            0.150756\n",
            "to              0.150756\n",
            "used            0.150756\n",
            "techniques      0.150756\n",
            "natural         0.150756\n",
            "of              0.150756\n",
            "military        0.150756\n",
            "marie           0.150756\n",
            "language        0.150756\n",
            "intelligent     0.150756\n",
            "information     0.150756\n",
            "implementation  0.150756\n",
            "images          0.150756\n",
            "iden            0.150756\n",
            "employs         0.150756\n",
            "descriptive     0.150756\n",
            "describes       0.150756\n",
            "current         0.150756\n",
            "concerning      0.150756\n",
            "briefly         0.150756\n",
            "various         0.150756\n",
            "               TF-IDF\n",
            "of           0.393919\n",
            "to           0.262613\n",
            "and          0.262613\n",
            "the          0.262613\n",
            "results      0.262613\n",
            "accepted     0.131306\n",
            "nlp          0.131306\n",
            "knowledge    0.131306\n",
            "language     0.131306\n",
            "literature   0.131306\n",
            "motivation   0.131306\n",
            "natural      0.131306\n",
            "processing   0.131306\n",
            "permit       0.131306\n",
            "into         0.131306\n",
            "resources    0.131306\n",
            "system       0.131306\n",
            "was          0.131306\n",
            "journal      0.131306\n",
            "interface    0.131306\n",
            "advent       0.131306\n",
            "information  0.131306\n",
            "agent        0.131306\n",
            "an           0.131306\n",
            "articles     0.131306\n",
            "base         0.131306\n",
            "based        0.131306\n",
            "curation     0.131306\n",
            "deposition   0.131306\n",
            "describe     0.131306\n",
            "developed    0.131306\n",
            "directed     0.131306\n",
            "extract      0.131306\n",
            "for          0.131306\n",
            "from         0.131306\n",
            "here         0.131306\n",
            "high         0.131306\n",
            "we           0.131306\n",
            "               TF-IDF\n",
            "evaluation   0.481543\n",
            "in           0.361158\n",
            "particular   0.240772\n",
            "for          0.240772\n",
            "and          0.240772\n",
            "the          0.240772\n",
            "that         0.120386\n",
            "to           0.120386\n",
            "techniques   0.120386\n",
            "translation  0.120386\n",
            "system       0.120386\n",
            "surveys      0.120386\n",
            "strategies   0.120386\n",
            "speech       0.120386\n",
            "so           0.120386\n",
            "significant  0.120386\n",
            "processing   0.120386\n",
            "problems     0.120386\n",
            "of           0.120386\n",
            "part         0.120386\n",
            "conclusion   0.120386\n",
            "nlp          0.120386\n",
            "need         0.120386\n",
            "much         0.120386\n",
            "more         0.120386\n",
            "machine      0.120386\n",
            "is           0.120386\n",
            "instance     0.120386\n",
            "generic      0.120386\n",
            "far          0.120386\n",
            "done         0.120386\n",
            "discusses    0.120386\n",
            "development  0.120386\n",
            "work         0.120386\n",
            "               TF-IDF\n",
            "in           0.291730\n",
            "to           0.291730\n",
            "of           0.291730\n",
            "analysis     0.145865\n",
            "processing   0.145865\n",
            "nlp          0.145865\n",
            "noisy        0.145865\n",
            "order        0.145865\n",
            "pages        0.145865\n",
            "paper        0.145865\n",
            "similar      0.145865\n",
            "main         0.145865\n",
            "techniques   0.145865\n",
            "the          0.145865\n",
            "this         0.145865\n",
            "way          0.145865\n",
            "we           0.145865\n",
            "web          0.145865\n",
            "natural      0.145865\n",
            "language     0.145865\n",
            "and          0.145865\n",
            "intuitively  0.145865\n",
            "article      0.145865\n",
            "associated   0.145865\n",
            "automated    0.145865\n",
            "combination  0.145865\n",
            "content      0.145865\n",
            "describe     0.145865\n",
            "do           0.145865\n",
            "dom          0.145865\n",
            "eliminate    0.145865\n",
            "extractions  0.145865\n",
            "for          0.145865\n",
            "from         0.145865\n",
            "html         0.145865\n",
            "humans       0.145865\n",
            "images       0.145865\n",
            "with         0.145865\n",
            "                 TF-IDF\n",
            "of             0.503953\n",
            "for            0.377964\n",
            "range          0.251976\n",
            "language       0.251976\n",
            "processing     0.251976\n",
            "abstract       0.125988\n",
            "naturally      0.125988\n",
            "the            0.125988\n",
            "texts          0.125988\n",
            "techniques     0.125988\n",
            "tasks          0.125988\n",
            "representing   0.125988\n",
            "purpose        0.125988\n",
            "or             0.125988\n",
            "one            0.125988\n",
            "occurring      0.125988\n",
            "motivated      0.125988\n",
            "natural        0.125988\n",
            "achieving      0.125988\n",
            "more           0.125988\n",
            "linguistic     0.125988\n",
            "like           0.125988\n",
            "levels         0.125988\n",
            "is             0.125988\n",
            "human          0.125988\n",
            "computational  0.125988\n",
            "at             0.125988\n",
            "and            0.125988\n",
            "analysis       0.125988\n",
            "analysing      0.125988\n",
            "theoretically  0.125988\n",
            "                TF-IDF\n",
            "the           0.675053\n",
            "of            0.225018\n",
            "it            0.225018\n",
            "text          0.225018\n",
            "syntactic     0.112509\n",
            "or            0.112509\n",
            "paper         0.112509\n",
            "processes     0.112509\n",
            "processing    0.112509\n",
            "reviews       0.112509\n",
            "analysis      0.112509\n",
            "nlp           0.112509\n",
            "that          0.112509\n",
            "then          0.112509\n",
            "this          0.112509\n",
            "time          0.112509\n",
            "various       0.112509\n",
            "taken         0.112509\n",
            "need          0.112509\n",
            "be            0.112509\n",
            "natural       0.112509\n",
            "morphology    0.112509\n",
            "language      0.112509\n",
            "kinds         0.112509\n",
            "involved      0.112509\n",
            "in            0.112509\n",
            "generation    0.112509\n",
            "execution     0.112509\n",
            "during        0.112509\n",
            "demonstrates  0.112509\n",
            "components    0.112509\n",
            "complexity    0.112509\n",
            "compares      0.112509\n",
            "choices       0.112509\n",
            "word          0.112509\n",
            "                TF-IDF\n",
            "the           0.478091\n",
            "of            0.478091\n",
            "natural       0.239046\n",
            "dictionary    0.239046\n",
            "language      0.239046\n",
            "processing    0.239046\n",
            "article       0.119523\n",
            "version       0.119523\n",
            "to            0.119523\n",
            "this          0.119523\n",
            "systems       0.119523\n",
            "support       0.119523\n",
            "restructured  0.119523\n",
            "process       0.119523\n",
            "on            0.119523\n",
            "longman       0.119523\n",
            "contemporary  0.119523\n",
            "linking       0.119523\n",
            "lexicons      0.119523\n",
            "large         0.119523\n",
            "for           0.119523\n",
            "focusses      0.119523\n",
            "environment   0.119523\n",
            "english       0.119523\n",
            "development   0.119523\n",
            "describe      0.119523\n",
            "derivation    0.119523\n",
            "we            0.119523\n",
            "              TF-IDF\n",
            "of          0.369274\n",
            "complexity  0.369274\n",
            "the         0.369274\n",
            "for         0.246183\n",
            "automata    0.246183\n",
            "tasks       0.246183\n",
            "processing  0.123091\n",
            "nlp         0.123091\n",
            "our         0.123091\n",
            "pieces      0.123091\n",
            "predicting  0.123091\n",
            "analyzing   0.123091\n",
            "purpose     0.123091\n",
            "natural     0.123091\n",
            "relevant    0.123091\n",
            "to          0.123091\n",
            "we          0.123091\n",
            "new         0.123091\n",
            "measures    0.123091\n",
            "method      0.123091\n",
            "and         0.123091\n",
            "meaning     0.123091\n",
            "language    0.123091\n",
            "kolmogorov  0.123091\n",
            "is          0.123091\n",
            "introduce   0.123091\n",
            "from        0.123091\n",
            "extract     0.123091\n",
            "difficulty  0.123091\n",
            "derived     0.123091\n",
            "class       0.123091\n",
            "are         0.123091\n",
            "whose       0.123091\n",
            "                TF-IDF\n",
            "research      0.377964\n",
            "the           0.377964\n",
            "natural       0.251976\n",
            "deep          0.251976\n",
            "and           0.251976\n",
            "learning      0.251976\n",
            "language      0.251976\n",
            "recent        0.251976\n",
            "processing    0.125988\n",
            "process       0.125988\n",
            "already       0.125988\n",
            "on            0.125988\n",
            "reviews       0.125988\n",
            "sounds        0.125988\n",
            "techniques    0.125988\n",
            "text          0.125988\n",
            "paper         0.125988\n",
            "motion        0.125988\n",
            "of            0.125988\n",
            "its           0.125988\n",
            "in            0.125988\n",
            "impacting     0.125988\n",
            "have          0.125988\n",
            "from          0.125988\n",
            "development   0.125988\n",
            "developed     0.125988\n",
            "been          0.125988\n",
            "applications  0.125988\n",
            "this          0.125988\n",
            "             TF-IDF\n",
            "an         0.301511\n",
            "author     0.301511\n",
            "in         0.301511\n",
            "is         0.301511\n",
            "of         0.301511\n",
            "paper      0.301511\n",
            "produced   0.301511\n",
            "published  0.301511\n",
            "the        0.301511\n",
            "this       0.301511\n",
            "version    0.301511\n",
            "                 TF-IDF\n",
            "of             0.478091\n",
            "nlp            0.358569\n",
            "to             0.358569\n",
            "and            0.239046\n",
            "the            0.239046\n",
            "requirements   0.239046\n",
            "abstract       0.119523\n",
            "use            0.119523\n",
            "text           0.119523\n",
            "techniques     0.119523\n",
            "standard       0.119523\n",
            "specification  0.119523\n",
            "processing     0.119523\n",
            "parsing        0.119523\n",
            "ontologies     0.119523\n",
            "natural        0.119523\n",
            "analyze        0.119523\n",
            "machine        0.119523\n",
            "learning       0.119523\n",
            "language       0.119523\n",
            "is             0.119523\n",
            "include        0.119523\n",
            "from           0.119523\n",
            "extraction     0.119523\n",
            "engineering    0.119523\n",
            "consistency    0.119523\n",
            "automated      0.119523\n",
            "applications   0.119523\n",
            "application    0.119523\n",
            "verify         0.119523\n",
            "               TF-IDF\n",
            "the          0.606339\n",
            "processing   0.242536\n",
            "statistical  0.242536\n",
            "of           0.242536\n",
            "and          0.121268\n",
            "methods      0.121268\n",
            "more         0.121268\n",
            "natural      0.121268\n",
            "nature       0.121268\n",
            "schemes      0.121268\n",
            "retrieval    0.121268\n",
            "linguistic   0.121268\n",
            "task         0.121268\n",
            "techniques   0.121268\n",
            "terms        0.121268\n",
            "typical      0.121268\n",
            "may          0.121268\n",
            "language     0.121268\n",
            "baseline     0.121268\n",
            "forgiving    0.121268\n",
            "be           0.121268\n",
            "broad        0.121268\n",
            "but          0.121268\n",
            "compound     0.121268\n",
            "coverage     0.121268\n",
            "for          0.121268\n",
            "good         0.121268\n",
            "lack         0.121268\n",
            "implicit     0.121268\n",
            "important    0.121268\n",
            "in           0.121268\n",
            "including    0.121268\n",
            "index        0.121268\n",
            "inherent     0.121268\n",
            "weighting    0.121268\n",
            "                 TF-IDF\n",
            "the            0.387298\n",
            "in             0.387298\n",
            "has            0.258199\n",
            "been           0.258199\n",
            "of             0.258199\n",
            "pervasive      0.129099\n",
            "language       0.129099\n",
            "linguistics    0.129099\n",
            "natural        0.129099\n",
            "not            0.129099\n",
            "soon           0.129099\n",
            "progress       0.129099\n",
            "that           0.129099\n",
            "there          0.129099\n",
            "understanding  0.129099\n",
            "very           0.129099\n",
            "work           0.129099\n",
            "intervening    0.129099\n",
            "1958           0.129099\n",
            "after          0.129099\n",
            "four           0.129099\n",
            "first          0.129099\n",
            "feeling        0.129099\n",
            "development    0.129099\n",
            "decades        0.129099\n",
            "computers      0.129099\n",
            "computer       0.129099\n",
            "computational  0.129099\n",
            "commensurate   0.129099\n",
            "cleave         0.129099\n",
            "brandwood      0.129099\n",
            "booth          0.129099\n",
            "began          0.129099\n",
            "and            0.129099\n",
            "yet            0.129099\n",
            "                TF-IDF\n",
            "the           0.549442\n",
            "and           0.412082\n",
            "to            0.274721\n",
            "for           0.274721\n",
            "accuracy      0.137361\n",
            "match         0.137361\n",
            "using         0.137361\n",
            "tamil         0.137361\n",
            "recognition   0.137361\n",
            "performance   0.137361\n",
            "natural       0.137361\n",
            "mfcc          0.137361\n",
            "mathematical  0.137361\n",
            "language      0.137361\n",
            "knowledge     0.137361\n",
            "improve       0.137361\n",
            "features      0.137361\n",
            "extract       0.137361\n",
            "dtw           0.137361\n",
            "digital       0.137361\n",
            "combining     0.137361\n",
            "by            0.137361\n",
            "better        0.137361\n",
            "voice         0.137361\n",
            "                TF-IDF\n",
            "the           0.581238\n",
            "by            0.232495\n",
            "requirements  0.232495\n",
            "is            0.232495\n",
            "testing       0.232495\n",
            "test          0.232495\n",
            "testers       0.116248\n",
            "so            0.116248\n",
            "standard      0.116248\n",
            "system        0.116248\n",
            "abstract      0.116248\n",
            "organization  0.116248\n",
            "things        0.116248\n",
            "this          0.116248\n",
            "to            0.116248\n",
            "unfamiliar    0.116248\n",
            "with          0.116248\n",
            "performed     0.116248\n",
            "often         0.116248\n",
            "only          0.116248\n",
            "acceptance    0.116248\n",
            "natural       0.116248\n",
            "language      0.116248\n",
            "independent   0.116248\n",
            "have          0.116248\n",
            "go            0.116248\n",
            "for           0.116248\n",
            "area          0.116248\n",
            "are           0.116248\n",
            "approach      0.116248\n",
            "application   0.116248\n",
            "and           0.116248\n",
            "an            0.116248\n",
            "against       0.116248\n",
            "written       0.116248\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                TF-IDF\n",
            "and              0.375\n",
            "to               0.375\n",
            "face             0.375\n",
            "about            0.125\n",
            "provides         0.125\n",
            "many             0.125\n",
            "more             0.125\n",
            "multiparty       0.125\n",
            "or               0.125\n",
            "partners         0.125\n",
            "persuade         0.125\n",
            "storytelling     0.125\n",
            "soften           0.125\n",
            "language         0.125\n",
            "subtleties       0.125\n",
            "such             0.125\n",
            "threatening      0.125\n",
            "us               0.125\n",
            "use              0.125\n",
            "using            0.125\n",
            "making           0.125\n",
            "it               0.125\n",
            "act              0.125\n",
            "interaction      0.125\n",
            "added            0.125\n",
            "also             0.125\n",
            "as               0.125\n",
            "associations     0.125\n",
            "avoid            0.125\n",
            "be               0.125\n",
            "being            0.125\n",
            "but              0.125\n",
            "can              0.125\n",
            "conversational   0.125\n",
            "creative         0.125\n",
            "dominate         0.125\n",
            "humor            0.125\n",
            "in               0.125\n",
            "information      0.125\n",
            "with             0.125\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "               TF-IDF\n",
            "to           0.359211\n",
            "in           0.359211\n",
            "more         0.359211\n",
            "and          0.179605\n",
            "mining       0.179605\n",
            "used         0.179605\n",
            "tasks        0.179605\n",
            "solve        0.179605\n",
            "recent       0.179605\n",
            "ranging      0.179605\n",
            "ml           0.179605\n",
            "machine      0.179605\n",
            "been         0.179605\n",
            "learning     0.179605\n",
            "information  0.179605\n",
            "has          0.179605\n",
            "from         0.179605\n",
            "disciplines  0.179605\n",
            "different    0.179605\n",
            "data         0.179605\n",
            "complex      0.179605\n",
            "years        0.179605\n",
            "                   TF-IDF\n",
            "is               0.397779\n",
            "the              0.397779\n",
            "of               0.318223\n",
            "for              0.238667\n",
            "nlp              0.238667\n",
            "thesauruses      0.238667\n",
            "thesaurus        0.159111\n",
            "manual           0.159111\n",
            "tasks            0.159111\n",
            "evaluation       0.159111\n",
            "range            0.159111\n",
            "this             0.159111\n",
            "within           0.159111\n",
            "and              0.159111\n",
            "urgent           0.079556\n",
            "resources        0.079556\n",
            "that             0.079556\n",
            "than             0.079556\n",
            "wasps            0.079556\n",
            "we               0.079556\n",
            "strategies       0.079556\n",
            "word             0.079556\n",
            "step             0.079556\n",
            "senses           0.079556\n",
            "same             0.079556\n",
            "roles            0.079556\n",
            "all              0.079556\n",
            "presented        0.079556\n",
            "rather           0.079556\n",
            "classifications  0.079556\n",
            "are              0.079556\n",
            "argue            0.079556\n",
            "as               0.079556\n",
            "automatic        0.079556\n",
            "becoming         0.079556\n",
            "briefly          0.079556\n",
            "case             0.079556\n",
            "embedded         0.079556\n",
            "radical          0.079556\n",
            "interpreting     0.079556\n",
            "introduced       0.079556\n",
            "involves         0.079556\n",
            "made             0.079556\n",
            "now              0.079556\n",
            "alternative      0.079556\n",
            "proposed         0.079556\n",
            "words            0.079556\n",
            "            TF-IDF\n",
            "the       0.488532\n",
            "of        0.390826\n",
            "to        0.341972\n",
            "patterns  0.244266\n",
            "and       0.195413\n",
            "...            ...\n",
            "evolve    0.048853\n",
            "employed  0.048853\n",
            "during    0.048853\n",
            "discover  0.048853\n",
            "years     0.048853\n",
            "\n",
            "[95 rows x 1 columns]\n",
            "               TF-IDF\n",
            "and          0.411054\n",
            "in           0.293610\n",
            "an           0.234888\n",
            "we           0.234888\n",
            "keyfact      0.234888\n",
            "...               ...\n",
            "improvement  0.058722\n",
            "idf          0.058722\n",
            "general      0.058722\n",
            "ft           0.058722\n",
            "words        0.058722\n",
            "\n",
            "[93 rows x 1 columns]\n",
            "                     TF-IDF\n",
            "qa                 0.493197\n",
            "based              0.328798\n",
            "and                0.164399\n",
            "lom                0.164399\n",
            "we                 0.164399\n",
            "trec               0.164399\n",
            "this               0.164399\n",
            "that               0.164399\n",
            "technical          0.164399\n",
            "questionanswering  0.164399\n",
            "paper              0.164399\n",
            "over               0.164399\n",
            "or                 0.164399\n",
            "it                 0.164399\n",
            "approaches         0.164399\n",
            "is                 0.164399\n",
            "intensive          0.164399\n",
            "from               0.164399\n",
            "domains            0.164399\n",
            "distinctly         0.164399\n",
            "different          0.164399\n",
            "data               0.164399\n",
            "cannot             0.164399\n",
            "benefit            0.164399\n",
            "argue              0.164399\n",
            "web                0.164399\n",
            "              TF-IDF\n",
            "at          0.447214\n",
            "des         0.447214\n",
            "quot        0.447214\n",
            "saarlandes  0.447214\n",
            "universit   0.447214\n",
            "               TF-IDF\n",
            "of           0.447214\n",
            "on           0.447214\n",
            "proceedings  0.447214\n",
            "the          0.447214\n",
            "workshop     0.447214\n",
            "          TF-IDF\n",
            "de       0.57735\n",
            "hamburg  0.57735\n",
            "uni      0.57735\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                 TF-IDF\n",
            "network        0.320256\n",
            "and            0.160128\n",
            "applies        0.160128\n",
            "language       0.160128\n",
            "linguistic     0.160128\n",
            "natural        0.160128\n",
            "new            0.160128\n",
            "processing     0.160128\n",
            "recognition    0.160128\n",
            "speech         0.160128\n",
            "sri            0.160128\n",
            "state          0.160128\n",
            "that           0.160128\n",
            "the            0.160128\n",
            "this           0.160128\n",
            "transition     0.160128\n",
            "unification    0.160128\n",
            "integrating    0.160128\n",
            "incrementally  0.160128\n",
            "in             0.160128\n",
            "dgn            0.160128\n",
            "approach       0.160128\n",
            "architecture   0.160128\n",
            "by             0.160128\n",
            "compare        0.160128\n",
            "constraints    0.160128\n",
            "developed      0.160128\n",
            "during         0.160128\n",
            "has            0.160128\n",
            "dynamic        0.160128\n",
            "embodied       0.160128\n",
            "expanding      0.160128\n",
            "for            0.160128\n",
            "gralnlnar      0.160128\n",
            "grammar        0.160128\n",
            "we             0.160128\n",
            "              TF-IDF\n",
            "the         0.569803\n",
            "of          0.341882\n",
            "and         0.227921\n",
            "research    0.227921\n",
            "over        0.113961\n",
            "paradigms   0.113961\n",
            "place       0.113961\n",
            "presents    0.113961\n",
            "processing  0.113961\n",
            "providing   0.113961\n",
            "reasons     0.113961\n",
            "1980s       0.113961\n",
            "structure   0.113961\n",
            "taken       0.113961\n",
            "that        0.113961\n",
            "then        0.113961\n",
            "this        0.113961\n",
            "to          0.113961\n",
            "two         0.113961\n",
            "revolution  0.113961\n",
            "nlp         0.113961\n",
            "natural     0.113961\n",
            "last        0.113961\n",
            "begins      0.113961\n",
            "brief       0.113961\n",
            "by          0.113961\n",
            "caricature  0.113961\n",
            "chapter     0.113961\n",
            "competing   0.113961\n",
            "considers   0.113961\n",
            "field       0.113961\n",
            "five        0.113961\n",
            "guide       0.113961\n",
            "has         0.113961\n",
            "in          0.113961\n",
            "indicates   0.113961\n",
            "it          0.113961\n",
            "language    0.113961\n",
            "years       0.113961\n",
            "                 TF-IDF\n",
            "visual         0.384111\n",
            "the            0.384111\n",
            "language       0.256074\n",
            "data           0.256074\n",
            "processing     0.256074\n",
            "of             0.256074\n",
            "graph          0.256074\n",
            "to             0.128037\n",
            "systems        0.128037\n",
            "synthesised    0.128037\n",
            "support        0.128037\n",
            "program        0.128037\n",
            "natural        0.128037\n",
            "modules        0.128037\n",
            "modular        0.128037\n",
            "model          0.128037\n",
            "an             0.128037\n",
            "analysis       0.128037\n",
            "from           0.128037\n",
            "flow           0.128037\n",
            "execution      0.128037\n",
            "executable     0.128037\n",
            "environment    0.128037\n",
            "development    0.128037\n",
            "dependency     0.128037\n",
            "declarations   0.128037\n",
            "automatically  0.128037\n",
            "assembly       0.128037\n",
            "and            0.128037\n",
            "is             0.128037\n",
            "                 TF-IDF\n",
            "the            0.515711\n",
            "of             0.412568\n",
            "in             0.309426\n",
            "logics         0.206284\n",
            "description    0.206284\n",
            "will           0.206284\n",
            "be             0.206284\n",
            "natural        0.103142\n",
            "out            0.103142\n",
            "pointed        0.103142\n",
            "processing     0.103142\n",
            "18             0.103142\n",
            "role           0.103142\n",
            "little         0.103142\n",
            "state          0.103142\n",
            "this           0.103142\n",
            "together       0.103142\n",
            "uses           0.103142\n",
            "since          0.103142\n",
            "language       0.103142\n",
            "linguistics    0.103142\n",
            "analysed       0.103142\n",
            "introduction   0.103142\n",
            "history        0.103142\n",
            "for            0.103142\n",
            "early          0.103142\n",
            "days           0.103142\n",
            "current        0.103142\n",
            "computational  0.103142\n",
            "chapter        0.103142\n",
            "bit            0.103142\n",
            "basic          0.103142\n",
            "art            0.103142\n",
            "and            0.103142\n",
            "with           0.103142\n",
            "                 TF-IDF\n",
            "the            0.384111\n",
            "structure      0.256074\n",
            "model          0.256074\n",
            "we             0.256074\n",
            "to             0.256074\n",
            "language       0.256074\n",
            "aim            0.128037\n",
            "of             0.128037\n",
            "output         0.128037\n",
            "present        0.128037\n",
            "processing     0.128037\n",
            "relationships  0.128037\n",
            "support        0.128037\n",
            "natural        0.128037\n",
            "svm            0.128037\n",
            "tasks          0.128037\n",
            "this           0.128037\n",
            "vector         0.128037\n",
            "where          0.128037\n",
            "nlp            0.128037\n",
            "multi          0.128037\n",
            "an             0.128037\n",
            "extension      0.128037\n",
            "and            0.128037\n",
            "applied        0.128037\n",
            "as             0.128037\n",
            "capture        0.128037\n",
            "class          0.128037\n",
            "domain         0.128037\n",
            "formulate      0.128037\n",
            "mms            0.128037\n",
            "is             0.128037\n",
            "latent         0.128037\n",
            "learning       0.128037\n",
            "machine        0.128037\n",
            "margin         0.128037\n",
            "max            0.128037\n",
            "within         0.128037\n",
            "                  TF-IDF\n",
            "of              0.390567\n",
            "natural         0.260378\n",
            "this            0.260378\n",
            "applications    0.260378\n",
            "language        0.260378\n",
            "processing      0.260378\n",
            "digital         0.260378\n",
            "networked       0.130189\n",
            "nlp             0.130189\n",
            "novel           0.130189\n",
            "number          0.130189\n",
            "agents          0.130189\n",
            "or              0.130189\n",
            "moving          0.130189\n",
            "services        0.130189\n",
            "successful      0.130189\n",
            "the             0.130189\n",
            "path            0.130189\n",
            "mation          0.130189\n",
            "mention         0.130189\n",
            "all             0.130189\n",
            "libraries       0.130189\n",
            "kinds           0.130189\n",
            "is              0.130189\n",
            "intelligent     0.130189\n",
            "infrastructure  0.130189\n",
            "for             0.130189\n",
            "critical        0.130189\n",
            "convergence     0.130189\n",
            "attention       0.130189\n",
            "article         0.130189\n",
            "along           0.130189\n",
            "will            0.130189\n",
            "                  TF-IDF\n",
            "text            0.312348\n",
            "of              0.312348\n",
            "among           0.156174\n",
            "sentiment       0.156174\n",
            "others          0.156174\n",
            "over            0.156174\n",
            "parsing         0.156174\n",
            "processing      0.156174\n",
            "sense           0.156174\n",
            "summarization   0.156174\n",
            "subjectivity    0.156174\n",
            "syntactic       0.156174\n",
            "techniques      0.156174\n",
            "the             0.156174\n",
            "these           0.156174\n",
            "word            0.156174\n",
            "ontology        0.156174\n",
            "number          0.156174\n",
            "analysis        0.156174\n",
            "construction    0.156174\n",
            "and             0.156174\n",
            "applying        0.156174\n",
            "areas           0.156174\n",
            "based           0.156174\n",
            "begun           0.156174\n",
            "clustering      0.156174\n",
            "disambiguation  0.156174\n",
            "natural         0.156174\n",
            "few             0.156174\n",
            "graph           0.156174\n",
            "have            0.156174\n",
            "include         0.156174\n",
            "language        0.156174\n",
            "last            0.156174\n",
            "years           0.156174\n",
            "               TF-IDF\n",
            "software     0.458831\n",
            "and          0.229416\n",
            "been         0.229416\n",
            "engineering  0.229416\n",
            "from         0.229416\n",
            "have         0.229416\n",
            "in           0.229416\n",
            "language     0.229416\n",
            "natural      0.229416\n",
            "neglected    0.229416\n",
            "nlp          0.229416\n",
            "often        0.229416\n",
            "processing   0.229416\n",
            "research     0.229416\n",
            "results      0.229416\n",
            "technology   0.229416\n",
            "                   TF-IDF\n",
            "and              0.397360\n",
            "kernelized       0.264906\n",
            "tasks            0.264906\n",
            "processing       0.264906\n",
            "of               0.264906\n",
            "on               0.264906\n",
            "from             0.132453\n",
            "image            0.132453\n",
            "variant          0.132453\n",
            "transliteration  0.132453\n",
            "to               0.132453\n",
            "these            0.132453\n",
            "that             0.132453\n",
            "corpora          0.132453\n",
            "supervised       0.132453\n",
            "sorting          0.132453\n",
            "show             0.132453\n",
            "several          0.132453\n",
            "semi             0.132453\n",
            "robustness       0.132453\n",
            "document         0.132453\n",
            "performance      0.132453\n",
            "parallel         0.132453\n",
            "comparable       0.132453\n",
            "empirically      0.132453\n",
            "nlp              0.132453\n",
            "natural          0.132453\n",
            "matching         0.132453\n",
            "machine          0.132453\n",
            "language         0.132453\n",
            "even             0.132453\n",
            "its              0.132453\n",
            "increase         0.132453\n",
            "we               0.132453\n",
            "                 TF-IDF\n",
            "the            0.447214\n",
            "of             0.335410\n",
            "words          0.223607\n",
            "as             0.223607\n",
            "or             0.223607\n",
            "such           0.223607\n",
            "statistical    0.223607\n",
            "elements       0.223607\n",
            "be             0.223607\n",
            "basic          0.223607\n",
            "we             0.111803\n",
            "to             0.111803\n",
            "sophisticated  0.111803\n",
            "syntactic      0.111803\n",
            "will           0.111803\n",
            "with           0.111803\n",
            "structured     0.111803\n",
            "structural     0.111803\n",
            "these          0.111803\n",
            "analysis       0.111803\n",
            "since          0.111803\n",
            "property       0.111803\n",
            "processing     0.111803\n",
            "parsing        0.111803\n",
            "need           0.111803\n",
            "natural        0.111803\n",
            "modeling       0.111803\n",
            "model          0.111803\n",
            "language       0.111803\n",
            "in             0.111803\n",
            "dependency     0.111803\n",
            "combined       0.111803\n",
            "phrases        0.111803\n",
            "                     TF-IDF\n",
            "the                0.529813\n",
            "in                 0.264906\n",
            "data               0.264906\n",
            "also               0.132453\n",
            "paper              0.132453\n",
            "most               0.132453\n",
            "natural            0.132453\n",
            "on                 0.132453\n",
            "our                0.132453\n",
            "overfitting        0.132453\n",
            "processing         0.132453\n",
            "probabilistic      0.132453\n",
            "language           0.132453\n",
            "that               0.132453\n",
            "this               0.132453\n",
            "to                 0.132453\n",
            "we                 0.132453\n",
            "well               0.132453\n",
            "models             0.132453\n",
            "is                 0.132453\n",
            "among              0.132453\n",
            "interdependencies  0.132453\n",
            "important          0.132453\n",
            "framework          0.132453\n",
            "formulating        0.132453\n",
            "for                0.132453\n",
            "focus              0.132453\n",
            "features           0.132453\n",
            "developing         0.132453\n",
            "describe           0.132453\n",
            "classifiers        0.132453\n",
            "class              0.132453\n",
            "characterizing     0.132453\n",
            "capture            0.132453\n",
            "avoid              0.132453\n",
            "while              0.132453\n",
            "                  TF-IDF\n",
            "processing      0.320256\n",
            "are             0.160128\n",
            "been            0.160128\n",
            "results         0.160128\n",
            "retrieval       0.160128\n",
            "sense           0.160128\n",
            "significant     0.160128\n",
            "simple          0.160128\n",
            "stemming        0.160128\n",
            "stopwording     0.160128\n",
            "style           0.160128\n",
            "techniques      0.160128\n",
            "the             0.160128\n",
            "used            0.160128\n",
            "usually         0.160128\n",
            "while           0.160128\n",
            "word            0.160128\n",
            "porter          0.160128\n",
            "parsing         0.160128\n",
            "not             0.160128\n",
            "improvements    0.160128\n",
            "chunking        0.160128\n",
            "disambiguation  0.160128\n",
            "encouraging     0.160128\n",
            "etc             0.160128\n",
            "have            0.160128\n",
            "higher          0.160128\n",
            "in              0.160128\n",
            "nlp             0.160128\n",
            "information     0.160128\n",
            "language        0.160128\n",
            "level           0.160128\n",
            "many            0.160128\n",
            "methods         0.160128\n",
            "natural         0.160128\n",
            "yield           0.160128\n",
            "               TF-IDF\n",
            "language     0.458831\n",
            "abstract     0.229416\n",
            "basic        0.229416\n",
            "explains     0.229416\n",
            "for          0.229416\n",
            "in           0.229416\n",
            "information  0.229416\n",
            "malayalam    0.229416\n",
            "natural      0.229416\n",
            "paper        0.229416\n",
            "processing   0.229416\n",
            "retrieval    0.229416\n",
            "the          0.229416\n",
            "these        0.229416\n",
            "this         0.229416\n",
            "using        0.229416\n",
            "                 TF-IDF\n",
            "the            0.439057\n",
            "and            0.329293\n",
            "recognition    0.219529\n",
            "of             0.219529\n",
            "nlp            0.219529\n",
            "pr             0.219529\n",
            "in             0.219529\n",
            "plan           0.219529\n",
            "argue          0.219529\n",
            "their          0.109764\n",
            "that           0.109764\n",
            "them           0.109764\n",
            "then           0.109764\n",
            "state          0.109764\n",
            "results        0.109764\n",
            "research       0.109764\n",
            "this           0.109764\n",
            "to             0.109764\n",
            "relations      0.109764\n",
            "recent         0.109764\n",
            "processing     0.109764\n",
            "systems        0.109764\n",
            "outline        0.109764\n",
            "paper          0.109764\n",
            "applicability  0.109764\n",
            "other          0.109764\n",
            "on             0.109764\n",
            "natural        0.109764\n",
            "language       0.109764\n",
            "key            0.109764\n",
            "inform         0.109764\n",
            "for            0.109764\n",
            "focus          0.109764\n",
            "effectively    0.109764\n",
            "each           0.109764\n",
            "can            0.109764\n",
            "between        0.109764\n",
            "art            0.109764\n",
            "will           0.109764\n",
            "                 TF-IDF\n",
            "the            0.439057\n",
            "and            0.329293\n",
            "recognition    0.219529\n",
            "of             0.219529\n",
            "nlp            0.219529\n",
            "pr             0.219529\n",
            "in             0.219529\n",
            "plan           0.219529\n",
            "argue          0.219529\n",
            "their          0.109764\n",
            "that           0.109764\n",
            "them           0.109764\n",
            "then           0.109764\n",
            "state          0.109764\n",
            "results        0.109764\n",
            "research       0.109764\n",
            "this           0.109764\n",
            "to             0.109764\n",
            "relations      0.109764\n",
            "recent         0.109764\n",
            "processing     0.109764\n",
            "systems        0.109764\n",
            "outline        0.109764\n",
            "paper          0.109764\n",
            "applicability  0.109764\n",
            "other          0.109764\n",
            "on             0.109764\n",
            "natural        0.109764\n",
            "language       0.109764\n",
            "key            0.109764\n",
            "inform         0.109764\n",
            "for            0.109764\n",
            "focus          0.109764\n",
            "effectively    0.109764\n",
            "each           0.109764\n",
            "can            0.109764\n",
            "between        0.109764\n",
            "art            0.109764\n",
            "will           0.109764\n",
            "               TF-IDF\n",
            "the          0.625543\n",
            "of           0.312772\n",
            "language     0.208514\n",
            "is           0.208514\n",
            "to           0.208514\n",
            "documents    0.208514\n",
            "natural      0.208514\n",
            "information  0.208514\n",
            "processing   0.104257\n",
            "process      0.104257\n",
            "that         0.104257\n",
            "retrieval    0.104257\n",
            "satisfies    0.104257\n",
            "this         0.104257\n",
            "used         0.104257\n",
            "user         0.104257\n",
            "need         0.104257\n",
            "and          0.104257\n",
            "motivation   0.104257\n",
            "are          0.104257\n",
            "investigate  0.104257\n",
            "in           0.104257\n",
            "improve      0.104257\n",
            "how          0.104257\n",
            "finding      0.104257\n",
            "document     0.104257\n",
            "constructs   0.104257\n",
            "collection   0.104257\n",
            "can          0.104257\n",
            "be           0.104257\n",
            "work         0.104257\n",
            "                 TF-IDF\n",
            "logic          0.468165\n",
            "programming    0.468165\n",
            "language       0.234082\n",
            "of             0.234082\n",
            "natural        0.234082\n",
            "machine        0.234082\n",
            "learning       0.234082\n",
            "within         0.234082\n",
            "knowledge      0.117041\n",
            "out            0.117041\n",
            "we             0.117041\n",
            "there          0.117041\n",
            "research       0.117041\n",
            "for            0.117041\n",
            "processing     0.117041\n",
            "point          0.117041\n",
            "opportunities  0.117041\n",
            "keywords       0.117041\n",
            "induction      0.117041\n",
            "inductive      0.117041\n",
            "introduction   0.117041\n",
            "both           0.117041\n",
            "linguistic     0.117041\n",
            "is             0.117041\n",
            "and            0.117041\n",
            "                  TF-IDF\n",
            "and             0.377964\n",
            "natural         0.251976\n",
            "we              0.251976\n",
            "nlp             0.251976\n",
            "in              0.251976\n",
            "of              0.251976\n",
            "language        0.251976\n",
            "processing      0.125988\n",
            "output          0.125988\n",
            "paper           0.125988\n",
            "statistical     0.125988\n",
            "start           0.125988\n",
            "systems         0.125988\n",
            "the             0.125988\n",
            "this            0.125988\n",
            "three           0.125988\n",
            "used            0.125988\n",
            "what            0.125988\n",
            "method          0.125988\n",
            "it              0.125988\n",
            "as              0.125988\n",
            "design          0.125988\n",
            "be              0.125988\n",
            "can             0.125988\n",
            "components      0.125988\n",
            "computational   0.125988\n",
            "concerned       0.125988\n",
            "definition      0.125988\n",
            "distinguish     0.125988\n",
            "is              0.125988\n",
            "effective       0.125988\n",
            "for             0.125988\n",
            "from            0.125988\n",
            "how             0.125988\n",
            "implementation  0.125988\n",
            "input           0.125988\n",
            "with            0.125988\n",
            "                 TF-IDF\n",
            "the            0.566139\n",
            "of             0.339683\n",
            "machine        0.226455\n",
            "learning       0.226455\n",
            "is             0.226455\n",
            "in             0.226455\n",
            "and            0.113228\n",
            "report         0.113228\n",
            "parts          0.113228\n",
            "presented      0.113228\n",
            "processing     0.113228\n",
            "some           0.113228\n",
            "state          0.113228\n",
            "structured     0.113228\n",
            "superficial    0.113228\n",
            "survey         0.113228\n",
            "this           0.113228\n",
            "two            0.113228\n",
            "part           0.113228\n",
            "natural        0.113228\n",
            "nlp            0.113228\n",
            "art            0.113228\n",
            "ml             0.113228\n",
            "language       0.113228\n",
            "includes       0.113228\n",
            "first          0.113228\n",
            "fields         0.113228\n",
            "document       0.113228\n",
            "covering       0.113228\n",
            "comprehensive  0.113228\n",
            "collaborative  0.113228\n",
            "but            0.113228\n",
            "between        0.113228\n",
            "work           0.113228\n",
            "                TF-IDF\n",
            "of            0.559017\n",
            "the           0.447214\n",
            "extraction    0.223607\n",
            "information   0.223607\n",
            "techniques    0.111803\n",
            "or            0.111803\n",
            "processing    0.111803\n",
            "systems       0.111803\n",
            "task          0.111803\n",
            "tasks         0.111803\n",
            "abstract      0.111803\n",
            "objectives    0.111803\n",
            "thematic      0.111803\n",
            "thesis        0.111803\n",
            "this          0.111803\n",
            "to            0.111803\n",
            "use           0.111803\n",
            "texts         0.111803\n",
            "natural       0.111803\n",
            "new           0.111803\n",
            "adaptability  0.111803\n",
            "mains         0.111803\n",
            "mainly        0.111803\n",
            "machine       0.111803\n",
            "learning      0.111803\n",
            "language      0.111803\n",
            "in            0.111803\n",
            "improvement   0.111803\n",
            "from          0.111803\n",
            "for           0.111803\n",
            "examines      0.111803\n",
            "even          0.111803\n",
            "do            0.111803\n",
            "are           0.111803\n",
            "various       0.111803\n",
            "                    TF-IDF\n",
            "the               0.437595\n",
            "this              0.291730\n",
            "of                0.291730\n",
            "language          0.291730\n",
            "36                0.145865\n",
            "learning          0.145865\n",
            "work              0.145865\n",
            "with              0.145865\n",
            "to                0.145865\n",
            "thirtyfive        0.145865\n",
            "processing        0.145865\n",
            "over              0.145865\n",
            "opportunities     0.145865\n",
            "on                0.145865\n",
            "natural           0.145865\n",
            "last              0.145865\n",
            "and               0.145865\n",
            "including         0.145865\n",
            "in                0.145865\n",
            "history           0.145865\n",
            "focus             0.145865\n",
            "field             0.145865\n",
            "examines          0.145865\n",
            "developments      0.145865\n",
            "current           0.145865\n",
            "computerassisted  0.145865\n",
            "chapter           0.145865\n",
            "but               0.145865\n",
            "application       0.145865\n",
            "years             0.145865\n",
            "                    TF-IDF\n",
            "driven            0.433013\n",
            "approaches        0.288675\n",
            "syntax            0.288675\n",
            "or                0.144338\n",
            "parse             0.144338\n",
            "process           0.144338\n",
            "processing        0.144338\n",
            "produce           0.144338\n",
            "semantics         0.144338\n",
            "and               0.144338\n",
            "one               0.144338\n",
            "the               0.144338\n",
            "three             0.144338\n",
            "to                0.144338\n",
            "tointerpretation  0.144338\n",
            "traditional       0.144338\n",
            "typically         0.144338\n",
            "task              0.144338\n",
            "of                0.144338\n",
            "natural           0.144338\n",
            "language          0.144338\n",
            "into              0.144338\n",
            "interpretation    0.144338\n",
            "independent       0.144338\n",
            "in                0.144338\n",
            "grammar           0.144338\n",
            "global            0.144338\n",
            "frame             0.144338\n",
            "fall              0.144338\n",
            "drive             0.144338\n",
            "domain            0.144338\n",
            "classes           0.144338\n",
            "based             0.144338\n",
            "use               0.144338\n",
            "                TF-IDF\n",
            "and           0.412082\n",
            "speech        0.274721\n",
            "recognition   0.274721\n",
            "language      0.274721\n",
            "nlp           0.274721\n",
            "to            0.137361\n",
            "text          0.137361\n",
            "subtopics     0.137361\n",
            "subtopic      0.137361\n",
            "of            0.137361\n",
            "result        0.137361\n",
            "translation   0.137361\n",
            "translators   0.137361\n",
            "reading       0.137361\n",
            "processing    0.137361\n",
            "optical       0.137361\n",
            "very          0.137361\n",
            "aids          0.137361\n",
            "natural       0.137361\n",
            "many          0.137361\n",
            "machine       0.137361\n",
            "large         0.137361\n",
            "itself        0.137361\n",
            "is            0.137361\n",
            "intelligence  0.137361\n",
            "including     0.137361\n",
            "has           0.137361\n",
            "foreign       0.137361\n",
            "diverse       0.137361\n",
            "character     0.137361\n",
            "as            0.137361\n",
            "artificial    0.137361\n",
            "writing       0.137361\n",
            "                 TF-IDF\n",
            "for            0.412082\n",
            "fsts           0.274721\n",
            "are            0.274721\n",
            "probabilistic  0.274721\n",
            "of             0.137361\n",
            "on             0.137361\n",
            "popular        0.137361\n",
            "powerful       0.137361\n",
            "processing     0.137361\n",
            "state          0.137361\n",
            "and            0.137361\n",
            "natural        0.137361\n",
            "string         0.137361\n",
            "the            0.137361\n",
            "them           0.137361\n",
            "to             0.137361\n",
            "transducers    0.137361\n",
            "unfortunately  0.137361\n",
            "not            0.137361\n",
            "modeling       0.137361\n",
            "much           0.137361\n",
            "applying       0.137361\n",
            "methods        0.137361\n",
            "machine        0.137361\n",
            "learning       0.137361\n",
            "language       0.137361\n",
            "in             0.137361\n",
            "good           0.137361\n",
            "generic        0.137361\n",
            "fit            0.137361\n",
            "finite         0.137361\n",
            "extremely      0.137361\n",
            "due            0.137361\n",
            "current        0.137361\n",
            "composing      0.137361\n",
            "work           0.137361\n",
            "             TF-IDF\n",
            "of            0.500\n",
            "the           0.250\n",
            "in            0.250\n",
            "evaluation    0.250\n",
            "we            0.250\n",
            "this          0.125\n",
            "that          0.125\n",
            "terminology   0.125\n",
            "underlying    0.125\n",
            "tal           0.125\n",
            "or            0.125\n",
            "single        0.125\n",
            "review        0.125\n",
            "protocol      0.125\n",
            "view          0.125\n",
            "processing    0.125\n",
            "principles    0.125\n",
            "point         0.125\n",
            "particular    0.125\n",
            "special       0.125\n",
            "abstract      0.125\n",
            "adopt         0.125\n",
            "look          0.125\n",
            "language      0.125\n",
            "issue         0.125\n",
            "horizon       0.125\n",
            "history       0.125\n",
            "goes          0.125\n",
            "global        0.125\n",
            "fundamental   0.125\n",
            "campaign      0.125\n",
            "brief         0.125\n",
            "beyond        0.125\n",
            "at            0.125\n",
            "and           0.125\n",
            "after         0.125\n",
            "natural       0.125\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                TF-IDF\n",
            "to            0.387298\n",
            "it            0.258199\n",
            "nlp           0.258199\n",
            "be            0.258199\n",
            "is            0.258199\n",
            "for           0.258199\n",
            "resources     0.129099\n",
            "particular    0.129099\n",
            "processing    0.129099\n",
            "reports       0.129099\n",
            "requires      0.129099\n",
            "shown         0.129099\n",
            "limited       0.129099\n",
            "substantial   0.129099\n",
            "system        0.129099\n",
            "systems       0.129099\n",
            "textual       0.129099\n",
            "that          0.129099\n",
            "typically     0.129099\n",
            "natural       0.129099\n",
            "an            0.129099\n",
            "language      0.129099\n",
            "and           0.129099\n",
            "information   0.129099\n",
            "if            0.129099\n",
            "from          0.129099\n",
            "extract       0.129099\n",
            "effective     0.129099\n",
            "easily        0.129099\n",
            "domains       0.129099\n",
            "develop       0.129099\n",
            "designed      0.129099\n",
            "clinical      0.129099\n",
            "beneficial    0.129099\n",
            "because       0.129099\n",
            "applications  0.129099\n",
            "were          0.129099\n",
            "             TF-IDF\n",
            "and            0.25\n",
            "between        0.25\n",
            "development    0.25\n",
            "facts          0.25\n",
            "forms          0.25\n",
            "ie             0.25\n",
            "in             0.25\n",
            "language       0.25\n",
            "link           0.25\n",
            "logic          0.25\n",
            "natural        0.25\n",
            "processing     0.25\n",
            "programming    0.25\n",
            "prolog         0.25\n",
            "recent         0.25\n",
            "with           0.25\n",
            "                 TF-IDF\n",
            "of             0.288675\n",
            "the            0.288675\n",
            "that           0.288675\n",
            "tags           0.288675\n",
            "sentence       0.288675\n",
            "and            0.144338\n",
            "semantically   0.144338\n",
            "processing     0.144338\n",
            "roles          0.144338\n",
            "semantic       0.144338\n",
            "similar        0.144338\n",
            "sense          0.144338\n",
            "part           0.144338\n",
            "single         0.144338\n",
            "speech         0.144338\n",
            "we             0.144338\n",
            "predictions    0.144338\n",
            "outputs        0.144338\n",
            "architecture   0.144338\n",
            "neural         0.144338\n",
            "network        0.144338\n",
            "named          0.144338\n",
            "makes          0.144338\n",
            "likelihood     0.144338\n",
            "language       0.144338\n",
            "host           0.144338\n",
            "grammatically  0.144338\n",
            "given          0.144338\n",
            "entity         0.144338\n",
            "describe       0.144338\n",
            "convolutional  0.144338\n",
            "chunks         0.144338\n",
            "words          0.144338\n",
            "                 TF-IDF\n",
            "retrieval      0.420084\n",
            "of             0.280056\n",
            "which          0.280056\n",
            "the            0.280056\n",
            "system         0.280056\n",
            "our            0.140028\n",
            "we             0.140028\n",
            "uses           0.140028\n",
            "traditional    0.140028\n",
            "to             0.140028\n",
            "techniques     0.140028\n",
            "statistical    0.140028\n",
            "prototype      0.140028\n",
            "processing     0.140028\n",
            "performs       0.140028\n",
            "advanced       0.140028\n",
            "automated      0.140028\n",
            "natural        0.140028\n",
            "language       0.140028\n",
            "key            0.140028\n",
            "is             0.140028\n",
            "information    0.140028\n",
            "indexing       0.140028\n",
            "enhance        0.140028\n",
            "engine         0.140028\n",
            "effectiveness  0.140028\n",
            "document       0.140028\n",
            "developed      0.140028\n",
            "based          0.140028\n",
            "backbone       0.140028\n",
            "word           0.140028\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                TF-IDF\n",
            "to            0.291730\n",
            "systems       0.291730\n",
            "and           0.291730\n",
            "adaptive      0.145865\n",
            "speaker       0.145865\n",
            "paper         0.145865\n",
            "processing    0.145865\n",
            "recognition   0.145865\n",
            "requirements  0.145865\n",
            "restricted    0.145865\n",
            "several       0.145865\n",
            "syntactic     0.145865\n",
            "speech        0.145865\n",
            "that          0.145865\n",
            "the           0.145865\n",
            "this          0.145865\n",
            "we            0.145865\n",
            "will          0.145865\n",
            "natural       0.145865\n",
            "language      0.145865\n",
            "issues        0.145865\n",
            "individual    0.145865\n",
            "are           0.145865\n",
            "become        0.145865\n",
            "context       0.145865\n",
            "continuous    0.145865\n",
            "discuss       0.145865\n",
            "domains       0.145865\n",
            "emerging      0.145865\n",
            "enabling      0.145865\n",
            "equipped      0.145865\n",
            "fact          0.145865\n",
            "feature       0.145865\n",
            "for           0.145865\n",
            "given         0.145865\n",
            "in            0.145865\n",
            "independent   0.145865\n",
            "with          0.145865\n",
            "                 TF-IDF\n",
            "in             0.353553\n",
            "which          0.353553\n",
            "an             0.176777\n",
            "analysis       0.176777\n",
            "understanding  0.176777\n",
            "text           0.176777\n",
            "techniques     0.176777\n",
            "students       0.176777\n",
            "processing     0.176777\n",
            "practical      0.176777\n",
            "of             0.176777\n",
            "new            0.176777\n",
            "natural        0.176777\n",
            "language       0.176777\n",
            "introduced     0.176777\n",
            "acquire        0.176777\n",
            "for            0.176777\n",
            "feasible       0.176777\n",
            "fall           0.176777\n",
            "currently      0.176777\n",
            "course         0.176777\n",
            "called         0.176777\n",
            "are            0.176777\n",
            "applied        0.176777\n",
            "applications   0.176777\n",
            "2004           0.176777\n",
            "           TF-IDF\n",
            "abstract  0.57735\n",
            "found     0.57735\n",
            "not       0.57735\n",
            "                 TF-IDF\n",
            "language       0.507673\n",
            "of             0.507673\n",
            "the            0.304604\n",
            "and            0.203069\n",
            "is             0.203069\n",
            "natural        0.203069\n",
            "abstract       0.101535\n",
            "possessed      0.101535\n",
            "may            0.101535\n",
            "modelling      0.101535\n",
            "range          0.101535\n",
            "processing     0.101535\n",
            "study          0.101535\n",
            "systems        0.101535\n",
            "that           0.101535\n",
            "various        0.101535\n",
            "mathematical   0.101535\n",
            "it             0.101535\n",
            "an             0.101535\n",
            "intellect      0.101535\n",
            "innate         0.101535\n",
            "improvement    0.101535\n",
            "human          0.101535\n",
            "for            0.101535\n",
            "facility       0.101535\n",
            "computational  0.101535\n",
            "by             0.101535\n",
            "aspects        0.101535\n",
            "as             0.101535\n",
            "arises         0.101535\n",
            "any            0.101535\n",
            "wide           0.101535\n",
            "                TF-IDF\n",
            "of            0.384111\n",
            "natural       0.256074\n",
            "the           0.256074\n",
            "language      0.256074\n",
            "is            0.256074\n",
            "speech        0.256074\n",
            "indian        0.256074\n",
            "processing    0.256074\n",
            "to            0.128037\n",
            "translation   0.128037\n",
            "unable        0.128037\n",
            "use           0.128037\n",
            "which         0.128037\n",
            "rural         0.128037\n",
            "recognition   0.128037\n",
            "range         0.128037\n",
            "synthesis     0.128037\n",
            "and           0.128037\n",
            "nlp           0.128037\n",
            "applications  0.128037\n",
            "most          0.128037\n",
            "make          0.128037\n",
            "machine       0.128037\n",
            "intelligence  0.128037\n",
            "includes      0.128037\n",
            "in            0.128037\n",
            "has           0.128037\n",
            "context       0.128037\n",
            "community     0.128037\n",
            "branch        0.128037\n",
            "artificial    0.128037\n",
            "wide          0.128037\n",
            "              TF-IDF\n",
            "the         0.481543\n",
            "lolita      0.361158\n",
            "of          0.361158\n",
            "systems     0.240772\n",
            "natural     0.240772\n",
            "addresses   0.120386\n",
            "university  0.120386\n",
            "to          0.120386\n",
            "this        0.120386\n",
            "submitted   0.120386\n",
            "research    0.120386\n",
            "related     0.120386\n",
            "question    0.120386\n",
            "processing  0.120386\n",
            "ph          0.120386\n",
            "paul        0.120386\n",
            "1997        0.120386\n",
            "like        0.120386\n",
            "language    0.120386\n",
            "is          0.120386\n",
            "how         0.120386\n",
            "for         0.120386\n",
            "evaluation  0.120386\n",
            "evaluate    0.120386\n",
            "durham      0.120386\n",
            "do          0.120386\n",
            "degree      0.120386\n",
            "callaghan   0.120386\n",
            "august      0.120386\n",
            "and         0.120386\n",
            "an          0.120386\n",
            "we          0.120386\n",
            "              TF-IDF\n",
            "web            0.381\n",
            "of             0.254\n",
            "be             0.254\n",
            "counts         0.254\n",
            "tasks          0.254\n",
            "that           0.254\n",
            "tested         0.127\n",
            "scale          0.127\n",
            "sets           0.127\n",
            "should         0.127\n",
            "so             0.127\n",
            "suggesting     0.127\n",
            "to             0.127\n",
            "previous       0.127\n",
            "used           0.127\n",
            "useful         0.127\n",
            "using          0.127\n",
            "variety        0.127\n",
            "wide           0.127\n",
            "processing     0.127\n",
            "approximate    0.127\n",
            "only           0.127\n",
            "based          0.127\n",
            "been           0.127\n",
            "bigram         0.127\n",
            "can            0.127\n",
            "data           0.127\n",
            "demonstrated   0.127\n",
            "far            0.127\n",
            "for            0.127\n",
            "frequencies    0.127\n",
            "have           0.127\n",
            "however        0.127\n",
            "language       0.127\n",
            "limited        0.127\n",
            "natural        0.127\n",
            "nlp            0.127\n",
            "number         0.127\n",
            "work           0.127\n",
            "                    TF-IDF\n",
            "the               0.384111\n",
            "this              0.384111\n",
            "of                0.256074\n",
            "chapter           0.256074\n",
            "on                0.256074\n",
            "language          0.256074\n",
            "over              0.128037\n",
            "learning          0.128037\n",
            "natural           0.128037\n",
            "opportunities     0.128037\n",
            "16                0.128037\n",
            "processing        0.128037\n",
            "thirtyfive        0.128037\n",
            "to                0.128037\n",
            "with              0.128037\n",
            "work              0.128037\n",
            "last              0.128037\n",
            "introduction      0.128037\n",
            "and               0.128037\n",
            "including         0.128037\n",
            "in                0.128037\n",
            "history           0.128037\n",
            "focuses           0.128037\n",
            "focus             0.128037\n",
            "field             0.128037\n",
            "examines          0.128037\n",
            "developments      0.128037\n",
            "current           0.128037\n",
            "computerassisted  0.128037\n",
            "but               0.128037\n",
            "applications      0.128037\n",
            "application       0.128037\n",
            "years             0.128037\n",
            "                 TF-IDF\n",
            "the            0.412082\n",
            "system         0.412082\n",
            "able           0.137361\n",
            "short          0.137361\n",
            "paper          0.137361\n",
            "performance    0.137361\n",
            "process        0.137361\n",
            "processes      0.137361\n",
            "schema         0.137361\n",
            "set            0.137361\n",
            "single         0.137361\n",
            "of             0.137361\n",
            "stereotypical  0.137361\n",
            "this           0.137361\n",
            "through        0.137361\n",
            "to             0.137361\n",
            "understanding  0.137361\n",
            "own            0.137361\n",
            "new            0.137361\n",
            "acquire        0.137361\n",
            "natural        0.137361\n",
            "actions        0.137361\n",
            "and            0.137361\n",
            "attempts       0.137361\n",
            "describes      0.137361\n",
            "during         0.137361\n",
            "english        0.137361\n",
            "for            0.137361\n",
            "from           0.137361\n",
            "improves       0.137361\n",
            "is             0.137361\n",
            "its            0.137361\n",
            "language       0.137361\n",
            "learning       0.137361\n",
            "narrative      0.137361\n",
            "narratives     0.137361\n",
            "which          0.137361\n",
            "                  TF-IDF\n",
            "and             0.436436\n",
            "approaches      0.218218\n",
            "to              0.218218\n",
            "the             0.218218\n",
            "task            0.218218\n",
            "systems         0.218218\n",
            "software        0.218218\n",
            "review          0.218218\n",
            "research        0.218218\n",
            "of              0.218218\n",
            "nlp             0.218218\n",
            "infrastructure  0.218218\n",
            "for             0.218218\n",
            "development     0.218218\n",
            "delivery        0.218218\n",
            "current         0.218218\n",
            "classify        0.218218\n",
            "we              0.218218\n",
            "              TF-IDF\n",
            "confidence     0.500\n",
            "of             0.375\n",
            "the            0.250\n",
            "estimation     0.250\n",
            "for            0.250\n",
            "measures       0.250\n",
            "an             0.125\n",
            "learning       0.125\n",
            "various        0.125\n",
            "usefulness     0.125\n",
            "solution       0.125\n",
            "processing     0.125\n",
            "practical      0.125\n",
            "overview       0.125\n",
            "natural        0.125\n",
            "machine        0.125\n",
            "is             0.125\n",
            "language       0.125\n",
            "application    0.125\n",
            "in             0.125\n",
            "improving      0.125\n",
            "give           0.125\n",
            "generic        0.125\n",
            "fields         0.125\n",
            "deriving       0.125\n",
            "are            0.125\n",
            "approach       0.125\n",
            "applications   0.125\n",
            "we             0.125\n",
            "               TF-IDF\n",
            "the          0.439155\n",
            "sense        0.341565\n",
            "id           0.292770\n",
            "information  0.292770\n",
            "by           0.195180\n",
            "...               ...\n",
            "formal       0.048795\n",
            "for          0.048795\n",
            "fledged      0.048795\n",
            "exploits     0.048795\n",
            "word         0.048795\n",
            "\n",
            "[94 rows x 1 columns]\n",
            "              TF-IDF\n",
            "and         0.361158\n",
            "the         0.361158\n",
            "nlp         0.240772\n",
            "we          0.240772\n",
            "toolkit     0.240772\n",
            "of          0.240772\n",
            "stanford    0.120386\n",
            "open        0.120386\n",
            "pipeline    0.120386\n",
            "provides    0.120386\n",
            "quite       0.120386\n",
            "research    0.120386\n",
            "source      0.120386\n",
            "that        0.120386\n",
            "suggest     0.120386\n",
            "technol     0.120386\n",
            "this        0.120386\n",
            "use         0.120386\n",
            "used        0.120386\n",
            "users       0.120386\n",
            "ogy         0.120386\n",
            "also        0.120386\n",
            "among       0.120386\n",
            "describe    0.120386\n",
            "an          0.120386\n",
            "analysis    0.120386\n",
            "both        0.120386\n",
            "commercial  0.120386\n",
            "community   0.120386\n",
            "core        0.120386\n",
            "corenlp     0.120386\n",
            "design      0.120386\n",
            "natural     0.120386\n",
            "extensible  0.120386\n",
            "govern      0.120386\n",
            "guage       0.120386\n",
            "in          0.120386\n",
            "is          0.120386\n",
            "lan         0.120386\n",
            "ment        0.120386\n",
            "widely      0.120386\n",
            "                 TF-IDF\n",
            "and            0.365148\n",
            "are            0.365148\n",
            "tasks          0.182574\n",
            "state          0.182574\n",
            "recognised     0.182574\n",
            "processes      0.182574\n",
            "powerful       0.182574\n",
            "of             0.182574\n",
            "mod            0.182574\n",
            "many           0.182574\n",
            "machine        0.182574\n",
            "learning       0.182574\n",
            "kernels        0.182574\n",
            "inference      0.182574\n",
            "incorporating  0.182574\n",
            "gps            0.182574\n",
            "gaussian       0.182574\n",
            "framework      0.182574\n",
            "for            0.182574\n",
            "elling         0.182574\n",
            "bayesian       0.182574\n",
            "as             0.182574\n",
            "art            0.182574\n",
            "the            0.182574\n",
            "                 TF-IDF\n",
            "of             0.478091\n",
            "the            0.358569\n",
            "acquisition    0.239046\n",
            "knowledge      0.239046\n",
            "an             0.239046\n",
            "is             0.239046\n",
            "language       0.239046\n",
            "and            0.239046\n",
            "prone          0.119523\n",
            "manual         0.119523\n",
            "prerequisite   0.119523\n",
            "preprogrammed  0.119523\n",
            "quantity       0.119523\n",
            "natural        0.119523\n",
            "tedious        0.119523\n",
            "this           0.119523\n",
            "processing     0.119523\n",
            "issue          0.119523\n",
            "in             0.119523\n",
            "fundamental    0.119523\n",
            "examination    0.119523\n",
            "error          0.119523\n",
            "enormous       0.119523\n",
            "domain         0.119523\n",
            "development    0.119523\n",
            "concerning     0.119523\n",
            "both           0.119523\n",
            "automated      0.119523\n",
            "under          0.119523\n",
            "                 TF-IDF\n",
            "the            0.512148\n",
            "in             0.256074\n",
            "of             0.256074\n",
            "and            0.256074\n",
            "using          0.128037\n",
            "upper          0.128037\n",
            "tic            0.128037\n",
            "variety        0.128037\n",
            "this           0.128037\n",
            "processing     0.128037\n",
            "that           0.128037\n",
            "supports       0.128037\n",
            "specific       0.128037\n",
            "sophisticated  0.128037\n",
            "while          0.128037\n",
            "simplifying    0.128037\n",
            "significantly  0.128037\n",
            "results        0.128037\n",
            "resources      0.128037\n",
            "past           0.128037\n",
            "presents       0.128037\n",
            "knowledge      0.128037\n",
            "between        0.128037\n",
            "designing      0.128037\n",
            "domain         0.128037\n",
            "experiences    0.128037\n",
            "general        0.128037\n",
            "interface      0.128037\n",
            "language       0.128037\n",
            "applications   0.128037\n",
            "linguis        0.128037\n",
            "model          0.128037\n",
            "natural        0.128037\n",
            "our            0.128037\n",
            "over           0.128037\n",
            "paper          0.128037\n",
            "years          0.128037\n",
            "               TF-IDF\n",
            "the          0.724286\n",
            "of           0.271607\n",
            "word         0.181071\n",
            "classes      0.181071\n",
            "is           0.181071\n",
            "nodes        0.181071\n",
            "thesis       0.090536\n",
            "thus         0.090536\n",
            "topic        0.090536\n",
            "som          0.090536\n",
            "no           0.090536\n",
            "same         0.090536\n",
            "processing   0.090536\n",
            "process      0.090536\n",
            "use          0.090536\n",
            "priori       0.090536\n",
            "organizing   0.090536\n",
            "or           0.090536\n",
            "viewed       0.090536\n",
            "self         0.090536\n",
            "about        0.090536\n",
            "neighboring  0.090536\n",
            "although     0.090536\n",
            "approach     0.090536\n",
            "as           0.090536\n",
            "be           0.090536\n",
            "categories   0.090536\n",
            "central      0.090536\n",
            "during       0.090536\n",
            "emerges      0.090536\n",
            "given        0.090536\n",
            "in           0.090536\n",
            "information  0.090536\n",
            "into         0.090536\n",
            "language     0.090536\n",
            "map          0.090536\n",
            "may          0.090536\n",
            "model        0.090536\n",
            "natural      0.090536\n",
            "                TF-IDF\n",
            "of            0.420084\n",
            "this          0.280056\n",
            "the           0.280056\n",
            "workbench     0.280056\n",
            "tools         0.140028\n",
            "that          0.140028\n",
            "technology    0.140028\n",
            "software      0.140028\n",
            "applied       0.140028\n",
            "resources     0.140028\n",
            "purposes      0.140028\n",
            "processing    0.140028\n",
            "priberam      0.140028\n",
            "presents      0.140028\n",
            "practical     0.140028\n",
            "paper         0.140028\n",
            "set           0.140028\n",
            "and           0.140028\n",
            "natural       0.140028\n",
            "linguistic    0.140028\n",
            "language      0.140028\n",
            "informática   0.140028\n",
            "includes      0.140028\n",
            "in            0.140028\n",
            "have          0.140028\n",
            "for           0.140028\n",
            "development   0.140028\n",
            "covering      0.140028\n",
            "considerable  0.140028\n",
            "company       0.140028\n",
            "by            0.140028\n",
            "built         0.140028\n",
            "been          0.140028\n",
            "number        0.140028\n",
            "                TF-IDF\n",
            "the           0.387298\n",
            "is            0.258199\n",
            "educational   0.258199\n",
            "nlp           0.258199\n",
            "in            0.258199\n",
            "for           0.258199\n",
            "effective     0.258199\n",
            "natural       0.258199\n",
            "providing     0.129099\n",
            "learning      0.129099\n",
            "setting       0.129099\n",
            "processing    0.129099\n",
            "process       0.129099\n",
            "solution      0.129099\n",
            "on            0.129099\n",
            "of            0.129099\n",
            "systems       0.129099\n",
            "abstract      0.129099\n",
            "language      0.129099\n",
            "it            0.129099\n",
            "acquisition   0.129099\n",
            "involves      0.129099\n",
            "initiating    0.129099\n",
            "improvement   0.129099\n",
            "implementing  0.129099\n",
            "bringing      0.129099\n",
            "based         0.129099\n",
            "approaches    0.129099\n",
            "approach      0.129099\n",
            "an            0.129099\n",
            "through       0.129099\n",
            "                 TF-IDF\n",
            "of             0.433013\n",
            "language       0.288675\n",
            "the            0.288675\n",
            "1986           0.144338\n",
            "rules          0.144338\n",
            "processes      0.144338\n",
            "pronunciation  0.144338\n",
            "returned       0.144338\n",
            "rosenberg      0.144338\n",
            "sejnowski      0.144338\n",
            "neural         0.144338\n",
            "spoken         0.144338\n",
            "technology     0.144338\n",
            "that           0.144338\n",
            "twenty         0.144338\n",
            "which          0.144338\n",
            "observe        0.144338\n",
            "network        0.144338\n",
            "abstract       0.144338\n",
            "natural        0.144338\n",
            "learn          0.144338\n",
            "imitates       0.144338\n",
            "has            0.144338\n",
            "from           0.144338\n",
            "experiments    0.144338\n",
            "disfavor       0.144338\n",
            "demonstrate    0.144338\n",
            "computing      0.144338\n",
            "can            0.144338\n",
            "brain          0.144338\n",
            "architecture   0.144338\n",
            "after          0.144338\n",
            "actual         0.144338\n",
            "years          0.144338\n",
            "                TF-IDF\n",
            "are           0.464991\n",
            "in            0.348743\n",
            "of            0.232495\n",
            "the           0.232495\n",
            "statistics    0.232495\n",
            "text          0.232495\n",
            "and           0.232495\n",
            "tools         0.116248\n",
            "this          0.116248\n",
            "usage         0.116248\n",
            "paper         0.116248\n",
            "stylometry    0.116248\n",
            "studies       0.116248\n",
            "used          0.116248\n",
            "some          0.116248\n",
            "prolog        0.116248\n",
            "program       0.116248\n",
            "processing    0.116248\n",
            "predicates    0.116248\n",
            "21            0.116248\n",
            "on            0.116248\n",
            "also          0.116248\n",
            "natural       0.116248\n",
            "logic         0.116248\n",
            "limitations   0.116248\n",
            "language      0.116248\n",
            "iso           0.116248\n",
            "given         0.116248\n",
            "frequently    0.116248\n",
            "for           0.116248\n",
            "discussed     0.116248\n",
            "developed     0.116248\n",
            "details       0.116248\n",
            "cryptography  0.116248\n",
            "callable      0.116248\n",
            "user          0.116248\n",
            "              TF-IDF\n",
            "we          0.397360\n",
            "in          0.397360\n",
            "different   0.264906\n",
            "framenet    0.264906\n",
            "that        0.264906\n",
            "nlp         0.264906\n",
            "processing  0.132453\n",
            "ways        0.132453\n",
            "using       0.132453\n",
            "two         0.132453\n",
            "to          0.132453\n",
            "summarize   0.132453\n",
            "some        0.132453\n",
            "sketch      0.132453\n",
            "rather      0.132453\n",
            "projects    0.132453\n",
            "be          0.132453\n",
            "problems    0.132453\n",
            "overcome    0.132453\n",
            "benefit     0.132453\n",
            "need        0.132453\n",
            "natural     0.132453\n",
            "language    0.132453\n",
            "from        0.132453\n",
            "experience  0.132453\n",
            "conclude    0.132453\n",
            "can         0.132453\n",
            "but         0.132453\n",
            "our         0.132453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW1GuyOVEei1",
        "outputId": "1a7bd925-f482-4cb6-de2f-9b9912c55fdd"
      },
      "source": [
        "#****************cosine similarity.\r\n",
        "\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords \r\n",
        "\r\n",
        "from nltk.tokenize import word_tokenize \r\n",
        "\r\n",
        "  \r\n",
        "# X = input(\"Enter first string: \").lower() \r\n",
        "# Y = input(\"Enter second string: \").lower() \r\n",
        "\r\n",
        "X =\"hello ! how are you ?\"\r\n",
        "\r\n",
        "Y =\"I'm good , thanks . How are you doing?\"\r\n",
        "\r\n",
        "  \r\n",
        "# tokenization \r\n",
        "\r\n",
        "X_list = word_tokenize(X)  \r\n",
        "\r\n",
        "Y_list = word_tokenize(Y) \r\n",
        "\r\n",
        "  \r\n",
        "# sw contains the list of stopwords \r\n",
        "\r\n",
        "sw = stopwords.words('english')  \r\n",
        "\r\n",
        "l1 =[];l2 =[] \r\n",
        "\r\n",
        "  \r\n",
        "# remove stop words from the string \r\n",
        "\r\n",
        "X_set = {w for w in X_list if not w in sw}  \r\n",
        "\r\n",
        "Y_set = {w for w in Y_list if not w in sw} \r\n",
        "\r\n",
        "  \r\n",
        "# form a set containing keywords of both strings  \r\n",
        "\r\n",
        "rvector = X_set.union(Y_set)  \r\n",
        "\r\n",
        "for w in rvector: \r\n",
        "\r\n",
        "    if w in X_set: l1.append(1) # create a vector \r\n",
        "\r\n",
        "    else: l1.append(0) \r\n",
        "\r\n",
        "    if w in Y_set: l2.append(1) \r\n",
        "\r\n",
        "    else: l2.append(0) \r\n",
        "\r\n",
        "c = 0\r\n",
        "\r\n",
        "  \r\n",
        "# cosine formula  \r\n",
        "\r\n",
        "for i in range(len(rvector)): \r\n",
        "\r\n",
        "        c+= l1[i]*l2[i] \r\n",
        "\r\n",
        "cosine = c / float((sum(l1)*sum(l2))*0.5) \r\n",
        "\r\n",
        "print(\" cosine similarity: \", cosine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            " cosine similarity:  0.08333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3896a730-fa45-4deb-9a97-4a14335e26cb"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd \n",
        "from nltk.corpus  import  stopwords\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import string\n",
        "\n",
        "from textblob import TextBlob , Word \n",
        "\n",
        "data =  \"/content/Abstract1.csv\"\n",
        "\n",
        "word = pd.read_csv(data)\n",
        "#ALL CHAR TO LOWER CASE\n",
        "word['Abstract'] = word['Abstract'].apply(lambda x :\" \".join(x.lower() for x in x.split()))\n",
        "word['Abstract']\n",
        "type1 = pd.DataFrame(word)\n",
        "\n",
        "\n",
        "# STOP WORDS REMOVAL\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "type1['Abstract'] = type1['Abstract'].apply(lambda x :\" \".join([x for x in  x.split() if x not in stop ]))\n",
        "type2 = pd.DataFrame(type1)\n",
        "\n",
        "#punctuation\n",
        "\n",
        "type2['Abstract'] = type2['Abstract'].apply(lambda x:''.join([i for i in x \n",
        "                                                  if i not in string.punctuation]))\n",
        "type3 = pd.DataFrame(type2)\n",
        "\n",
        "#FREQUENT WORDS REMOVAL\n",
        "\n",
        "fre = pd.Series(' '.join(type2['Abstract']).split()).value_counts()[:20]\n",
        "fre = list(fre.index)\n",
        "type3['Abstract'] = type3['Abstract'].apply(lambda x :\" \".join([x for x in  x.split() if x not in fre ]))\n",
        "type4 = pd.DataFrame(type3)\n",
        "\n",
        "# RARE WORDS REMOVAL\n",
        "\n",
        "'''rar = pd.Series(' '.join(type2['Abstract']).split()).value_counts()[-20:]\n",
        "rar = list(rar.index)\n",
        "type4['Abstract'] = type4['Abstract'].apply(lambda x :\" \".join([x for x in  x.split() if x not in rar ]))\n",
        "type5 = pd.DataFrame(type4)\n",
        "type5 '''\n",
        "\n",
        "# SPELLING CORRECTION \n",
        "\n",
        "\n",
        "type4['Abstract'] = type4['Abstract'] .apply(lambda x : str(TextBlob(x).correct()))\n",
        "type6 = pd.DataFrame(type4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# STEMMING \n",
        "st = PorterStemmer()\n",
        "type6['Abstract'] = type5['Abstract'].apply(lambda x : \" \".join([st.stem(info) for info in x.split()]))\n",
        "type7 = pd.DataFrame(type6)\n",
        "\n",
        "\n",
        "#lemmatization\n",
        "\n",
        "nltk.download('wordnet')\n",
        "type7['DATAafter cleaning'] = type6['Abstract'].apply(lambda x : \" \".join([Word(values).lemmatize() for values in x.split()]))\n",
        "df1 = pd.DataFrame(type7)\n",
        "\n",
        "\n",
        "# all data after cleaning , storing in new datacleaning colum \n",
        "\n",
        "df1.to_csv('datacleaningg.csv', index=True)\n",
        "\n",
        "#SENTMENTALANALYSISFILE IS ATTACHED WHERE SENTIEMNT ANALYSIS IS MENTIONED IN SEPERATE COLUMN\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}